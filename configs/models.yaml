models:
  qwen-3b:
    name: "Qwen/Qwen2.5-3B-Instruct"
    short_name: "qwen-3b"
    max_seq_length: 512
    load_in_4bit: true
    lora_r: 64
    lora_alpha: 128
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj

  qwen-7b:
    name: "Qwen/Qwen2.5-7B-Instruct"
    short_name: "qwen-7b"
    max_seq_length: 512
    load_in_4bit: true
    lora_r: 64
    lora_alpha: 128
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj

  phi3:
    name: "microsoft/Phi-3-mini-4k-instruct"
    short_name: "phi3"
    max_seq_length: 512
    load_in_4bit: true
    lora_r: 32
    lora_alpha: 64
    target_modules:
      - qkv_proj
      - o_proj
      - gate_up_proj
      - down_proj

  mistral:
    name: "mistralai/Mistral-7B-Instruct-v0.3"
    short_name: "mistral"
    max_seq_length: 512
    load_in_4bit: true
    lora_r: 64
    lora_alpha: 128
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj

  llama:
    name: "meta-llama/Meta-Llama-3.1-8B-Instruct"
    short_name: "llama"
    max_seq_length: 512
    load_in_4bit: true
    lora_r: 64
    lora_alpha: 128
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj