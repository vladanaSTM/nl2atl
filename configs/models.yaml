models:
  qwen-3b:
    name: "Qwen/Qwen2.5-3B-Instruct"
    short_name: "qwen-3b"
    max_seq_length: 512
    load_in_4bit: false
    lora_r: 64
    lora_alpha: 128
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj

  qwen-7b:
    name: "Qwen/Qwen2.5-7B-Instruct"
    short_name: "qwen-7b"
    max_seq_length: 512
    load_in_4bit: false
    lora_r: 64
    lora_alpha: 128
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj

  phi3:
    name: "microsoft/Phi-3-mini-4k-instruct"
    short_name: "phi3"
    max_seq_length: 512
    load_in_4bit: false
    lora_r: 32
    lora_alpha: 64
    target_modules:
      - qkv_proj
      - o_proj
      - gate_up_proj
      - down_proj

  mistral:
    name: "mistralai/Mistral-7B-Instruct-v0.3"
    short_name: "mistral"
    max_seq_length: 512
    load_in_4bit: false
    lora_r: 64
    lora_alpha: 128
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj

  llama:
    name: "meta-llama/Meta-Llama-3.1-8B-Instruct"
    short_name: "llama-8b"
    max_seq_length: 512
    load_in_4bit: false
    lora_r: 64
    lora_alpha: 128
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj

  deepseek-r1-qwen-32b:
    name: "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
    short_name: "ds-r1-qwen-32b"
    max_seq_length: 8192
    load_in_4bit: true
    lora_r: 64
    lora_alpha: 128
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj

  qwen-coder-32b:
    name: "Qwen/Qwen2.5-Coder-32B-Instruct"
    short_name: "qwen-coder-32b"
    max_seq_length: 8192
    load_in_4bit: true
    lora_r: 64
    lora_alpha: 128
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj

  gemma3-27b:
    name: "google/gemma-3-27b-it"
    short_name: "gemma3-27b"
    max_seq_length: 8192
    load_in_4bit: true
    lora_r: 64
    lora_alpha: 128
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj

  azure-gpt-4.1:
    name: "azure-openai-gpt-4.1"
    short_name: "gpt-4.1"
    provider: "elysium"
    api_model: "azure-openai-gpt-4.1"
    max_seq_length: 8192
    load_in_4bit: false
    lora_r: 0
    lora_alpha: 0
    target_modules: []

  azure-gpt-5:
    name: "azure-openai-gpt-5"
    short_name: "azure-gpt-5"
    provider: "elysium"
    api_model: "azure-openai-gpt-5"
    max_seq_length: 8192
    load_in_4bit: false
    lora_r: 0
    lora_alpha: 0
    target_modules: []

  gpt-5.2:
    name: "gpt-5.2"
    short_name: "gpt-5.2"
    provider: "elysium"
    api_model: "gpt-5.2"
    max_seq_length: 8192
    load_in_4bit: false
    lora_r: 0
    lora_alpha: 0
    target_modules: []

  DeepSeek-V3.2:
    name: "DeepSeek-V3.2"
    short_name: "ds-v3.2"
    provider: "elysium"
    api_model: "DeepSeek-V3.2"
    max_seq_length: 8192
    load_in_4bit: false
    lora_r: 0
    lora_alpha: 0
    target_modules: []

