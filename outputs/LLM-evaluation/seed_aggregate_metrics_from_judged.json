[
  {
    "model_short": "ds-r1-qwen-32b",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 12,
    "metrics": {
      "accuracy": {
        "mean": 0.6612083333333333,
        "std": 0.11580041348755579
      },
      "exact_match": {
        "mean": 0.060109289617486336,
        "std": 0.0204462152282729
      },
      "exact_match_rate": {
        "mean": 0.06013333333333334,
        "std": 0.020454393714364215
      },
      "llm_approval_rate": {
        "mean": 0.6391083333333334,
        "std": 0.12406752501718123
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 40.333333333333336,
        "std": 7.06320670013903
      },
      "incorrect": {
        "mean": 20.666666666666668,
        "std": 7.06320670013903
      },
      "accuracy_from_exact_match": {
        "mean": 0.06013333333333334,
        "std": 0.020454393714364215
      },
      "accuracy_boost_from_llm": {
        "mean": 0.6011083333333334,
        "std": 0.11941860867227613
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 19932,
        "std": 39.30224760324359
      },
      "total_tokens_output": {
        "mean": 1671.6666666666667,
        "std": 43.77467558100485
      },
      "total_tokens": {
        "mean": 21603.666666666668,
        "std": 77.57290477709053
      },
      "latency_mean_ms": {
        "mean": 2994.1433333333334,
        "std": 67.40218855662064
      },
      "latency_p50_ms": {
        "mean": 2961.81,
        "std": 83.77174702726468
      },
      "latency_p95_ms": {
        "mean": 3926.883333333333,
        "std": 107.43059940672818
      },
      "latency_p99_ms": {
        "mean": 5415.816666666667,
        "std": 706.8527899703652
      },
      "latency_total_ms": {
        "mean": 182642.92333333334,
        "std": 4111.496929751436
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 19941,
          "total_tokens_output": 1720,
          "total_tokens": 21661,
          "latency_mean_ms": 2994.47,
          "latency_p50_ms": 3056.01,
          "latency_p95_ms": 3885.91,
          "latency_p99_ms": 5854.56,
          "latency_total_ms": 182662.92,
          "accuracy": 0.6557,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.6441,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6002,
            "mean_kappa": 0.6002,
            "min_kappa": 0.3034,
            "max_kappa": 0.8923,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 19880,
          "total_tokens_output": 1614,
          "total_tokens": 21494,
          "latency_mean_ms": 2911.43,
          "latency_p50_ms": 2852.49,
          "latency_p95_ms": 3820.67,
          "latency_p99_ms": 4418.57,
          "latency_total_ms": 177597.42,
          "accuracy": 0.6066,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.5714,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.5246,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6223,
            "mean_kappa": 0.6223,
            "min_kappa": 0.4039,
            "max_kappa": 0.8026,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 19975,
          "total_tokens_output": 1681,
          "total_tokens": 21656,
          "latency_mean_ms": 3076.53,
          "latency_p50_ms": 2976.93,
          "latency_p95_ms": 4074.07,
          "latency_p99_ms": 5974.32,
          "latency_total_ms": 187668.43,
          "accuracy": 0.6721,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.6491,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.6066,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6502,
            "mean_kappa": 0.6502,
            "min_kappa": 0.3571,
            "max_kappa": 0.9275,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 19941,
          "total_tokens_output": 1720,
          "total_tokens": 21661,
          "latency_mean_ms": 2994.47,
          "latency_p50_ms": 3056.01,
          "latency_p95_ms": 3885.91,
          "latency_p99_ms": 5854.56,
          "latency_total_ms": 182662.92,
          "accuracy": 0.6393,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.6271,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.6066,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6002,
            "mean_kappa": 0.6002,
            "min_kappa": 0.3034,
            "max_kappa": 0.8923,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 19880,
          "total_tokens_output": 1614,
          "total_tokens": 21494,
          "latency_mean_ms": 2911.43,
          "latency_p50_ms": 2852.49,
          "latency_p95_ms": 3820.67,
          "latency_p99_ms": 4418.57,
          "latency_total_ms": 177597.42,
          "accuracy": 0.5902,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.5536,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.5082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6223,
            "mean_kappa": 0.6223,
            "min_kappa": 0.4039,
            "max_kappa": 0.8026,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 19975,
          "total_tokens_output": 1681,
          "total_tokens": 21656,
          "latency_mean_ms": 3076.53,
          "latency_p50_ms": 2976.93,
          "latency_p95_ms": 4074.07,
          "latency_p99_ms": 5974.32,
          "latency_total_ms": 187668.43,
          "accuracy": 0.6393,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.614,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.5738,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6502,
            "mean_kappa": 0.6502,
            "min_kappa": 0.3571,
            "max_kappa": 0.9275,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 19941,
          "total_tokens_output": 1720,
          "total_tokens": 21661,
          "latency_mean_ms": 2994.47,
          "latency_p50_ms": 3056.01,
          "latency_p95_ms": 3885.91,
          "latency_p99_ms": 5854.56,
          "latency_total_ms": 182662.92,
          "accuracy": 0.5082,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.4915,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 31,
          "incorrect": 30,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.4754,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6002,
            "mean_kappa": 0.6002,
            "min_kappa": 0.3034,
            "max_kappa": 0.8923,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 19880,
          "total_tokens_output": 1614,
          "total_tokens": 21494,
          "latency_mean_ms": 2911.43,
          "latency_p50_ms": 2852.49,
          "latency_p95_ms": 3820.67,
          "latency_p99_ms": 4418.57,
          "latency_total_ms": 177597.42,
          "accuracy": 0.5082,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.4643,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 31,
          "incorrect": 30,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.4262,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6223,
            "mean_kappa": 0.6223,
            "min_kappa": 0.4039,
            "max_kappa": 0.8026,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 19975,
          "total_tokens_output": 1681,
          "total_tokens": 21656,
          "latency_mean_ms": 3076.53,
          "latency_p50_ms": 2976.93,
          "latency_p95_ms": 4074.07,
          "latency_p99_ms": 5974.32,
          "latency_total_ms": 187668.43,
          "accuracy": 0.5902,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.5614,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.5246,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6502,
            "mean_kappa": 0.6502,
            "min_kappa": 0.3571,
            "max_kappa": 0.9275,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 19941,
          "total_tokens_output": 1720,
          "total_tokens": 21661,
          "latency_mean_ms": 2994.47,
          "latency_p50_ms": 3056.01,
          "latency_p95_ms": 3885.91,
          "latency_p99_ms": 5854.56,
          "latency_total_ms": 182662.92,
          "accuracy": 0.8525,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.8475,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 52,
          "incorrect": 9,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.8197,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6002,
            "mean_kappa": 0.6002,
            "min_kappa": 0.3034,
            "max_kappa": 0.8923,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_few_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 19880,
          "total_tokens_output": 1614,
          "total_tokens": 21494,
          "latency_mean_ms": 2911.43,
          "latency_p50_ms": 2852.49,
          "latency_p95_ms": 3820.67,
          "latency_p99_ms": 4418.57,
          "latency_total_ms": 177597.42,
          "accuracy": 0.8033,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.7857,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.7213,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6223,
            "mean_kappa": 0.6223,
            "min_kappa": 0.4039,
            "max_kappa": 0.8026,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_few_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 19975,
          "total_tokens_output": 1681,
          "total_tokens": 21656,
          "latency_mean_ms": 3076.53,
          "latency_p50_ms": 2976.93,
          "latency_p95_ms": 4074.07,
          "latency_p99_ms": 5974.32,
          "latency_total_ms": 187668.43,
          "accuracy": 0.8689,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.8596,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 53,
          "incorrect": 8,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.8033,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6502,
            "mean_kappa": 0.6502,
            "min_kappa": 0.3571,
            "max_kappa": 0.9275,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_few_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.6242333333333333,
        "std": 0.020458141546962575
      },
      "mean_kappa": {
        "mean": 0.6242333333333333,
        "std": 0.020458141546962575
      },
      "min_kappa": {
        "mean": 0.3548,
        "std": 0.04106117387508544
      },
      "max_kappa": {
        "mean": 0.8741333333333333,
        "std": 0.05258341521388237
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "ds-r1-qwen-32b",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.50410625,
        "std": 0.19017186131480518
      },
      "exact_match": {
        "mean": 0.020491803278688527,
        "std": 0.021295706650437014
      },
      "exact_match_rate": {
        "mean": 0.0205,
        "std": 0.02130422493309719
      },
      "llm_approval_rate": {
        "mean": 0.49368125,
        "std": 0.19364494319097905
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 30.75,
        "std": 11.600107758120181
      },
      "incorrect": {
        "mean": 30.25,
        "std": 11.600107758120181
      },
      "accuracy_from_exact_match": {
        "mean": 0.0205,
        "std": 0.02130422493309719
      },
      "accuracy_boost_from_llm": {
        "mean": 0.4836125,
        "std": 0.1903882771962339
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 10855,
        "std": 39.881073205218534
      },
      "total_tokens_output": {
        "mean": 1945.25,
        "std": 137.7613425457229
      },
      "total_tokens": {
        "mean": 12800.25,
        "std": 167.5878500965986
      },
      "latency_mean_ms": {
        "mean": 3379.265,
        "std": 284.8967176451846
      },
      "latency_p50_ms": {
        "mean": 2945.1375,
        "std": 122.6872701984602
      },
      "latency_p95_ms": {
        "mean": 5329.075,
        "std": 533.8225987395064
      },
      "latency_p99_ms": {
        "mean": 11846.0175,
        "std": 4188.714183531594
      },
      "latency_total_ms": {
        "mean": 206134.9975,
        "std": 17378.743117730606
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 10852,
          "total_tokens_output": 2103,
          "total_tokens": 12955,
          "latency_mean_ms": 3678.58,
          "latency_p50_ms": 3086.38,
          "latency_p95_ms": 5183.0,
          "latency_p99_ms": 15298.18,
          "latency_total_ms": 224393.16,
          "accuracy": 0.5574,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.5424,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.5246,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4176,
            "mean_kappa": 0.4176,
            "min_kappa": 0.1567,
            "max_kappa": 0.6141,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 10791,
          "total_tokens_output": 1730,
          "total_tokens": 12521,
          "latency_mean_ms": 2911.35,
          "latency_p50_ms": 2788.09,
          "latency_p95_ms": 4697.7,
          "latency_p99_ms": 5958.56,
          "latency_total_ms": 177592.09,
          "accuracy": 0.5246,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.5,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 32,
          "incorrect": 29,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4754,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5184,
            "mean_kappa": 0.5184,
            "min_kappa": 0.2307,
            "max_kappa": 0.824,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10891,
          "total_tokens_output": 1935,
          "total_tokens": 12826,
          "latency_mean_ms": 3432.6,
          "latency_p50_ms": 3040.99,
          "latency_p95_ms": 5260.81,
          "latency_p99_ms": 9851.47,
          "latency_total_ms": 209388.35,
          "accuracy": 0.4754,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.4754,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.4754,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4137,
            "mean_kappa": 0.4137,
            "min_kappa": 0.0993,
            "max_kappa": 0.667,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10886,
          "total_tokens_output": 2013,
          "total_tokens": 12899,
          "latency_mean_ms": 3494.53,
          "latency_p50_ms": 2865.09,
          "latency_p95_ms": 6174.79,
          "latency_p99_ms": 16275.86,
          "latency_total_ms": 213166.39,
          "accuracy": 0.5246,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.5246,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 32,
          "incorrect": 29,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.5246,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4608,
            "mean_kappa": 0.4608,
            "min_kappa": 0.1651,
            "max_kappa": 0.6893,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 10852,
          "total_tokens_output": 2103,
          "total_tokens": 12955,
          "latency_mean_ms": 3678.58,
          "latency_p50_ms": 3086.38,
          "latency_p95_ms": 5183.0,
          "latency_p99_ms": 15298.18,
          "latency_total_ms": 224393.16,
          "accuracy": 0.4262,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.4068,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 26,
          "incorrect": 35,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4176,
            "mean_kappa": 0.4176,
            "min_kappa": 0.1567,
            "max_kappa": 0.6141,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 10791,
          "total_tokens_output": 1730,
          "total_tokens": 12521,
          "latency_mean_ms": 2911.35,
          "latency_p50_ms": 2788.09,
          "latency_p95_ms": 4697.7,
          "latency_p99_ms": 5958.56,
          "latency_total_ms": 177592.09,
          "accuracy": 0.377,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.3448,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 23,
          "incorrect": 38,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5184,
            "mean_kappa": 0.5184,
            "min_kappa": 0.2307,
            "max_kappa": 0.824,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10891,
          "total_tokens_output": 1935,
          "total_tokens": 12826,
          "latency_mean_ms": 3432.6,
          "latency_p50_ms": 3040.99,
          "latency_p95_ms": 5260.81,
          "latency_p99_ms": 9851.47,
          "latency_total_ms": 209388.35,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.3443,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4137,
            "mean_kappa": 0.4137,
            "min_kappa": 0.0993,
            "max_kappa": 0.667,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10886,
          "total_tokens_output": 2013,
          "total_tokens": 12899,
          "latency_mean_ms": 3494.53,
          "latency_p50_ms": 2865.09,
          "latency_p95_ms": 6174.79,
          "latency_p99_ms": 16275.86,
          "latency_total_ms": 213166.39,
          "accuracy": 0.4098,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.4098,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 25,
          "incorrect": 36,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4608,
            "mean_kappa": 0.4608,
            "min_kappa": 0.1651,
            "max_kappa": 0.6893,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 10852,
          "total_tokens_output": 2103,
          "total_tokens": 12955,
          "latency_mean_ms": 3678.58,
          "latency_p50_ms": 3086.38,
          "latency_p95_ms": 5183.0,
          "latency_p99_ms": 15298.18,
          "latency_total_ms": 224393.16,
          "accuracy": 0.2787,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.2542,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 17,
          "incorrect": 44,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4176,
            "mean_kappa": 0.4176,
            "min_kappa": 0.1567,
            "max_kappa": 0.6141,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 10791,
          "total_tokens_output": 1730,
          "total_tokens": 12521,
          "latency_mean_ms": 2911.35,
          "latency_p50_ms": 2788.09,
          "latency_p95_ms": 4697.7,
          "latency_p99_ms": 5958.56,
          "latency_total_ms": 177592.09,
          "accuracy": 0.3607,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.3276,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 22,
          "incorrect": 39,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5184,
            "mean_kappa": 0.5184,
            "min_kappa": 0.2307,
            "max_kappa": 0.824,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10891,
          "total_tokens_output": 1935,
          "total_tokens": 12826,
          "latency_mean_ms": 3432.6,
          "latency_p50_ms": 3040.99,
          "latency_p95_ms": 5260.81,
          "latency_p99_ms": 9851.47,
          "latency_total_ms": 209388.35,
          "accuracy": 0.2295,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2295,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 14,
          "incorrect": 47,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4137,
            "mean_kappa": 0.4137,
            "min_kappa": 0.0993,
            "max_kappa": 0.667,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10886,
          "total_tokens_output": 2013,
          "total_tokens": 12899,
          "latency_mean_ms": 3494.53,
          "latency_p50_ms": 2865.09,
          "latency_p95_ms": 6174.79,
          "latency_p99_ms": 16275.86,
          "latency_total_ms": 213166.39,
          "accuracy": 0.3607,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.3607,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 22,
          "incorrect": 39,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4608,
            "mean_kappa": 0.4608,
            "min_kappa": 0.1651,
            "max_kappa": 0.6893,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 10852,
          "total_tokens_output": 2103,
          "total_tokens": 12955,
          "latency_mean_ms": 3678.58,
          "latency_p50_ms": 3086.38,
          "latency_p95_ms": 5183.0,
          "latency_p99_ms": 15298.18,
          "latency_total_ms": 224393.16,
          "accuracy": 0.8197,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.8136,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 50,
          "incorrect": 11,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.7869,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4176,
            "mean_kappa": 0.4176,
            "min_kappa": 0.1567,
            "max_kappa": 0.6141,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 10791,
          "total_tokens_output": 1730,
          "total_tokens": 12521,
          "latency_mean_ms": 2911.35,
          "latency_p50_ms": 2788.09,
          "latency_p95_ms": 4697.7,
          "latency_p99_ms": 5958.56,
          "latency_total_ms": 177592.09,
          "accuracy": 0.7705,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.7586,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.7213,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5184,
            "mean_kappa": 0.5184,
            "min_kappa": 0.2307,
            "max_kappa": 0.824,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10891,
          "total_tokens_output": 1935,
          "total_tokens": 12826,
          "latency_mean_ms": 3432.6,
          "latency_p50_ms": 3040.99,
          "latency_p95_ms": 5260.81,
          "latency_p99_ms": 9851.47,
          "latency_total_ms": 209388.35,
          "accuracy": 0.7869,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.7869,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 48,
          "incorrect": 13,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.7869,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4137,
            "mean_kappa": 0.4137,
            "min_kappa": 0.0993,
            "max_kappa": 0.667,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed45__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10886,
          "total_tokens_output": 2013,
          "total_tokens": 12899,
          "latency_mean_ms": 3494.53,
          "latency_p50_ms": 2865.09,
          "latency_p95_ms": 6174.79,
          "latency_p99_ms": 16275.86,
          "latency_total_ms": 213166.39,
          "accuracy": 0.8197,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.8197,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 50,
          "incorrect": 11,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.8197,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4608,
            "mean_kappa": 0.4608,
            "min_kappa": 0.1651,
            "max_kappa": 0.6893,
            "n_items": 61
          }
        },
        "source": "ds-r1-qwen-32b_baseline_zero_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.452625,
        "std": 0.042234723569593756
      },
      "mean_kappa": {
        "mean": 0.452625,
        "std": 0.042234723569593756
      },
      "min_kappa": {
        "mean": 0.16294999999999998,
        "std": 0.04659686148229299
      },
      "max_kappa": {
        "mean": 0.6986,
        "std": 0.07737968079541294
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "ds-v3.2",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.73565625,
        "std": 0.0912413075911207
      },
      "exact_match": {
        "mean": 0.11475409836065574,
        "std": 0.05052798363089325
      },
      "exact_match_rate": {
        "mean": 0.11474999999999999,
        "std": 0.05049952970078037
      },
      "llm_approval_rate": {
        "mean": 0.70126875,
        "std": 0.10249040637268202
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 44.875,
        "std": 5.56636101955308
      },
      "incorrect": {
        "mean": 16.125,
        "std": 5.56636101955308
      },
      "accuracy_from_exact_match": {
        "mean": 0.11474999999999999,
        "std": 0.05049952970078037
      },
      "accuracy_boost_from_llm": {
        "mean": 0.62090625,
        "std": 0.0981660103393099
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 17744.75,
        "std": 40.53008142108772
      },
      "total_tokens_output": {
        "mean": 775.25,
        "std": 38.3038836151114
      },
      "total_tokens": {
        "mean": 18520,
        "std": 73.05819598101229
      },
      "latency_mean_ms": {
        "mean": 2873.42,
        "std": 1382.2434577707359
      },
      "latency_p50_ms": {
        "mean": 1428.435,
        "std": 107.68283208107037
      },
      "latency_p95_ms": {
        "mean": 9949.3575,
        "std": 9402.714805898813
      },
      "latency_p99_ms": {
        "mean": 19839.6425,
        "std": 13061.348183980426
      },
      "latency_total_ms": {
        "mean": 175278.6075,
        "std": 84316.95472137866
      }
    },
    "per_seed": [
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.14754098360655737,
          "total_tokens_input": 17680,
          "total_tokens_output": 717,
          "total_tokens": 18397,
          "total_cost_usd": 0.012641,
          "total_cost_input_usd": 0.011316,
          "total_cost_output_usd": 0.001336,
          "avg_cost_usd": 0.000207,
          "avg_cost_input_usd": 0.000186,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 2048.97,
          "latency_p50_ms": 1381.46,
          "latency_p95_ms": 4160.24,
          "latency_p99_ms": 10431.11,
          "latency_total_ms": 124986.91,
          "accuracy": 0.6885,
          "exact_match_rate": 0.1475,
          "llm_approval_rate": 0.6346,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.1475,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6332,
            "mean_kappa": 0.6332,
            "min_kappa": 0.4812,
            "max_kappa": 0.7221,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17741,
          "total_tokens_output": 813,
          "total_tokens": 18554,
          "total_cost_usd": 0.012859,
          "total_cost_input_usd": 0.011358,
          "total_cost_output_usd": 0.00151,
          "avg_cost_usd": 0.000211,
          "avg_cost_input_usd": 0.000186,
          "avg_cost_output_usd": 2.5e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 5251.92,
          "latency_p50_ms": 1592.56,
          "latency_p95_ms": 26218.93,
          "latency_p99_ms": 40426.11,
          "latency_total_ms": 320367.32,
          "accuracy": 0.7377,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.7193,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.6721,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6553,
            "mean_kappa": 0.6553,
            "min_kappa": 0.4894,
            "max_kappa": 0.7557,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17782,
          "total_tokens_output": 806,
          "total_tokens": 18588,
          "total_cost_usd": 0.012868,
          "total_cost_input_usd": 0.011382,
          "total_cost_output_usd": 0.001497,
          "avg_cost_usd": 0.000211,
          "avg_cost_input_usd": 0.000187,
          "avg_cost_output_usd": 2.5e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 2317.61,
          "latency_p50_ms": 1297.83,
          "latency_p95_ms": 5214.77,
          "latency_p99_ms": 21585.49,
          "latency_total_ms": 141373.97,
          "accuracy": 0.7705,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.7544,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.7049,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5075,
            "mean_kappa": 0.5075,
            "min_kappa": 0.3528,
            "max_kappa": 0.6776,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.18032786885245902,
          "total_tokens_input": 17776,
          "total_tokens_output": 765,
          "total_tokens": 18541,
          "total_cost_usd": 0.012794,
          "total_cost_input_usd": 0.011375,
          "total_cost_output_usd": 0.001422,
          "avg_cost_usd": 0.00021,
          "avg_cost_input_usd": 0.000186,
          "avg_cost_output_usd": 2.3e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 1875.18,
          "latency_p50_ms": 1441.89,
          "latency_p95_ms": 4203.49,
          "latency_p99_ms": 6915.86,
          "latency_total_ms": 114386.23,
          "accuracy": 0.8033,
          "exact_match_rate": 0.1803,
          "llm_approval_rate": 0.76,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.1803,
          "accuracy_boost_from_llm": 0.623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6502,
            "mean_kappa": 0.6502,
            "min_kappa": 0.4404,
            "max_kappa": 0.8754,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.14754098360655737,
          "total_tokens_input": 17680,
          "total_tokens_output": 717,
          "total_tokens": 18397,
          "total_cost_usd": 0.012641,
          "total_cost_input_usd": 0.011316,
          "total_cost_output_usd": 0.001336,
          "avg_cost_usd": 0.000207,
          "avg_cost_input_usd": 0.000186,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 2048.97,
          "latency_p50_ms": 1381.46,
          "latency_p95_ms": 4160.24,
          "latency_p99_ms": 10431.11,
          "latency_total_ms": 124986.91,
          "accuracy": 0.6557,
          "exact_match_rate": 0.1475,
          "llm_approval_rate": 0.5962,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.1475,
          "accuracy_boost_from_llm": 0.5082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6332,
            "mean_kappa": 0.6332,
            "min_kappa": 0.4812,
            "max_kappa": 0.7221,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17741,
          "total_tokens_output": 813,
          "total_tokens": 18554,
          "total_cost_usd": 0.012859,
          "total_cost_input_usd": 0.011358,
          "total_cost_output_usd": 0.00151,
          "avg_cost_usd": 0.000211,
          "avg_cost_input_usd": 0.000186,
          "avg_cost_output_usd": 2.5e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 5251.92,
          "latency_p50_ms": 1592.56,
          "latency_p95_ms": 26218.93,
          "latency_p99_ms": 40426.11,
          "latency_total_ms": 320367.32,
          "accuracy": 0.7049,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.6842,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6553,
            "mean_kappa": 0.6553,
            "min_kappa": 0.4894,
            "max_kappa": 0.7557,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17782,
          "total_tokens_output": 806,
          "total_tokens": 18588,
          "total_cost_usd": 0.012868,
          "total_cost_input_usd": 0.011382,
          "total_cost_output_usd": 0.001497,
          "avg_cost_usd": 0.000211,
          "avg_cost_input_usd": 0.000187,
          "avg_cost_output_usd": 2.5e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 2317.61,
          "latency_p50_ms": 1297.83,
          "latency_p95_ms": 5214.77,
          "latency_p99_ms": 21585.49,
          "latency_total_ms": 141373.97,
          "accuracy": 0.6721,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.6491,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.6066,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5075,
            "mean_kappa": 0.5075,
            "min_kappa": 0.3528,
            "max_kappa": 0.6776,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.18032786885245902,
          "total_tokens_input": 17776,
          "total_tokens_output": 765,
          "total_tokens": 18541,
          "total_cost_usd": 0.012794,
          "total_cost_input_usd": 0.011375,
          "total_cost_output_usd": 0.001422,
          "avg_cost_usd": 0.00021,
          "avg_cost_input_usd": 0.000186,
          "avg_cost_output_usd": 2.3e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 1875.18,
          "latency_p50_ms": 1441.89,
          "latency_p95_ms": 4203.49,
          "latency_p99_ms": 6915.86,
          "latency_total_ms": 114386.23,
          "accuracy": 0.7213,
          "exact_match_rate": 0.1803,
          "llm_approval_rate": 0.66,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.1803,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6502,
            "mean_kappa": 0.6502,
            "min_kappa": 0.4404,
            "max_kappa": 0.8754,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.14754098360655737,
          "total_tokens_input": 17680,
          "total_tokens_output": 717,
          "total_tokens": 18397,
          "total_cost_usd": 0.012641,
          "total_cost_input_usd": 0.011316,
          "total_cost_output_usd": 0.001336,
          "avg_cost_usd": 0.000207,
          "avg_cost_input_usd": 0.000186,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 2048.97,
          "latency_p50_ms": 1381.46,
          "latency_p95_ms": 4160.24,
          "latency_p99_ms": 10431.11,
          "latency_total_ms": 124986.91,
          "accuracy": 0.5902,
          "exact_match_rate": 0.1475,
          "llm_approval_rate": 0.5192,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.1475,
          "accuracy_boost_from_llm": 0.4426,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6332,
            "mean_kappa": 0.6332,
            "min_kappa": 0.4812,
            "max_kappa": 0.7221,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17741,
          "total_tokens_output": 813,
          "total_tokens": 18554,
          "total_cost_usd": 0.012859,
          "total_cost_input_usd": 0.011358,
          "total_cost_output_usd": 0.00151,
          "avg_cost_usd": 0.000211,
          "avg_cost_input_usd": 0.000186,
          "avg_cost_output_usd": 2.5e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 5251.92,
          "latency_p50_ms": 1592.56,
          "latency_p95_ms": 26218.93,
          "latency_p99_ms": 40426.11,
          "latency_total_ms": 320367.32,
          "accuracy": 0.623,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.5965,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6553,
            "mean_kappa": 0.6553,
            "min_kappa": 0.4894,
            "max_kappa": 0.7557,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17782,
          "total_tokens_output": 806,
          "total_tokens": 18588,
          "total_cost_usd": 0.012868,
          "total_cost_input_usd": 0.011382,
          "total_cost_output_usd": 0.001497,
          "avg_cost_usd": 0.000211,
          "avg_cost_input_usd": 0.000187,
          "avg_cost_output_usd": 2.5e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 2317.61,
          "latency_p50_ms": 1297.83,
          "latency_p95_ms": 5214.77,
          "latency_p99_ms": 21585.49,
          "latency_total_ms": 141373.97,
          "accuracy": 0.623,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.5965,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5075,
            "mean_kappa": 0.5075,
            "min_kappa": 0.3528,
            "max_kappa": 0.6776,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.18032786885245902,
          "total_tokens_input": 17776,
          "total_tokens_output": 765,
          "total_tokens": 18541,
          "total_cost_usd": 0.012794,
          "total_cost_input_usd": 0.011375,
          "total_cost_output_usd": 0.001422,
          "avg_cost_usd": 0.00021,
          "avg_cost_input_usd": 0.000186,
          "avg_cost_output_usd": 2.3e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 1875.18,
          "latency_p50_ms": 1441.89,
          "latency_p95_ms": 4203.49,
          "latency_p99_ms": 6915.86,
          "latency_total_ms": 114386.23,
          "accuracy": 0.7377,
          "exact_match_rate": 0.1803,
          "llm_approval_rate": 0.68,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.1803,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6502,
            "mean_kappa": 0.6502,
            "min_kappa": 0.4404,
            "max_kappa": 0.8754,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.14754098360655737,
          "total_tokens_input": 17680,
          "total_tokens_output": 717,
          "total_tokens": 18397,
          "total_cost_usd": 0.012641,
          "total_cost_input_usd": 0.011316,
          "total_cost_output_usd": 0.001336,
          "avg_cost_usd": 0.000207,
          "avg_cost_input_usd": 0.000186,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 2048.97,
          "latency_p50_ms": 1381.46,
          "latency_p95_ms": 4160.24,
          "latency_p99_ms": 10431.11,
          "latency_total_ms": 124986.91,
          "accuracy": 0.8197,
          "exact_match_rate": 0.1475,
          "llm_approval_rate": 0.7885,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 50,
          "incorrect": 11,
          "accuracy_from_exact_match": 0.1475,
          "accuracy_boost_from_llm": 0.6721,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6332,
            "mean_kappa": 0.6332,
            "min_kappa": 0.4812,
            "max_kappa": 0.7221,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17741,
          "total_tokens_output": 813,
          "total_tokens": 18554,
          "total_cost_usd": 0.012859,
          "total_cost_input_usd": 0.011358,
          "total_cost_output_usd": 0.00151,
          "avg_cost_usd": 0.000211,
          "avg_cost_input_usd": 0.000186,
          "avg_cost_output_usd": 2.5e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 5251.92,
          "latency_p50_ms": 1592.56,
          "latency_p95_ms": 26218.93,
          "latency_p99_ms": 40426.11,
          "latency_total_ms": 320367.32,
          "accuracy": 0.8361,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.8246,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 51,
          "incorrect": 10,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.7705,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6553,
            "mean_kappa": 0.6553,
            "min_kappa": 0.4894,
            "max_kappa": 0.7557,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed44__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17782,
          "total_tokens_output": 806,
          "total_tokens": 18588,
          "total_cost_usd": 0.012868,
          "total_cost_input_usd": 0.011382,
          "total_cost_output_usd": 0.001497,
          "avg_cost_usd": 0.000211,
          "avg_cost_input_usd": 0.000187,
          "avg_cost_output_usd": 2.5e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 2317.61,
          "latency_p50_ms": 1297.83,
          "latency_p95_ms": 5214.77,
          "latency_p99_ms": 21585.49,
          "latency_total_ms": 141373.97,
          "accuracy": 0.8852,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.8772,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 54,
          "incorrect": 7,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.8197,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5075,
            "mean_kappa": 0.5075,
            "min_kappa": 0.3528,
            "max_kappa": 0.6776,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed45__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.18032786885245902,
          "total_tokens_input": 17776,
          "total_tokens_output": 765,
          "total_tokens": 18541,
          "total_cost_usd": 0.012794,
          "total_cost_input_usd": 0.011375,
          "total_cost_output_usd": 0.001422,
          "avg_cost_usd": 0.00021,
          "avg_cost_input_usd": 0.000186,
          "avg_cost_output_usd": 2.3e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 1875.18,
          "latency_p50_ms": 1441.89,
          "latency_p95_ms": 4203.49,
          "latency_p99_ms": 6915.86,
          "latency_total_ms": 114386.23,
          "accuracy": 0.9016,
          "exact_match_rate": 0.1803,
          "llm_approval_rate": 0.88,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 55,
          "incorrect": 6,
          "accuracy_from_exact_match": 0.1803,
          "accuracy_boost_from_llm": 0.7213,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6502,
            "mean_kappa": 0.6502,
            "min_kappa": 0.4404,
            "max_kappa": 0.8754,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_few_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.61155,
        "std": 0.060627984462622554
      },
      "mean_kappa": {
        "mean": 0.61155,
        "std": 0.060627984462622554
      },
      "min_kappa": {
        "mean": 0.44095,
        "std": 0.05417146389013316
      },
      "max_kappa": {
        "mean": 0.7577,
        "std": 0.07338368347255403
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "ds-v3.2",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 20,
    "metrics": {
      "accuracy": {
        "mean": 0.6287,
        "std": 0.1251989576633927
      },
      "exact_match": {
        "mean": 0.04262295081967213,
        "std": 0.013114754098360656
      },
      "exact_match_rate": {
        "mean": 0.04264,
        "std": 0.01312
      },
      "llm_approval_rate": {
        "mean": 0.611835,
        "std": 0.13138688014790517
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 38.35,
        "std": 7.63724426740431
      },
      "incorrect": {
        "mean": 22.65,
        "std": 7.63724426740431
      },
      "accuracy_from_exact_match": {
        "mean": 0.04264,
        "std": 0.01312
      },
      "accuracy_boost_from_llm": {
        "mean": 0.58607,
        "std": 0.1277181823390859
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 8716.4,
        "std": 36.257964642268604
      },
      "total_tokens_output": {
        "mean": 733.4,
        "std": 34.575135574571505
      },
      "total_tokens": {
        "mean": 9449.8,
        "std": 68.9504169675572
      },
      "latency_mean_ms": {
        "mean": 3508.9480000000003,
        "std": 1136.6056041107663
      },
      "latency_p50_ms": {
        "mean": 1516.742,
        "std": 135.57881566085467
      },
      "latency_p95_ms": {
        "mean": 11993.406,
        "std": 8482.52839987135
      },
      "latency_p99_ms": {
        "mean": 24748.88,
        "std": 8748.168483034606
      },
      "latency_total_ms": {
        "mean": 214045.788,
        "std": 69333.07682920106
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8715,
          "total_tokens_output": 737,
          "total_tokens": 9452,
          "total_cost_usd": 0.006942,
          "total_cost_input_usd": 0.005579,
          "total_cost_output_usd": 0.001365,
          "avg_cost_usd": 0.000114,
          "avg_cost_input_usd": 9.1e-05,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 3651.55,
          "latency_p50_ms": 1710.16,
          "latency_p95_ms": 8393.53,
          "latency_p99_ms": 29521.6,
          "latency_total_ms": 222744.38,
          "accuracy": 0.5902,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.569,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.55,
            "mean_kappa": 0.55,
            "min_kappa": 0.2533,
            "max_kappa": 0.7967,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8652,
          "total_tokens_output": 676,
          "total_tokens": 9328,
          "total_cost_usd": 0.006789,
          "total_cost_input_usd": 0.005542,
          "total_cost_output_usd": 0.001254,
          "avg_cost_usd": 0.000111,
          "avg_cost_input_usd": 9.1e-05,
          "avg_cost_output_usd": 2.1e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 1826.47,
          "latency_p50_ms": 1332.01,
          "latency_p95_ms": 2537.95,
          "latency_p99_ms": 10180.9,
          "latency_total_ms": 111414.54,
          "accuracy": 0.541,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.5172,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 33,
          "incorrect": 28,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4918,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5246,
            "mean_kappa": 0.5246,
            "min_kappa": 0.3175,
            "max_kappa": 0.7388,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8713,
          "total_tokens_output": 736,
          "total_tokens": 9449,
          "total_cost_usd": 0.006936,
          "total_cost_input_usd": 0.005577,
          "total_cost_output_usd": 0.001359,
          "avg_cost_usd": 0.000114,
          "avg_cost_input_usd": 9.1e-05,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 4738.31,
          "latency_p50_ms": 1489.29,
          "latency_p95_ms": 16053.61,
          "latency_p99_ms": 33944.75,
          "latency_total_ms": 289037.08,
          "accuracy": 0.6393,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.6207,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.5902,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4917,
            "mean_kappa": 0.4917,
            "min_kappa": 0.3021,
            "max_kappa": 0.6514,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8754,
          "total_tokens_output": 785,
          "total_tokens": 9539,
          "total_cost_usd": 0.00706,
          "total_cost_input_usd": 0.005601,
          "total_cost_output_usd": 0.001456,
          "avg_cost_usd": 0.000116,
          "avg_cost_input_usd": 9.2e-05,
          "avg_cost_output_usd": 2.4e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 2652.09,
          "latency_p50_ms": 1427.53,
          "latency_p95_ms": 6479.47,
          "latency_p99_ms": 19440.38,
          "latency_total_ms": 161777.27,
          "accuracy": 0.5738,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.5517,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.5246,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6782,
            "mean_kappa": 0.6782,
            "min_kappa": 0.4255,
            "max_kappa": 0.9009,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8748,
          "total_tokens_output": 733,
          "total_tokens": 9481,
          "total_cost_usd": 0.006956,
          "total_cost_input_usd": 0.005602,
          "total_cost_output_usd": 0.001358,
          "avg_cost_usd": 0.000114,
          "avg_cost_input_usd": 9.2e-05,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 4676.32,
          "latency_p50_ms": 1624.72,
          "latency_p95_ms": 26502.47,
          "latency_p99_ms": 30656.77,
          "latency_total_ms": 285255.67,
          "accuracy": 0.6721,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.6667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5375,
            "mean_kappa": 0.5375,
            "min_kappa": 0.2651,
            "max_kappa": 0.7683,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8715,
          "total_tokens_output": 737,
          "total_tokens": 9452,
          "total_cost_usd": 0.006942,
          "total_cost_input_usd": 0.005579,
          "total_cost_output_usd": 0.001365,
          "avg_cost_usd": 0.000114,
          "avg_cost_input_usd": 9.1e-05,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 3651.55,
          "latency_p50_ms": 1710.16,
          "latency_p95_ms": 8393.53,
          "latency_p99_ms": 29521.6,
          "latency_total_ms": 222744.38,
          "accuracy": 0.5902,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.569,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.55,
            "mean_kappa": 0.55,
            "min_kappa": 0.2533,
            "max_kappa": 0.7967,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8652,
          "total_tokens_output": 676,
          "total_tokens": 9328,
          "total_cost_usd": 0.006789,
          "total_cost_input_usd": 0.005542,
          "total_cost_output_usd": 0.001254,
          "avg_cost_usd": 0.000111,
          "avg_cost_input_usd": 9.1e-05,
          "avg_cost_output_usd": 2.1e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 1826.47,
          "latency_p50_ms": 1332.01,
          "latency_p95_ms": 2537.95,
          "latency_p99_ms": 10180.9,
          "latency_total_ms": 111414.54,
          "accuracy": 0.4918,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.4655,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 30,
          "incorrect": 31,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4426,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5246,
            "mean_kappa": 0.5246,
            "min_kappa": 0.3175,
            "max_kappa": 0.7388,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8713,
          "total_tokens_output": 736,
          "total_tokens": 9449,
          "total_cost_usd": 0.006936,
          "total_cost_input_usd": 0.005577,
          "total_cost_output_usd": 0.001359,
          "avg_cost_usd": 0.000114,
          "avg_cost_input_usd": 9.1e-05,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 4738.31,
          "latency_p50_ms": 1489.29,
          "latency_p95_ms": 16053.61,
          "latency_p99_ms": 33944.75,
          "latency_total_ms": 289037.08,
          "accuracy": 0.6066,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.5862,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4917,
            "mean_kappa": 0.4917,
            "min_kappa": 0.3021,
            "max_kappa": 0.6514,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8754,
          "total_tokens_output": 785,
          "total_tokens": 9539,
          "total_cost_usd": 0.00706,
          "total_cost_input_usd": 0.005601,
          "total_cost_output_usd": 0.001456,
          "avg_cost_usd": 0.000116,
          "avg_cost_input_usd": 9.2e-05,
          "avg_cost_output_usd": 2.4e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 2652.09,
          "latency_p50_ms": 1427.53,
          "latency_p95_ms": 6479.47,
          "latency_p99_ms": 19440.38,
          "latency_total_ms": 161777.27,
          "accuracy": 0.6066,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.5862,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6782,
            "mean_kappa": 0.6782,
            "min_kappa": 0.4255,
            "max_kappa": 0.9009,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8748,
          "total_tokens_output": 733,
          "total_tokens": 9481,
          "total_cost_usd": 0.006956,
          "total_cost_input_usd": 0.005602,
          "total_cost_output_usd": 0.001358,
          "avg_cost_usd": 0.000114,
          "avg_cost_input_usd": 9.2e-05,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 4676.32,
          "latency_p50_ms": 1624.72,
          "latency_p95_ms": 26502.47,
          "latency_p99_ms": 30656.77,
          "latency_total_ms": 285255.67,
          "accuracy": 0.541,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.5333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 33,
          "incorrect": 28,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.5246,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5375,
            "mean_kappa": 0.5375,
            "min_kappa": 0.2651,
            "max_kappa": 0.7683,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8715,
          "total_tokens_output": 737,
          "total_tokens": 9452,
          "total_cost_usd": 0.006942,
          "total_cost_input_usd": 0.005579,
          "total_cost_output_usd": 0.001365,
          "avg_cost_usd": 0.000114,
          "avg_cost_input_usd": 9.1e-05,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 3651.55,
          "latency_p50_ms": 1710.16,
          "latency_p95_ms": 8393.53,
          "latency_p99_ms": 29521.6,
          "latency_total_ms": 222744.38,
          "accuracy": 0.4918,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.4655,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 30,
          "incorrect": 31,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4426,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.55,
            "mean_kappa": 0.55,
            "min_kappa": 0.2533,
            "max_kappa": 0.7967,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8652,
          "total_tokens_output": 676,
          "total_tokens": 9328,
          "total_cost_usd": 0.006789,
          "total_cost_input_usd": 0.005542,
          "total_cost_output_usd": 0.001254,
          "avg_cost_usd": 0.000111,
          "avg_cost_input_usd": 9.1e-05,
          "avg_cost_output_usd": 2.1e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 1826.47,
          "latency_p50_ms": 1332.01,
          "latency_p95_ms": 2537.95,
          "latency_p99_ms": 10180.9,
          "latency_total_ms": 111414.54,
          "accuracy": 0.4754,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.4483,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4262,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5246,
            "mean_kappa": 0.5246,
            "min_kappa": 0.3175,
            "max_kappa": 0.7388,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8713,
          "total_tokens_output": 736,
          "total_tokens": 9449,
          "total_cost_usd": 0.006936,
          "total_cost_input_usd": 0.005577,
          "total_cost_output_usd": 0.001359,
          "avg_cost_usd": 0.000114,
          "avg_cost_input_usd": 9.1e-05,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 4738.31,
          "latency_p50_ms": 1489.29,
          "latency_p95_ms": 16053.61,
          "latency_p99_ms": 33944.75,
          "latency_total_ms": 289037.08,
          "accuracy": 0.541,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.5172,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 33,
          "incorrect": 28,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4918,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4917,
            "mean_kappa": 0.4917,
            "min_kappa": 0.3021,
            "max_kappa": 0.6514,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8754,
          "total_tokens_output": 785,
          "total_tokens": 9539,
          "total_cost_usd": 0.00706,
          "total_cost_input_usd": 0.005601,
          "total_cost_output_usd": 0.001456,
          "avg_cost_usd": 0.000116,
          "avg_cost_input_usd": 9.2e-05,
          "avg_cost_output_usd": 2.4e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 2652.09,
          "latency_p50_ms": 1427.53,
          "latency_p95_ms": 6479.47,
          "latency_p99_ms": 19440.38,
          "latency_total_ms": 161777.27,
          "accuracy": 0.5246,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.5,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 32,
          "incorrect": 29,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4754,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6782,
            "mean_kappa": 0.6782,
            "min_kappa": 0.4255,
            "max_kappa": 0.9009,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8748,
          "total_tokens_output": 733,
          "total_tokens": 9481,
          "total_cost_usd": 0.006956,
          "total_cost_input_usd": 0.005602,
          "total_cost_output_usd": 0.001358,
          "avg_cost_usd": 0.000114,
          "avg_cost_input_usd": 9.2e-05,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 4676.32,
          "latency_p50_ms": 1624.72,
          "latency_p95_ms": 26502.47,
          "latency_p99_ms": 30656.77,
          "latency_total_ms": 285255.67,
          "accuracy": 0.5574,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.55,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5375,
            "mean_kappa": 0.5375,
            "min_kappa": 0.2651,
            "max_kappa": 0.7683,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8715,
          "total_tokens_output": 737,
          "total_tokens": 9452,
          "total_cost_usd": 0.006942,
          "total_cost_input_usd": 0.005579,
          "total_cost_output_usd": 0.001365,
          "avg_cost_usd": 0.000114,
          "avg_cost_input_usd": 9.1e-05,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 3651.55,
          "latency_p50_ms": 1710.16,
          "latency_p95_ms": 8393.53,
          "latency_p99_ms": 29521.6,
          "latency_total_ms": 222744.38,
          "accuracy": 0.8033,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.7931,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.7541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.55,
            "mean_kappa": 0.55,
            "min_kappa": 0.2533,
            "max_kappa": 0.7967,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8652,
          "total_tokens_output": 676,
          "total_tokens": 9328,
          "total_cost_usd": 0.006789,
          "total_cost_input_usd": 0.005542,
          "total_cost_output_usd": 0.001254,
          "avg_cost_usd": 0.000111,
          "avg_cost_input_usd": 9.1e-05,
          "avg_cost_output_usd": 2.1e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 1826.47,
          "latency_p50_ms": 1332.01,
          "latency_p95_ms": 2537.95,
          "latency_p99_ms": 10180.9,
          "latency_total_ms": 111414.54,
          "accuracy": 0.7705,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.7586,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.7213,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5246,
            "mean_kappa": 0.5246,
            "min_kappa": 0.3175,
            "max_kappa": 0.7388,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8713,
          "total_tokens_output": 736,
          "total_tokens": 9449,
          "total_cost_usd": 0.006936,
          "total_cost_input_usd": 0.005577,
          "total_cost_output_usd": 0.001359,
          "avg_cost_usd": 0.000114,
          "avg_cost_input_usd": 9.1e-05,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 4738.31,
          "latency_p50_ms": 1489.29,
          "latency_p95_ms": 16053.61,
          "latency_p99_ms": 33944.75,
          "latency_total_ms": 289037.08,
          "accuracy": 0.8689,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.8621,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 53,
          "incorrect": 8,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.8197,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4917,
            "mean_kappa": 0.4917,
            "min_kappa": 0.3021,
            "max_kappa": 0.6514,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed44__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8754,
          "total_tokens_output": 785,
          "total_tokens": 9539,
          "total_cost_usd": 0.00706,
          "total_cost_input_usd": 0.005601,
          "total_cost_output_usd": 0.001456,
          "avg_cost_usd": 0.000116,
          "avg_cost_input_usd": 9.2e-05,
          "avg_cost_output_usd": 2.4e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 2652.09,
          "latency_p50_ms": 1427.53,
          "latency_p95_ms": 6479.47,
          "latency_p99_ms": 19440.38,
          "latency_total_ms": 161777.27,
          "accuracy": 0.8033,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.7931,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.7541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6782,
            "mean_kappa": 0.6782,
            "min_kappa": 0.4255,
            "max_kappa": 0.9009,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed45__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8748,
          "total_tokens_output": 733,
          "total_tokens": 9481,
          "total_cost_usd": 0.006956,
          "total_cost_input_usd": 0.005602,
          "total_cost_output_usd": 0.001358,
          "avg_cost_usd": 0.000114,
          "avg_cost_input_usd": 9.2e-05,
          "avg_cost_output_usd": 2.2e-05,
          "price_input_per_1k": 0.00064,
          "price_output_per_1k": 0.00185,
          "price_input_per_token": 6.4e-07,
          "price_output_per_token": 1.85e-06,
          "latency_mean_ms": 4676.32,
          "latency_p50_ms": 1624.72,
          "latency_p95_ms": 26502.47,
          "latency_p99_ms": 30656.77,
          "latency_total_ms": 285255.67,
          "accuracy": 0.8852,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.8833,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 54,
          "incorrect": 7,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.8689,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5375,
            "mean_kappa": 0.5375,
            "min_kappa": 0.2651,
            "max_kappa": 0.7683,
            "n_items": 61
          }
        },
        "source": "ds-v3.2_baseline_zero_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.5564,
        "std": 0.06392298491153242
      },
      "mean_kappa": {
        "mean": 0.5564,
        "std": 0.06392298491153242
      },
      "min_kappa": {
        "mean": 0.3127,
        "std": 0.061079227238071694
      },
      "max_kappa": {
        "mean": 0.77122,
        "std": 0.0810956817592651
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "gemma3-27b",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.70389375,
        "std": 0.10786944347653557
      },
      "exact_match": {
        "mean": 0.13114754098360656,
        "std": 0.04015556955382259
      },
      "exact_match_rate": {
        "mean": 0.131125,
        "std": 0.04013080954827599
      },
      "llm_approval_rate": {
        "mean": 0.6580625,
        "std": 0.12527840433909587
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 42.9375,
        "std": 6.580926511517964
      },
      "incorrect": {
        "mean": 18.0625,
        "std": 6.580926511517964
      },
      "accuracy_from_exact_match": {
        "mean": 0.131125,
        "std": 0.04013080954827599
      },
      "accuracy_boost_from_llm": {
        "mean": 0.5727375,
        "std": 0.11771783995533558
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 19147.75,
        "std": 43.3265219005634
      },
      "total_tokens_output": {
        "mean": 15616,
        "std": 0.0
      },
      "total_tokens": {
        "mean": 34763.75,
        "std": 43.3265219005634
      },
      "latency_mean_ms": {
        "mean": 34038.3225,
        "std": 491.51852261003313
      },
      "latency_p50_ms": {
        "mean": 34027.0375,
        "std": 488.49434077453714
      },
      "latency_p95_ms": {
        "mean": 34230.0775,
        "std": 582.8823277203978
      },
      "latency_p99_ms": {
        "mean": 34460.9325,
        "std": 529.8263963023634
      },
      "latency_total_ms": {
        "mean": 2076337.715,
        "std": 29982.51791610449
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.16393442622950818,
          "total_tokens_input": 19141,
          "total_tokens_output": 15616,
          "total_tokens": 34757,
          "latency_mean_ms": 33225.79,
          "latency_p50_ms": 33213.53,
          "latency_p95_ms": 33274.11,
          "latency_p99_ms": 33572.33,
          "latency_total_ms": 2026773.49,
          "accuracy": 0.7213,
          "exact_match_rate": 0.1639,
          "llm_approval_rate": 0.6667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.1639,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6897,
            "mean_kappa": 0.6897,
            "min_kappa": 0.4714,
            "max_kappa": 0.8066,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.16393442622950818,
          "total_tokens_input": 19080,
          "total_tokens_output": 15616,
          "total_tokens": 34696,
          "latency_mean_ms": 34165.39,
          "latency_p50_ms": 34169.34,
          "latency_p95_ms": 34393.27,
          "latency_p99_ms": 34634.01,
          "latency_total_ms": 2084088.52,
          "accuracy": 0.6721,
          "exact_match_rate": 0.1639,
          "llm_approval_rate": 0.6078,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.1639,
          "accuracy_boost_from_llm": 0.5082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5793,
            "mean_kappa": 0.5793,
            "min_kappa": 0.4238,
            "max_kappa": 0.7619,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 19192,
          "total_tokens_output": 15616,
          "total_tokens": 34808,
          "latency_mean_ms": 34215.11,
          "latency_p50_ms": 34209.01,
          "latency_p95_ms": 34398.15,
          "latency_p99_ms": 34664.9,
          "latency_total_ms": 2087121.75,
          "accuracy": 0.7377,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.7193,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.6721,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5031,
            "mean_kappa": 0.5031,
            "min_kappa": 0.2232,
            "max_kappa": 0.7642,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 19178,
          "total_tokens_output": 15616,
          "total_tokens": 34794,
          "latency_mean_ms": 34547.0,
          "latency_p50_ms": 34516.27,
          "latency_p95_ms": 34854.78,
          "latency_p99_ms": 34972.49,
          "latency_total_ms": 2107367.1,
          "accuracy": 0.7869,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.7547,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 48,
          "incorrect": 13,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5662,
            "mean_kappa": 0.5662,
            "min_kappa": 0.2907,
            "max_kappa": 0.8514,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.16393442622950818,
          "total_tokens_input": 19141,
          "total_tokens_output": 15616,
          "total_tokens": 34757,
          "latency_mean_ms": 33225.79,
          "latency_p50_ms": 33213.53,
          "latency_p95_ms": 33274.11,
          "latency_p99_ms": 33572.33,
          "latency_total_ms": 2026773.49,
          "accuracy": 0.6721,
          "exact_match_rate": 0.1639,
          "llm_approval_rate": 0.6078,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.1639,
          "accuracy_boost_from_llm": 0.5082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6897,
            "mean_kappa": 0.6897,
            "min_kappa": 0.4714,
            "max_kappa": 0.8066,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.16393442622950818,
          "total_tokens_input": 19080,
          "total_tokens_output": 15616,
          "total_tokens": 34696,
          "latency_mean_ms": 34165.39,
          "latency_p50_ms": 34169.34,
          "latency_p95_ms": 34393.27,
          "latency_p99_ms": 34634.01,
          "latency_total_ms": 2084088.52,
          "accuracy": 0.623,
          "exact_match_rate": 0.1639,
          "llm_approval_rate": 0.549,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.1639,
          "accuracy_boost_from_llm": 0.459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5793,
            "mean_kappa": 0.5793,
            "min_kappa": 0.4238,
            "max_kappa": 0.7619,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 19192,
          "total_tokens_output": 15616,
          "total_tokens": 34808,
          "latency_mean_ms": 34215.11,
          "latency_p50_ms": 34209.01,
          "latency_p95_ms": 34398.15,
          "latency_p99_ms": 34664.9,
          "latency_total_ms": 2087121.75,
          "accuracy": 0.5902,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.5614,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.5246,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5031,
            "mean_kappa": 0.5031,
            "min_kappa": 0.2232,
            "max_kappa": 0.7642,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 19178,
          "total_tokens_output": 15616,
          "total_tokens": 34794,
          "latency_mean_ms": 34547.0,
          "latency_p50_ms": 34516.27,
          "latency_p95_ms": 34854.78,
          "latency_p99_ms": 34972.49,
          "latency_total_ms": 2107367.1,
          "accuracy": 0.6885,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.6415,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5662,
            "mean_kappa": 0.5662,
            "min_kappa": 0.2907,
            "max_kappa": 0.8514,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.16393442622950818,
          "total_tokens_input": 19141,
          "total_tokens_output": 15616,
          "total_tokens": 34757,
          "latency_mean_ms": 33225.79,
          "latency_p50_ms": 33213.53,
          "latency_p95_ms": 33274.11,
          "latency_p99_ms": 33572.33,
          "latency_total_ms": 2026773.49,
          "accuracy": 0.5574,
          "exact_match_rate": 0.1639,
          "llm_approval_rate": 0.4706,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.1639,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6897,
            "mean_kappa": 0.6897,
            "min_kappa": 0.4714,
            "max_kappa": 0.8066,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.16393442622950818,
          "total_tokens_input": 19080,
          "total_tokens_output": 15616,
          "total_tokens": 34696,
          "latency_mean_ms": 34165.39,
          "latency_p50_ms": 34169.34,
          "latency_p95_ms": 34393.27,
          "latency_p99_ms": 34634.01,
          "latency_total_ms": 2084088.52,
          "accuracy": 0.5738,
          "exact_match_rate": 0.1639,
          "llm_approval_rate": 0.4902,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.1639,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5793,
            "mean_kappa": 0.5793,
            "min_kappa": 0.4238,
            "max_kappa": 0.7619,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 19192,
          "total_tokens_output": 15616,
          "total_tokens": 34808,
          "latency_mean_ms": 34215.11,
          "latency_p50_ms": 34209.01,
          "latency_p95_ms": 34398.15,
          "latency_p99_ms": 34664.9,
          "latency_total_ms": 2087121.75,
          "accuracy": 0.5738,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.5439,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.5082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5031,
            "mean_kappa": 0.5031,
            "min_kappa": 0.2232,
            "max_kappa": 0.7642,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 19178,
          "total_tokens_output": 15616,
          "total_tokens": 34794,
          "latency_mean_ms": 34547.0,
          "latency_p50_ms": 34516.27,
          "latency_p95_ms": 34854.78,
          "latency_p99_ms": 34972.49,
          "latency_total_ms": 2107367.1,
          "accuracy": 0.6557,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.6038,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.5246,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5662,
            "mean_kappa": 0.5662,
            "min_kappa": 0.2907,
            "max_kappa": 0.8514,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.16393442622950818,
          "total_tokens_input": 19141,
          "total_tokens_output": 15616,
          "total_tokens": 34757,
          "latency_mean_ms": 33225.79,
          "latency_p50_ms": 33213.53,
          "latency_p95_ms": 33274.11,
          "latency_p99_ms": 33572.33,
          "latency_total_ms": 2026773.49,
          "accuracy": 0.8033,
          "exact_match_rate": 0.1639,
          "llm_approval_rate": 0.7647,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.1639,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6897,
            "mean_kappa": 0.6897,
            "min_kappa": 0.4714,
            "max_kappa": 0.8066,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.16393442622950818,
          "total_tokens_input": 19080,
          "total_tokens_output": 15616,
          "total_tokens": 34696,
          "latency_mean_ms": 34165.39,
          "latency_p50_ms": 34169.34,
          "latency_p95_ms": 34393.27,
          "latency_p99_ms": 34634.01,
          "latency_total_ms": 2084088.52,
          "accuracy": 0.8033,
          "exact_match_rate": 0.1639,
          "llm_approval_rate": 0.7647,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.1639,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5793,
            "mean_kappa": 0.5793,
            "min_kappa": 0.4238,
            "max_kappa": 0.7619,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 19192,
          "total_tokens_output": 15616,
          "total_tokens": 34808,
          "latency_mean_ms": 34215.11,
          "latency_p50_ms": 34209.01,
          "latency_p95_ms": 34398.15,
          "latency_p99_ms": 34664.9,
          "latency_total_ms": 2087121.75,
          "accuracy": 0.8852,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.8772,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 54,
          "incorrect": 7,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.8197,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5031,
            "mean_kappa": 0.5031,
            "min_kappa": 0.2232,
            "max_kappa": 0.7642,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed45__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 19178,
          "total_tokens_output": 15616,
          "total_tokens": 34794,
          "latency_mean_ms": 34547.0,
          "latency_p50_ms": 34516.27,
          "latency_p95_ms": 34854.78,
          "latency_p99_ms": 34972.49,
          "latency_total_ms": 2107367.1,
          "accuracy": 0.918,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.9057,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 56,
          "incorrect": 5,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.7869,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5662,
            "mean_kappa": 0.5662,
            "min_kappa": 0.2907,
            "max_kappa": 0.8514,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_few_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.5845750000000001,
        "std": 0.06718427550401954
      },
      "mean_kappa": {
        "mean": 0.5845750000000001,
        "std": 0.06718427550401954
      },
      "min_kappa": {
        "mean": 0.352275,
        "std": 0.09969757707687785
      },
      "max_kappa": {
        "mean": 0.796025,
        "std": 0.03659087147090106
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "gemma3-27b",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.461075,
        "std": 0.19984469438791716
      },
      "exact_match": {
        "mean": 0.045081967213114756,
        "std": 0.017864339932543744
      },
      "exact_match_rate": {
        "mean": 0.0451,
        "std": 0.017871485668516762
      },
      "llm_approval_rate": {
        "mean": 0.435625,
        "std": 0.2094058783200701
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 28.125,
        "std": 12.190544491531131
      },
      "incorrect": {
        "mean": 32.875,
        "std": 12.190544491531131
      },
      "accuracy_from_exact_match": {
        "mean": 0.0451,
        "std": 0.017871485668516762
      },
      "accuracy_boost_from_llm": {
        "mean": 0.415975,
        "std": 0.19967639288358552
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 9439.5,
        "std": 36.26637561157718
      },
      "total_tokens_output": {
        "mean": 15616,
        "std": 0.0
      },
      "total_tokens": {
        "mean": 25055.5,
        "std": 36.26637561157718
      },
      "latency_mean_ms": {
        "mean": 34747.585,
        "std": 951.9277852993887
      },
      "latency_p50_ms": {
        "mean": 34627.845,
        "std": 873.02522316082
      },
      "latency_p95_ms": {
        "mean": 35654.1325,
        "std": 2024.1650741401381
      },
      "latency_p99_ms": {
        "mean": 36149.6475,
        "std": 2331.2370835178367
      },
      "latency_total_ms": {
        "mean": 2119602.7824999997,
        "std": 58067.7038311704
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 9442,
          "total_tokens_output": 15616,
          "total_tokens": 25058,
          "latency_mean_ms": 33150.26,
          "latency_p50_ms": 33137.15,
          "latency_p95_ms": 33219.02,
          "latency_p99_ms": 33567.38,
          "latency_total_ms": 2022165.73,
          "accuracy": 0.4426,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.4035,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 27,
          "incorrect": 34,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4379,
            "mean_kappa": 0.4379,
            "min_kappa": 0.186,
            "max_kappa": 0.8121,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 9381,
          "total_tokens_output": 15616,
          "total_tokens": 24997,
          "latency_mean_ms": 35329.07,
          "latency_p50_ms": 35309.47,
          "latency_p95_ms": 35542.43,
          "latency_p99_ms": 35782.63,
          "latency_total_ms": 2155073.44,
          "accuracy": 0.3115,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.2759,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 19,
          "incorrect": 42,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.3962,
            "mean_kappa": 0.3962,
            "min_kappa": 0.1602,
            "max_kappa": 0.7204,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9456,
          "total_tokens_output": 15616,
          "total_tokens": 25072,
          "latency_mean_ms": 34924.5,
          "latency_p50_ms": 34900.83,
          "latency_p95_ms": 35029.7,
          "latency_p99_ms": 35323.56,
          "latency_total_ms": 2130394.78,
          "accuracy": 0.4262,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.4167,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 26,
          "incorrect": 35,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.3529,
            "mean_kappa": 0.3529,
            "min_kappa": 0.2245,
            "max_kappa": 0.4997,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 9479,
          "total_tokens_output": 15616,
          "total_tokens": 25095,
          "latency_mean_ms": 35586.51,
          "latency_p50_ms": 35163.93,
          "latency_p95_ms": 38825.38,
          "latency_p99_ms": 39925.02,
          "latency_total_ms": 2170777.18,
          "accuracy": 0.4754,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.4483,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4262,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4671,
            "mean_kappa": 0.4671,
            "min_kappa": 0.2278,
            "max_kappa": 0.7037,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 9442,
          "total_tokens_output": 15616,
          "total_tokens": 25058,
          "latency_mean_ms": 33150.26,
          "latency_p50_ms": 33137.15,
          "latency_p95_ms": 33219.02,
          "latency_p99_ms": 33567.38,
          "latency_total_ms": 2022165.73,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.2982,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4379,
            "mean_kappa": 0.4379,
            "min_kappa": 0.186,
            "max_kappa": 0.8121,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 9381,
          "total_tokens_output": 15616,
          "total_tokens": 24997,
          "latency_mean_ms": 35329.07,
          "latency_p50_ms": 35309.47,
          "latency_p95_ms": 35542.43,
          "latency_p99_ms": 35782.63,
          "latency_total_ms": 2155073.44,
          "accuracy": 0.2623,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.2241,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 16,
          "incorrect": 45,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.3962,
            "mean_kappa": 0.3962,
            "min_kappa": 0.1602,
            "max_kappa": 0.7204,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9456,
          "total_tokens_output": 15616,
          "total_tokens": 25072,
          "latency_mean_ms": 34924.5,
          "latency_p50_ms": 34900.83,
          "latency_p95_ms": 35029.7,
          "latency_p99_ms": 35323.56,
          "latency_total_ms": 2130394.78,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.3333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.3529,
            "mean_kappa": 0.3529,
            "min_kappa": 0.2245,
            "max_kappa": 0.4997,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 9479,
          "total_tokens_output": 15616,
          "total_tokens": 25095,
          "latency_mean_ms": 35586.51,
          "latency_p50_ms": 35163.93,
          "latency_p95_ms": 38825.38,
          "latency_p99_ms": 39925.02,
          "latency_total_ms": 2170777.18,
          "accuracy": 0.459,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.431,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 28,
          "incorrect": 33,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4671,
            "mean_kappa": 0.4671,
            "min_kappa": 0.2278,
            "max_kappa": 0.7037,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 9442,
          "total_tokens_output": 15616,
          "total_tokens": 25058,
          "latency_mean_ms": 33150.26,
          "latency_p50_ms": 33137.15,
          "latency_p95_ms": 33219.02,
          "latency_p99_ms": 33567.38,
          "latency_total_ms": 2022165.73,
          "accuracy": 0.2951,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.2456,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 18,
          "incorrect": 43,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4379,
            "mean_kappa": 0.4379,
            "min_kappa": 0.186,
            "max_kappa": 0.8121,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 9381,
          "total_tokens_output": 15616,
          "total_tokens": 24997,
          "latency_mean_ms": 35329.07,
          "latency_p50_ms": 35309.47,
          "latency_p95_ms": 35542.43,
          "latency_p99_ms": 35782.63,
          "latency_total_ms": 2155073.44,
          "accuracy": 0.2623,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.2241,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 16,
          "incorrect": 45,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.3962,
            "mean_kappa": 0.3962,
            "min_kappa": 0.1602,
            "max_kappa": 0.7204,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9456,
          "total_tokens_output": 15616,
          "total_tokens": 25072,
          "latency_mean_ms": 34924.5,
          "latency_p50_ms": 34900.83,
          "latency_p95_ms": 35029.7,
          "latency_p99_ms": 35323.56,
          "latency_total_ms": 2130394.78,
          "accuracy": 0.2623,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.25,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 16,
          "incorrect": 45,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.3529,
            "mean_kappa": 0.3529,
            "min_kappa": 0.2245,
            "max_kappa": 0.4997,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 9479,
          "total_tokens_output": 15616,
          "total_tokens": 25095,
          "latency_mean_ms": 35586.51,
          "latency_p50_ms": 35163.93,
          "latency_p95_ms": 38825.38,
          "latency_p99_ms": 39925.02,
          "latency_total_ms": 2170777.18,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.3103,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4671,
            "mean_kappa": 0.4671,
            "min_kappa": 0.2278,
            "max_kappa": 0.7037,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 9442,
          "total_tokens_output": 15616,
          "total_tokens": 25058,
          "latency_mean_ms": 33150.26,
          "latency_p50_ms": 33137.15,
          "latency_p95_ms": 33219.02,
          "latency_p99_ms": 33567.38,
          "latency_total_ms": 2022165.73,
          "accuracy": 0.8033,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.7895,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.7377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4379,
            "mean_kappa": 0.4379,
            "min_kappa": 0.186,
            "max_kappa": 0.8121,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 9381,
          "total_tokens_output": 15616,
          "total_tokens": 24997,
          "latency_mean_ms": 35329.07,
          "latency_p50_ms": 35309.47,
          "latency_p95_ms": 35542.43,
          "latency_p99_ms": 35782.63,
          "latency_total_ms": 2155073.44,
          "accuracy": 0.8033,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.7931,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.7541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.3962,
            "mean_kappa": 0.3962,
            "min_kappa": 0.1602,
            "max_kappa": 0.7204,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9456,
          "total_tokens_output": 15616,
          "total_tokens": 25072,
          "latency_mean_ms": 34924.5,
          "latency_p50_ms": 34900.83,
          "latency_p95_ms": 35029.7,
          "latency_p99_ms": 35323.56,
          "latency_total_ms": 2130394.78,
          "accuracy": 0.7377,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.7333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.7213,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.3529,
            "mean_kappa": 0.3529,
            "min_kappa": 0.2245,
            "max_kappa": 0.4997,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed44__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 9479,
          "total_tokens_output": 15616,
          "total_tokens": 25095,
          "latency_mean_ms": 35586.51,
          "latency_p50_ms": 35163.93,
          "latency_p95_ms": 38825.38,
          "latency_p99_ms": 39925.02,
          "latency_total_ms": 2170777.18,
          "accuracy": 0.8033,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.7931,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.7541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4671,
            "mean_kappa": 0.4671,
            "min_kappa": 0.2278,
            "max_kappa": 0.7037,
            "n_items": 61
          }
        },
        "source": "gemma3-27b_baseline_zero_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.41352500000000003,
        "std": 0.04312762310862959
      },
      "mean_kappa": {
        "mean": 0.41352500000000003,
        "std": 0.04312762310862959
      },
      "min_kappa": {
        "mean": 0.199625,
        "std": 0.028073864625305863
      },
      "max_kappa": {
        "mean": 0.683975,
        "std": 0.11411523506964355
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "gpt-4.1",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 20,
    "metrics": {
      "accuracy": {
        "mean": 0.727055,
        "std": 0.10227380639733716
      },
      "exact_match": {
        "mean": 0.08196721311475409,
        "std": 0.03738280082292256
      },
      "exact_match_rate": {
        "mean": 0.08198,
        "std": 0.037362676563651054
      },
      "llm_approval_rate": {
        "mean": 0.703845,
        "std": 0.10649663128475004
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 44.35,
        "std": 6.239190652640773
      },
      "incorrect": {
        "mean": 16.65,
        "std": 6.239190652640773
      },
      "accuracy_from_exact_match": {
        "mean": 0.08198,
        "std": 0.037362676563651054
      },
      "accuracy_boost_from_llm": {
        "mean": 0.645085,
        "std": 0.09575526760967253
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 17744.4,
        "std": 36.257964642268604
      },
      "total_tokens_output": {
        "mean": 803.8,
        "std": 45.91034741754848
      },
      "total_tokens": {
        "mean": 18548.2,
        "std": 76.61435896749381
      },
      "latency_mean_ms": {
        "mean": 1421.508,
        "std": 28.56150584265474
      },
      "latency_p50_ms": {
        "mean": 1368.196,
        "std": 14.926472590669231
      },
      "latency_p95_ms": {
        "mean": 1995.612,
        "std": 277.9441971619484
      },
      "latency_p99_ms": {
        "mean": 2421.6440000000002,
        "std": 115.48478663443076
      },
      "latency_total_ms": {
        "mean": 86711.95999999999,
        "std": 1742.157476062369
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 17743,
          "total_tokens_output": 758,
          "total_tokens": 18501,
          "total_cost_usd": 0.045704,
          "total_cost_input_usd": 0.039033,
          "total_cost_output_usd": 0.006669,
          "avg_cost_usd": 0.000749,
          "avg_cost_input_usd": 0.00064,
          "avg_cost_output_usd": 0.000109,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1403.24,
          "latency_p50_ms": 1379.07,
          "latency_p95_ms": 1656.95,
          "latency_p99_ms": 2263.32,
          "latency_total_ms": 85597.42,
          "accuracy": 0.7377,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.7143,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5921,
            "mean_kappa": 0.5921,
            "min_kappa": 0.4447,
            "max_kappa": 0.7093,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 17680,
          "total_tokens_output": 749,
          "total_tokens": 18429,
          "total_cost_usd": 0.045489,
          "total_cost_input_usd": 0.038894,
          "total_cost_output_usd": 0.006588,
          "avg_cost_usd": 0.000746,
          "avg_cost_input_usd": 0.000638,
          "avg_cost_output_usd": 0.000108,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1447.52,
          "latency_p50_ms": 1386.25,
          "latency_p95_ms": 2073.65,
          "latency_p99_ms": 2343.29,
          "latency_total_ms": 88298.51,
          "accuracy": 0.7049,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.6786,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6457,
            "mean_kappa": 0.6457,
            "min_kappa": 0.5214,
            "max_kappa": 0.7916,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17741,
          "total_tokens_output": 834,
          "total_tokens": 18575,
          "total_cost_usd": 0.046369,
          "total_cost_input_usd": 0.039031,
          "total_cost_output_usd": 0.007336,
          "avg_cost_usd": 0.00076,
          "avg_cost_input_usd": 0.00064,
          "avg_cost_output_usd": 0.00012,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1455.48,
          "latency_p50_ms": 1374.6,
          "latency_p95_ms": 2137.31,
          "latency_p99_ms": 2517.12,
          "latency_total_ms": 88784.3,
          "accuracy": 0.7213,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.7018,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5873,
            "mean_kappa": 0.5873,
            "min_kappa": 0.3654,
            "max_kappa": 0.7159,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 17782,
          "total_tokens_output": 871,
          "total_tokens": 18653,
          "total_cost_usd": 0.04679,
          "total_cost_input_usd": 0.039121,
          "total_cost_output_usd": 0.007662,
          "avg_cost_usd": 0.000767,
          "avg_cost_input_usd": 0.000641,
          "avg_cost_output_usd": 0.000126,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1423.5,
          "latency_p50_ms": 1352.05,
          "latency_p95_ms": 2400.28,
          "latency_p99_ms": 2582.78,
          "latency_total_ms": 86833.48,
          "accuracy": 0.7049,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.6949,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.6721,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4829,
            "mean_kappa": 0.4829,
            "min_kappa": 0.1904,
            "max_kappa": 0.7658,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.14754098360655737,
          "total_tokens_input": 17776,
          "total_tokens_output": 807,
          "total_tokens": 18583,
          "total_cost_usd": 0.04621,
          "total_cost_input_usd": 0.039104,
          "total_cost_output_usd": 0.0071,
          "avg_cost_usd": 0.000758,
          "avg_cost_input_usd": 0.000641,
          "avg_cost_output_usd": 0.000116,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1377.8,
          "latency_p50_ms": 1349.01,
          "latency_p95_ms": 1709.87,
          "latency_p99_ms": 2401.71,
          "latency_total_ms": 84046.09,
          "accuracy": 0.8033,
          "exact_match_rate": 0.1475,
          "llm_approval_rate": 0.7692,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.1475,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6217,
            "mean_kappa": 0.6217,
            "min_kappa": 0.4202,
            "max_kappa": 0.8234,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 17743,
          "total_tokens_output": 758,
          "total_tokens": 18501,
          "total_cost_usd": 0.045704,
          "total_cost_input_usd": 0.039033,
          "total_cost_output_usd": 0.006669,
          "avg_cost_usd": 0.000749,
          "avg_cost_input_usd": 0.00064,
          "avg_cost_output_usd": 0.000109,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1403.24,
          "latency_p50_ms": 1379.07,
          "latency_p95_ms": 1656.95,
          "latency_p99_ms": 2263.32,
          "latency_total_ms": 85597.42,
          "accuracy": 0.7213,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.6964,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5921,
            "mean_kappa": 0.5921,
            "min_kappa": 0.4447,
            "max_kappa": 0.7093,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 17680,
          "total_tokens_output": 749,
          "total_tokens": 18429,
          "total_cost_usd": 0.045489,
          "total_cost_input_usd": 0.038894,
          "total_cost_output_usd": 0.006588,
          "avg_cost_usd": 0.000746,
          "avg_cost_input_usd": 0.000638,
          "avg_cost_output_usd": 0.000108,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1447.52,
          "latency_p50_ms": 1386.25,
          "latency_p95_ms": 2073.65,
          "latency_p99_ms": 2343.29,
          "latency_total_ms": 88298.51,
          "accuracy": 0.6557,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.625,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.5738,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6457,
            "mean_kappa": 0.6457,
            "min_kappa": 0.5214,
            "max_kappa": 0.7916,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17741,
          "total_tokens_output": 834,
          "total_tokens": 18575,
          "total_cost_usd": 0.046369,
          "total_cost_input_usd": 0.039031,
          "total_cost_output_usd": 0.007336,
          "avg_cost_usd": 0.00076,
          "avg_cost_input_usd": 0.00064,
          "avg_cost_output_usd": 0.00012,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1455.48,
          "latency_p50_ms": 1374.6,
          "latency_p95_ms": 2137.31,
          "latency_p99_ms": 2517.12,
          "latency_total_ms": 88784.3,
          "accuracy": 0.6557,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.6316,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.5902,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5873,
            "mean_kappa": 0.5873,
            "min_kappa": 0.3654,
            "max_kappa": 0.7159,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 17782,
          "total_tokens_output": 871,
          "total_tokens": 18653,
          "total_cost_usd": 0.04679,
          "total_cost_input_usd": 0.039121,
          "total_cost_output_usd": 0.007662,
          "avg_cost_usd": 0.000767,
          "avg_cost_input_usd": 0.000641,
          "avg_cost_output_usd": 0.000126,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1423.5,
          "latency_p50_ms": 1352.05,
          "latency_p95_ms": 2400.28,
          "latency_p99_ms": 2582.78,
          "latency_total_ms": 86833.48,
          "accuracy": 0.623,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.6102,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.5902,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4829,
            "mean_kappa": 0.4829,
            "min_kappa": 0.1904,
            "max_kappa": 0.7658,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.14754098360655737,
          "total_tokens_input": 17776,
          "total_tokens_output": 807,
          "total_tokens": 18583,
          "total_cost_usd": 0.04621,
          "total_cost_input_usd": 0.039104,
          "total_cost_output_usd": 0.0071,
          "avg_cost_usd": 0.000758,
          "avg_cost_input_usd": 0.000641,
          "avg_cost_output_usd": 0.000116,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1377.8,
          "latency_p50_ms": 1349.01,
          "latency_p95_ms": 1709.87,
          "latency_p99_ms": 2401.71,
          "latency_total_ms": 84046.09,
          "accuracy": 0.7377,
          "exact_match_rate": 0.1475,
          "llm_approval_rate": 0.6923,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.1475,
          "accuracy_boost_from_llm": 0.5902,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6217,
            "mean_kappa": 0.6217,
            "min_kappa": 0.4202,
            "max_kappa": 0.8234,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 17743,
          "total_tokens_output": 758,
          "total_tokens": 18501,
          "total_cost_usd": 0.045704,
          "total_cost_input_usd": 0.039033,
          "total_cost_output_usd": 0.006669,
          "avg_cost_usd": 0.000749,
          "avg_cost_input_usd": 0.00064,
          "avg_cost_output_usd": 0.000109,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1403.24,
          "latency_p50_ms": 1379.07,
          "latency_p95_ms": 1656.95,
          "latency_p99_ms": 2263.32,
          "latency_total_ms": 85597.42,
          "accuracy": 0.623,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.5893,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5921,
            "mean_kappa": 0.5921,
            "min_kappa": 0.4447,
            "max_kappa": 0.7093,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 17680,
          "total_tokens_output": 749,
          "total_tokens": 18429,
          "total_cost_usd": 0.045489,
          "total_cost_input_usd": 0.038894,
          "total_cost_output_usd": 0.006588,
          "avg_cost_usd": 0.000746,
          "avg_cost_input_usd": 0.000638,
          "avg_cost_output_usd": 0.000108,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1447.52,
          "latency_p50_ms": 1386.25,
          "latency_p95_ms": 2073.65,
          "latency_p99_ms": 2343.29,
          "latency_total_ms": 88298.51,
          "accuracy": 0.5902,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.5536,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.5082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6457,
            "mean_kappa": 0.6457,
            "min_kappa": 0.5214,
            "max_kappa": 0.7916,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17741,
          "total_tokens_output": 834,
          "total_tokens": 18575,
          "total_cost_usd": 0.046369,
          "total_cost_input_usd": 0.039031,
          "total_cost_output_usd": 0.007336,
          "avg_cost_usd": 0.00076,
          "avg_cost_input_usd": 0.00064,
          "avg_cost_output_usd": 0.00012,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1455.48,
          "latency_p50_ms": 1374.6,
          "latency_p95_ms": 2137.31,
          "latency_p99_ms": 2517.12,
          "latency_total_ms": 88784.3,
          "accuracy": 0.623,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.5965,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5873,
            "mean_kappa": 0.5873,
            "min_kappa": 0.3654,
            "max_kappa": 0.7159,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 17782,
          "total_tokens_output": 871,
          "total_tokens": 18653,
          "total_cost_usd": 0.04679,
          "total_cost_input_usd": 0.039121,
          "total_cost_output_usd": 0.007662,
          "avg_cost_usd": 0.000767,
          "avg_cost_input_usd": 0.000641,
          "avg_cost_output_usd": 0.000126,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1423.5,
          "latency_p50_ms": 1352.05,
          "latency_p95_ms": 2400.28,
          "latency_p99_ms": 2582.78,
          "latency_total_ms": 86833.48,
          "accuracy": 0.541,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.5254,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 33,
          "incorrect": 28,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.5082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4829,
            "mean_kappa": 0.4829,
            "min_kappa": 0.1904,
            "max_kappa": 0.7658,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.14754098360655737,
          "total_tokens_input": 17776,
          "total_tokens_output": 807,
          "total_tokens": 18583,
          "total_cost_usd": 0.04621,
          "total_cost_input_usd": 0.039104,
          "total_cost_output_usd": 0.0071,
          "avg_cost_usd": 0.000758,
          "avg_cost_input_usd": 0.000641,
          "avg_cost_output_usd": 0.000116,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1377.8,
          "latency_p50_ms": 1349.01,
          "latency_p95_ms": 1709.87,
          "latency_p99_ms": 2401.71,
          "latency_total_ms": 84046.09,
          "accuracy": 0.7705,
          "exact_match_rate": 0.1475,
          "llm_approval_rate": 0.7308,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.1475,
          "accuracy_boost_from_llm": 0.623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6217,
            "mean_kappa": 0.6217,
            "min_kappa": 0.4202,
            "max_kappa": 0.8234,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 17743,
          "total_tokens_output": 758,
          "total_tokens": 18501,
          "total_cost_usd": 0.045704,
          "total_cost_input_usd": 0.039033,
          "total_cost_output_usd": 0.006669,
          "avg_cost_usd": 0.000749,
          "avg_cost_input_usd": 0.00064,
          "avg_cost_output_usd": 0.000109,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1403.24,
          "latency_p50_ms": 1379.07,
          "latency_p95_ms": 1656.95,
          "latency_p99_ms": 2263.32,
          "latency_total_ms": 85597.42,
          "accuracy": 0.8525,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.8393,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 52,
          "incorrect": 9,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.7705,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5921,
            "mean_kappa": 0.5921,
            "min_kappa": 0.4447,
            "max_kappa": 0.7093,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 17680,
          "total_tokens_output": 749,
          "total_tokens": 18429,
          "total_cost_usd": 0.045489,
          "total_cost_input_usd": 0.038894,
          "total_cost_output_usd": 0.006588,
          "avg_cost_usd": 0.000746,
          "avg_cost_input_usd": 0.000638,
          "avg_cost_output_usd": 0.000108,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1447.52,
          "latency_p50_ms": 1386.25,
          "latency_p95_ms": 2073.65,
          "latency_p99_ms": 2343.29,
          "latency_total_ms": 88298.51,
          "accuracy": 0.8033,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.7857,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.7213,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6457,
            "mean_kappa": 0.6457,
            "min_kappa": 0.5214,
            "max_kappa": 0.7916,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17741,
          "total_tokens_output": 834,
          "total_tokens": 18575,
          "total_cost_usd": 0.046369,
          "total_cost_input_usd": 0.039031,
          "total_cost_output_usd": 0.007336,
          "avg_cost_usd": 0.00076,
          "avg_cost_input_usd": 0.00064,
          "avg_cost_output_usd": 0.00012,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1455.48,
          "latency_p50_ms": 1374.6,
          "latency_p95_ms": 2137.31,
          "latency_p99_ms": 2517.12,
          "latency_total_ms": 88784.3,
          "accuracy": 0.8525,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.8421,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 52,
          "incorrect": 9,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.7869,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5873,
            "mean_kappa": 0.5873,
            "min_kappa": 0.3654,
            "max_kappa": 0.7159,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed44__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 17782,
          "total_tokens_output": 871,
          "total_tokens": 18653,
          "total_cost_usd": 0.04679,
          "total_cost_input_usd": 0.039121,
          "total_cost_output_usd": 0.007662,
          "avg_cost_usd": 0.000767,
          "avg_cost_input_usd": 0.000641,
          "avg_cost_output_usd": 0.000126,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1423.5,
          "latency_p50_ms": 1352.05,
          "latency_p95_ms": 2400.28,
          "latency_p99_ms": 2582.78,
          "latency_total_ms": 86833.48,
          "accuracy": 0.918,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.9153,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 56,
          "incorrect": 5,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.8852,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4829,
            "mean_kappa": 0.4829,
            "min_kappa": 0.1904,
            "max_kappa": 0.7658,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed45__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.14754098360655737,
          "total_tokens_input": 17776,
          "total_tokens_output": 807,
          "total_tokens": 18583,
          "total_cost_usd": 0.04621,
          "total_cost_input_usd": 0.039104,
          "total_cost_output_usd": 0.0071,
          "avg_cost_usd": 0.000758,
          "avg_cost_input_usd": 0.000641,
          "avg_cost_output_usd": 0.000116,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1377.8,
          "latency_p50_ms": 1349.01,
          "latency_p95_ms": 1709.87,
          "latency_p99_ms": 2401.71,
          "latency_total_ms": 84046.09,
          "accuracy": 0.9016,
          "exact_match_rate": 0.1475,
          "llm_approval_rate": 0.8846,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 55,
          "incorrect": 6,
          "accuracy_from_exact_match": 0.1475,
          "accuracy_boost_from_llm": 0.7541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6217,
            "mean_kappa": 0.6217,
            "min_kappa": 0.4202,
            "max_kappa": 0.8234,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_few_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.58594,
        "std": 0.055690343866778215
      },
      "mean_kappa": {
        "mean": 0.58594,
        "std": 0.055690343866778215
      },
      "min_kappa": {
        "mean": 0.38842,
        "std": 0.11099813331763736
      },
      "max_kappa": {
        "mean": 0.7612,
        "std": 0.04372610204443108
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "gpt-4.1",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 20,
    "metrics": {
      "accuracy": {
        "mean": 0.70246,
        "std": 0.09812688418573169
      },
      "exact_match": {
        "mean": 0.029508196721311476,
        "std": 0.016062227821529038
      },
      "exact_match_rate": {
        "mean": 0.02952,
        "std": 0.016068652712657647
      },
      "llm_approval_rate": {
        "mean": 0.6934,
        "std": 0.10068535146683452
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 42.85,
        "std": 5.9856077385675714
      },
      "incorrect": {
        "mean": 18.15,
        "std": 5.9856077385675714
      },
      "accuracy_from_exact_match": {
        "mean": 0.02952,
        "std": 0.016068652712657647
      },
      "accuracy_boost_from_llm": {
        "mean": 0.67296,
        "std": 0.09882451821284027
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 8716.4,
        "std": 36.257964642268604
      },
      "total_tokens_output": {
        "mean": 813.8,
        "std": 36.02998751040583
      },
      "total_tokens": {
        "mean": 9530.2,
        "std": 72.20360101823177
      },
      "latency_mean_ms": {
        "mean": 1851.506,
        "std": 458.4214033659424
      },
      "latency_p50_ms": {
        "mean": 1540.74,
        "std": 22.954162149814962
      },
      "latency_p95_ms": {
        "mean": 2128.994,
        "std": 298.44191928078743
      },
      "latency_p99_ms": {
        "mean": 8724.926,
        "std": 11943.332017340219
      },
      "latency_total_ms": {
        "mean": 112941.936,
        "std": 27963.65957244695
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 8715,
          "total_tokens_output": 815,
          "total_tokens": 9530,
          "total_cost_usd": 0.026349,
          "total_cost_input_usd": 0.019173,
          "total_cost_output_usd": 0.007172,
          "avg_cost_usd": 0.000432,
          "avg_cost_input_usd": 0.000314,
          "avg_cost_output_usd": 0.000118,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1657.03,
          "latency_p50_ms": 1547.31,
          "latency_p95_ms": 2519.61,
          "latency_p99_ms": 2972.15,
          "latency_total_ms": 101078.9,
          "accuracy": 0.6393,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.6271,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.6066,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5926,
            "mean_kappa": 0.5926,
            "min_kappa": 0.3378,
            "max_kappa": 0.7948,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 8652,
          "total_tokens_output": 747,
          "total_tokens": 9399,
          "total_cost_usd": 0.02561,
          "total_cost_input_usd": 0.019034,
          "total_cost_output_usd": 0.006574,
          "avg_cost_usd": 0.00042,
          "avg_cost_input_usd": 0.000312,
          "avg_cost_output_usd": 0.000108,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1566.15,
          "latency_p50_ms": 1533.08,
          "latency_p95_ms": 1891.52,
          "latency_p99_ms": 2783.01,
          "latency_total_ms": 95535.29,
          "accuracy": 0.6557,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.6441,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5992,
            "mean_kappa": 0.5992,
            "min_kappa": 0.488,
            "max_kappa": 0.6806,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8713,
          "total_tokens_output": 816,
          "total_tokens": 9529,
          "total_cost_usd": 0.026349,
          "total_cost_input_usd": 0.019165,
          "total_cost_output_usd": 0.00718,
          "avg_cost_usd": 0.000432,
          "avg_cost_input_usd": 0.000314,
          "avg_cost_output_usd": 0.000118,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1682.39,
          "latency_p50_ms": 1574.86,
          "latency_p95_ms": 2452.94,
          "latency_p99_ms": 2899.08,
          "latency_total_ms": 102625.88,
          "accuracy": 0.7049,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.6897,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.599,
            "mean_kappa": 0.599,
            "min_kappa": 0.3992,
            "max_kappa": 0.771,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 8754,
          "total_tokens_output": 848,
          "total_tokens": 9602,
          "total_cost_usd": 0.026721,
          "total_cost_input_usd": 0.019258,
          "total_cost_output_usd": 0.007459,
          "avg_cost_usd": 0.000438,
          "avg_cost_input_usd": 0.000316,
          "avg_cost_output_usd": 0.000122,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 2764.34,
          "latency_p50_ms": 1503.94,
          "latency_p95_ms": 1796.6,
          "latency_p99_ms": 32607.86,
          "latency_total_ms": 168624.72,
          "accuracy": 0.6721,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.6721,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.6721,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5327,
            "mean_kappa": 0.5327,
            "min_kappa": 0.2561,
            "max_kappa": 0.8164,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 8748,
          "total_tokens_output": 843,
          "total_tokens": 9591,
          "total_cost_usd": 0.026665,
          "total_cost_input_usd": 0.019247,
          "total_cost_output_usd": 0.00742,
          "avg_cost_usd": 0.000437,
          "avg_cost_input_usd": 0.000316,
          "avg_cost_output_usd": 0.000122,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1587.62,
          "latency_p50_ms": 1544.51,
          "latency_p95_ms": 1984.3,
          "latency_p99_ms": 2362.53,
          "latency_total_ms": 96844.89,
          "accuracy": 0.7377,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.7288,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.7049,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7178,
            "mean_kappa": 0.7178,
            "min_kappa": 0.5438,
            "max_kappa": 0.8754,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 8715,
          "total_tokens_output": 815,
          "total_tokens": 9530,
          "total_cost_usd": 0.026349,
          "total_cost_input_usd": 0.019173,
          "total_cost_output_usd": 0.007172,
          "avg_cost_usd": 0.000432,
          "avg_cost_input_usd": 0.000314,
          "avg_cost_output_usd": 0.000118,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1657.03,
          "latency_p50_ms": 1547.31,
          "latency_p95_ms": 2519.61,
          "latency_p99_ms": 2972.15,
          "latency_total_ms": 101078.9,
          "accuracy": 0.6885,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.678,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5926,
            "mean_kappa": 0.5926,
            "min_kappa": 0.3378,
            "max_kappa": 0.7948,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 8652,
          "total_tokens_output": 747,
          "total_tokens": 9399,
          "total_cost_usd": 0.02561,
          "total_cost_input_usd": 0.019034,
          "total_cost_output_usd": 0.006574,
          "avg_cost_usd": 0.00042,
          "avg_cost_input_usd": 0.000312,
          "avg_cost_output_usd": 0.000108,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1566.15,
          "latency_p50_ms": 1533.08,
          "latency_p95_ms": 1891.52,
          "latency_p99_ms": 2783.01,
          "latency_total_ms": 95535.29,
          "accuracy": 0.623,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.6102,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.5902,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5992,
            "mean_kappa": 0.5992,
            "min_kappa": 0.488,
            "max_kappa": 0.6806,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8713,
          "total_tokens_output": 816,
          "total_tokens": 9529,
          "total_cost_usd": 0.026349,
          "total_cost_input_usd": 0.019165,
          "total_cost_output_usd": 0.00718,
          "avg_cost_usd": 0.000432,
          "avg_cost_input_usd": 0.000314,
          "avg_cost_output_usd": 0.000118,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1682.39,
          "latency_p50_ms": 1574.86,
          "latency_p95_ms": 2452.94,
          "latency_p99_ms": 2899.08,
          "latency_total_ms": 102625.88,
          "accuracy": 0.6721,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.6552,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.599,
            "mean_kappa": 0.599,
            "min_kappa": 0.3992,
            "max_kappa": 0.771,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 8754,
          "total_tokens_output": 848,
          "total_tokens": 9602,
          "total_cost_usd": 0.026721,
          "total_cost_input_usd": 0.019258,
          "total_cost_output_usd": 0.007459,
          "avg_cost_usd": 0.000438,
          "avg_cost_input_usd": 0.000316,
          "avg_cost_output_usd": 0.000122,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 2764.34,
          "latency_p50_ms": 1503.94,
          "latency_p95_ms": 1796.6,
          "latency_p99_ms": 32607.86,
          "latency_total_ms": 168624.72,
          "accuracy": 0.6557,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.6557,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5327,
            "mean_kappa": 0.5327,
            "min_kappa": 0.2561,
            "max_kappa": 0.8164,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 8748,
          "total_tokens_output": 843,
          "total_tokens": 9591,
          "total_cost_usd": 0.026665,
          "total_cost_input_usd": 0.019247,
          "total_cost_output_usd": 0.00742,
          "avg_cost_usd": 0.000437,
          "avg_cost_input_usd": 0.000316,
          "avg_cost_output_usd": 0.000122,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1587.62,
          "latency_p50_ms": 1544.51,
          "latency_p95_ms": 1984.3,
          "latency_p99_ms": 2362.53,
          "latency_total_ms": 96844.89,
          "accuracy": 0.7213,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.7119,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.6885,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7178,
            "mean_kappa": 0.7178,
            "min_kappa": 0.5438,
            "max_kappa": 0.8754,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 8715,
          "total_tokens_output": 815,
          "total_tokens": 9530,
          "total_cost_usd": 0.026349,
          "total_cost_input_usd": 0.019173,
          "total_cost_output_usd": 0.007172,
          "avg_cost_usd": 0.000432,
          "avg_cost_input_usd": 0.000314,
          "avg_cost_output_usd": 0.000118,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1657.03,
          "latency_p50_ms": 1547.31,
          "latency_p95_ms": 2519.61,
          "latency_p99_ms": 2972.15,
          "latency_total_ms": 101078.9,
          "accuracy": 0.5738,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.5593,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5926,
            "mean_kappa": 0.5926,
            "min_kappa": 0.3378,
            "max_kappa": 0.7948,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 8652,
          "total_tokens_output": 747,
          "total_tokens": 9399,
          "total_cost_usd": 0.02561,
          "total_cost_input_usd": 0.019034,
          "total_cost_output_usd": 0.006574,
          "avg_cost_usd": 0.00042,
          "avg_cost_input_usd": 0.000312,
          "avg_cost_output_usd": 0.000108,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1566.15,
          "latency_p50_ms": 1533.08,
          "latency_p95_ms": 1891.52,
          "latency_p99_ms": 2783.01,
          "latency_total_ms": 95535.29,
          "accuracy": 0.5902,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.5763,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5992,
            "mean_kappa": 0.5992,
            "min_kappa": 0.488,
            "max_kappa": 0.6806,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8713,
          "total_tokens_output": 816,
          "total_tokens": 9529,
          "total_cost_usd": 0.026349,
          "total_cost_input_usd": 0.019165,
          "total_cost_output_usd": 0.00718,
          "avg_cost_usd": 0.000432,
          "avg_cost_input_usd": 0.000314,
          "avg_cost_output_usd": 0.000118,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1682.39,
          "latency_p50_ms": 1574.86,
          "latency_p95_ms": 2452.94,
          "latency_p99_ms": 2899.08,
          "latency_total_ms": 102625.88,
          "accuracy": 0.623,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.6034,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.5738,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.599,
            "mean_kappa": 0.599,
            "min_kappa": 0.3992,
            "max_kappa": 0.771,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 8754,
          "total_tokens_output": 848,
          "total_tokens": 9602,
          "total_cost_usd": 0.026721,
          "total_cost_input_usd": 0.019258,
          "total_cost_output_usd": 0.007459,
          "avg_cost_usd": 0.000438,
          "avg_cost_input_usd": 0.000316,
          "avg_cost_output_usd": 0.000122,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 2764.34,
          "latency_p50_ms": 1503.94,
          "latency_p95_ms": 1796.6,
          "latency_p99_ms": 32607.86,
          "latency_total_ms": 168624.72,
          "accuracy": 0.5738,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.5738,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.5738,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5327,
            "mean_kappa": 0.5327,
            "min_kappa": 0.2561,
            "max_kappa": 0.8164,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 8748,
          "total_tokens_output": 843,
          "total_tokens": 9591,
          "total_cost_usd": 0.026665,
          "total_cost_input_usd": 0.019247,
          "total_cost_output_usd": 0.00742,
          "avg_cost_usd": 0.000437,
          "avg_cost_input_usd": 0.000316,
          "avg_cost_output_usd": 0.000122,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1587.62,
          "latency_p50_ms": 1544.51,
          "latency_p95_ms": 1984.3,
          "latency_p99_ms": 2362.53,
          "latency_total_ms": 96844.89,
          "accuracy": 0.6557,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.6441,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7178,
            "mean_kappa": 0.7178,
            "min_kappa": 0.5438,
            "max_kappa": 0.8754,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 8715,
          "total_tokens_output": 815,
          "total_tokens": 9530,
          "total_cost_usd": 0.026349,
          "total_cost_input_usd": 0.019173,
          "total_cost_output_usd": 0.007172,
          "avg_cost_usd": 0.000432,
          "avg_cost_input_usd": 0.000314,
          "avg_cost_output_usd": 0.000118,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1657.03,
          "latency_p50_ms": 1547.31,
          "latency_p95_ms": 2519.61,
          "latency_p99_ms": 2972.15,
          "latency_total_ms": 101078.9,
          "accuracy": 0.8689,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.8644,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 53,
          "incorrect": 8,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.8361,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5926,
            "mean_kappa": 0.5926,
            "min_kappa": 0.3378,
            "max_kappa": 0.7948,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 8652,
          "total_tokens_output": 747,
          "total_tokens": 9399,
          "total_cost_usd": 0.02561,
          "total_cost_input_usd": 0.019034,
          "total_cost_output_usd": 0.006574,
          "avg_cost_usd": 0.00042,
          "avg_cost_input_usd": 0.000312,
          "avg_cost_output_usd": 0.000108,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1566.15,
          "latency_p50_ms": 1533.08,
          "latency_p95_ms": 1891.52,
          "latency_p99_ms": 2783.01,
          "latency_total_ms": 95535.29,
          "accuracy": 0.7869,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.7797,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 48,
          "incorrect": 13,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.7541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5992,
            "mean_kappa": 0.5992,
            "min_kappa": 0.488,
            "max_kappa": 0.6806,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8713,
          "total_tokens_output": 816,
          "total_tokens": 9529,
          "total_cost_usd": 0.026349,
          "total_cost_input_usd": 0.019165,
          "total_cost_output_usd": 0.00718,
          "avg_cost_usd": 0.000432,
          "avg_cost_input_usd": 0.000314,
          "avg_cost_output_usd": 0.000118,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1682.39,
          "latency_p50_ms": 1574.86,
          "latency_p95_ms": 2452.94,
          "latency_p99_ms": 2899.08,
          "latency_total_ms": 102625.88,
          "accuracy": 0.8689,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.8621,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 53,
          "incorrect": 8,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.8197,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.599,
            "mean_kappa": 0.599,
            "min_kappa": 0.3992,
            "max_kappa": 0.771,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed44__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 8754,
          "total_tokens_output": 848,
          "total_tokens": 9602,
          "total_cost_usd": 0.026721,
          "total_cost_input_usd": 0.019258,
          "total_cost_output_usd": 0.007459,
          "avg_cost_usd": 0.000438,
          "avg_cost_input_usd": 0.000316,
          "avg_cost_output_usd": 0.000122,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 2764.34,
          "latency_p50_ms": 1503.94,
          "latency_p95_ms": 1796.6,
          "latency_p99_ms": 32607.86,
          "latency_total_ms": 168624.72,
          "accuracy": 0.9016,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.9016,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 55,
          "incorrect": 6,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.9016,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5327,
            "mean_kappa": 0.5327,
            "min_kappa": 0.2561,
            "max_kappa": 0.8164,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed45__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 8748,
          "total_tokens_output": 843,
          "total_tokens": 9591,
          "total_cost_usd": 0.026665,
          "total_cost_input_usd": 0.019247,
          "total_cost_output_usd": 0.00742,
          "avg_cost_usd": 0.000437,
          "avg_cost_input_usd": 0.000316,
          "avg_cost_output_usd": 0.000122,
          "price_input_per_1k": 0.0022,
          "price_output_per_1k": 0.0088,
          "price_input_per_token": 2.2e-06,
          "price_output_per_token": 8.8e-06,
          "latency_mean_ms": 1587.62,
          "latency_p50_ms": 1544.51,
          "latency_p95_ms": 1984.3,
          "latency_p99_ms": 2362.53,
          "latency_total_ms": 96844.89,
          "accuracy": 0.8361,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.8305,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 51,
          "incorrect": 10,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.8033,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7178,
            "mean_kappa": 0.7178,
            "min_kappa": 0.5438,
            "max_kappa": 0.8754,
            "n_items": 61
          }
        },
        "source": "gpt-4.1_baseline_zero_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.60826,
        "std": 0.06020198003388262
      },
      "mean_kappa": {
        "mean": 0.60826,
        "std": 0.06020198003388262
      },
      "min_kappa": {
        "mean": 0.40498,
        "std": 0.10283494347739973
      },
      "max_kappa": {
        "mean": 0.78764,
        "std": 0.06374115154278277
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "gpt-5.2",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 20,
    "metrics": {
      "accuracy": {
        "mean": 0.75574,
        "std": 0.08872300941694887
      },
      "exact_match": {
        "mean": 0.08524590163934427,
        "std": 0.0406874545770192
      },
      "exact_match_rate": {
        "mean": 0.08526,
        "std": 0.04068117992389109
      },
      "llm_approval_rate": {
        "mean": 0.73351,
        "std": 0.09479604896829825
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 46.1,
        "std": 5.412023651093923
      },
      "incorrect": {
        "mean": 14.9,
        "std": 5.412023651093923
      },
      "accuracy_from_exact_match": {
        "mean": 0.08526,
        "std": 0.04068117992389109
      },
      "accuracy_boost_from_llm": {
        "mean": 0.670485,
        "std": 0.08840775574009331
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 17744.4,
        "std": 36.257964642268604
      },
      "total_tokens_output": {
        "mean": 844.4,
        "std": 46.31889463275219
      },
      "total_tokens": {
        "mean": 18588.8,
        "std": 82.3587275278097
      },
      "latency_mean_ms": {
        "mean": 1865.478,
        "std": 107.67414386007442
      },
      "latency_p50_ms": {
        "mean": 1681.51,
        "std": 34.664065543441396
      },
      "latency_p95_ms": {
        "mean": 2830.564,
        "std": 506.65057602256803
      },
      "latency_p99_ms": {
        "mean": 3986.2380000000003,
        "std": 974.6895776071477
      },
      "latency_total_ms": {
        "mean": 113794.116,
        "std": 6568.229912719561
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.09836065573770492,
          "total_tokens_input": 17743,
          "total_tokens_output": 843,
          "total_tokens": 18586,
          "total_cost_usd": 0.033757,
          "total_cost_input_usd": 0.024484,
          "total_cost_output_usd": 0.009273,
          "avg_cost_usd": 0.000553,
          "avg_cost_input_usd": 0.000401,
          "avg_cost_output_usd": 0.000152,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1791.67,
          "latency_p50_ms": 1668.44,
          "latency_p95_ms": 2505.71,
          "latency_p99_ms": 3632.5,
          "latency_total_ms": 109291.64,
          "accuracy": 0.7377,
          "exact_match_rate": 0.0984,
          "llm_approval_rate": 0.7091,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.0984,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6673,
            "mean_kappa": 0.6673,
            "min_kappa": 0.5238,
            "max_kappa": 0.8432,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.11475409836065574,
          "total_tokens_input": 17680,
          "total_tokens_output": 758,
          "total_tokens": 18438,
          "total_cost_usd": 0.032734,
          "total_cost_input_usd": 0.024396,
          "total_cost_output_usd": 0.008338,
          "avg_cost_usd": 0.000537,
          "avg_cost_input_usd": 0.0004,
          "avg_cost_output_usd": 0.000137,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1758.22,
          "latency_p50_ms": 1635.34,
          "latency_p95_ms": 2396.98,
          "latency_p99_ms": 3137.61,
          "latency_total_ms": 107251.3,
          "accuracy": 0.6885,
          "exact_match_rate": 0.1148,
          "llm_approval_rate": 0.6481,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.1148,
          "accuracy_boost_from_llm": 0.5738,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6302,
            "mean_kappa": 0.6302,
            "min_kappa": 0.5065,
            "max_kappa": 0.6942,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17741,
          "total_tokens_output": 853,
          "total_tokens": 18594,
          "total_cost_usd": 0.033864,
          "total_cost_input_usd": 0.024481,
          "total_cost_output_usd": 0.009383,
          "avg_cost_usd": 0.000555,
          "avg_cost_input_usd": 0.000401,
          "avg_cost_output_usd": 0.000154,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 2009.76,
          "latency_p50_ms": 1734.2,
          "latency_p95_ms": 3742.5,
          "latency_p99_ms": 4196.34,
          "latency_total_ms": 122595.49,
          "accuracy": 0.7377,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.7193,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.6721,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6976,
            "mean_kappa": 0.6976,
            "min_kappa": 0.6048,
            "max_kappa": 0.7924,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 17782,
          "total_tokens_output": 889,
          "total_tokens": 18671,
          "total_cost_usd": 0.034318,
          "total_cost_input_usd": 0.024539,
          "total_cost_output_usd": 0.009779,
          "avg_cost_usd": 0.000563,
          "avg_cost_input_usd": 0.000402,
          "avg_cost_output_usd": 0.00016,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1785.07,
          "latency_p50_ms": 1663.48,
          "latency_p95_ms": 2483.13,
          "latency_p99_ms": 3184.61,
          "latency_total_ms": 108889.23,
          "accuracy": 0.7541,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.75,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.7377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.53,
            "mean_kappa": 0.53,
            "min_kappa": 0.2879,
            "max_kappa": 0.7877,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 17776,
          "total_tokens_output": 879,
          "total_tokens": 18655,
          "total_cost_usd": 0.034199,
          "total_cost_input_usd": 0.02453,
          "total_cost_output_usd": 0.009669,
          "avg_cost_usd": 0.000561,
          "avg_cost_input_usd": 0.000402,
          "avg_cost_output_usd": 0.000159,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1982.67,
          "latency_p50_ms": 1706.09,
          "latency_p95_ms": 3024.5,
          "latency_p99_ms": 5780.13,
          "latency_total_ms": 120942.92,
          "accuracy": 0.8525,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.8302,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 52,
          "incorrect": 9,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.7213,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7234,
            "mean_kappa": 0.7234,
            "min_kappa": 0.5344,
            "max_kappa": 0.8806,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.09836065573770492,
          "total_tokens_input": 17743,
          "total_tokens_output": 843,
          "total_tokens": 18586,
          "total_cost_usd": 0.033757,
          "total_cost_input_usd": 0.024484,
          "total_cost_output_usd": 0.009273,
          "avg_cost_usd": 0.000553,
          "avg_cost_input_usd": 0.000401,
          "avg_cost_output_usd": 0.000152,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1791.67,
          "latency_p50_ms": 1668.44,
          "latency_p95_ms": 2505.71,
          "latency_p99_ms": 3632.5,
          "latency_total_ms": 109291.64,
          "accuracy": 0.7377,
          "exact_match_rate": 0.0984,
          "llm_approval_rate": 0.7091,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.0984,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6673,
            "mean_kappa": 0.6673,
            "min_kappa": 0.5238,
            "max_kappa": 0.8432,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.11475409836065574,
          "total_tokens_input": 17680,
          "total_tokens_output": 758,
          "total_tokens": 18438,
          "total_cost_usd": 0.032734,
          "total_cost_input_usd": 0.024396,
          "total_cost_output_usd": 0.008338,
          "avg_cost_usd": 0.000537,
          "avg_cost_input_usd": 0.0004,
          "avg_cost_output_usd": 0.000137,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1758.22,
          "latency_p50_ms": 1635.34,
          "latency_p95_ms": 2396.98,
          "latency_p99_ms": 3137.61,
          "latency_total_ms": 107251.3,
          "accuracy": 0.6885,
          "exact_match_rate": 0.1148,
          "llm_approval_rate": 0.6481,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.1148,
          "accuracy_boost_from_llm": 0.5738,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6302,
            "mean_kappa": 0.6302,
            "min_kappa": 0.5065,
            "max_kappa": 0.6942,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17741,
          "total_tokens_output": 853,
          "total_tokens": 18594,
          "total_cost_usd": 0.033864,
          "total_cost_input_usd": 0.024481,
          "total_cost_output_usd": 0.009383,
          "avg_cost_usd": 0.000555,
          "avg_cost_input_usd": 0.000401,
          "avg_cost_output_usd": 0.000154,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 2009.76,
          "latency_p50_ms": 1734.2,
          "latency_p95_ms": 3742.5,
          "latency_p99_ms": 4196.34,
          "latency_total_ms": 122595.49,
          "accuracy": 0.7213,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.7018,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6976,
            "mean_kappa": 0.6976,
            "min_kappa": 0.6048,
            "max_kappa": 0.7924,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 17782,
          "total_tokens_output": 889,
          "total_tokens": 18671,
          "total_cost_usd": 0.034318,
          "total_cost_input_usd": 0.024539,
          "total_cost_output_usd": 0.009779,
          "avg_cost_usd": 0.000563,
          "avg_cost_input_usd": 0.000402,
          "avg_cost_output_usd": 0.00016,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1785.07,
          "latency_p50_ms": 1663.48,
          "latency_p95_ms": 2483.13,
          "latency_p99_ms": 3184.61,
          "latency_total_ms": 108889.23,
          "accuracy": 0.6721,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.6667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.53,
            "mean_kappa": 0.53,
            "min_kappa": 0.2879,
            "max_kappa": 0.7877,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 17776,
          "total_tokens_output": 879,
          "total_tokens": 18655,
          "total_cost_usd": 0.034199,
          "total_cost_input_usd": 0.02453,
          "total_cost_output_usd": 0.009669,
          "avg_cost_usd": 0.000561,
          "avg_cost_input_usd": 0.000402,
          "avg_cost_output_usd": 0.000159,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1982.67,
          "latency_p50_ms": 1706.09,
          "latency_p95_ms": 3024.5,
          "latency_p99_ms": 5780.13,
          "latency_total_ms": 120942.92,
          "accuracy": 0.8033,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.7736,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.6721,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7234,
            "mean_kappa": 0.7234,
            "min_kappa": 0.5344,
            "max_kappa": 0.8806,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.09836065573770492,
          "total_tokens_input": 17743,
          "total_tokens_output": 843,
          "total_tokens": 18586,
          "total_cost_usd": 0.033757,
          "total_cost_input_usd": 0.024484,
          "total_cost_output_usd": 0.009273,
          "avg_cost_usd": 0.000553,
          "avg_cost_input_usd": 0.000401,
          "avg_cost_output_usd": 0.000152,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1791.67,
          "latency_p50_ms": 1668.44,
          "latency_p95_ms": 2505.71,
          "latency_p99_ms": 3632.5,
          "latency_total_ms": 109291.64,
          "accuracy": 0.6721,
          "exact_match_rate": 0.0984,
          "llm_approval_rate": 0.6364,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.0984,
          "accuracy_boost_from_llm": 0.5738,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6673,
            "mean_kappa": 0.6673,
            "min_kappa": 0.5238,
            "max_kappa": 0.8432,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.11475409836065574,
          "total_tokens_input": 17680,
          "total_tokens_output": 758,
          "total_tokens": 18438,
          "total_cost_usd": 0.032734,
          "total_cost_input_usd": 0.024396,
          "total_cost_output_usd": 0.008338,
          "avg_cost_usd": 0.000537,
          "avg_cost_input_usd": 0.0004,
          "avg_cost_output_usd": 0.000137,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1758.22,
          "latency_p50_ms": 1635.34,
          "latency_p95_ms": 2396.98,
          "latency_p99_ms": 3137.61,
          "latency_total_ms": 107251.3,
          "accuracy": 0.6066,
          "exact_match_rate": 0.1148,
          "llm_approval_rate": 0.5556,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.1148,
          "accuracy_boost_from_llm": 0.4918,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6302,
            "mean_kappa": 0.6302,
            "min_kappa": 0.5065,
            "max_kappa": 0.6942,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17741,
          "total_tokens_output": 853,
          "total_tokens": 18594,
          "total_cost_usd": 0.033864,
          "total_cost_input_usd": 0.024481,
          "total_cost_output_usd": 0.009383,
          "avg_cost_usd": 0.000555,
          "avg_cost_input_usd": 0.000401,
          "avg_cost_output_usd": 0.000154,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 2009.76,
          "latency_p50_ms": 1734.2,
          "latency_p95_ms": 3742.5,
          "latency_p99_ms": 4196.34,
          "latency_total_ms": 122595.49,
          "accuracy": 0.6885,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.6667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6976,
            "mean_kappa": 0.6976,
            "min_kappa": 0.6048,
            "max_kappa": 0.7924,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 17782,
          "total_tokens_output": 889,
          "total_tokens": 18671,
          "total_cost_usd": 0.034318,
          "total_cost_input_usd": 0.024539,
          "total_cost_output_usd": 0.009779,
          "avg_cost_usd": 0.000563,
          "avg_cost_input_usd": 0.000402,
          "avg_cost_output_usd": 0.00016,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1785.07,
          "latency_p50_ms": 1663.48,
          "latency_p95_ms": 2483.13,
          "latency_p99_ms": 3184.61,
          "latency_total_ms": 108889.23,
          "accuracy": 0.6066,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.6,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.5902,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.53,
            "mean_kappa": 0.53,
            "min_kappa": 0.2879,
            "max_kappa": 0.7877,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 17776,
          "total_tokens_output": 879,
          "total_tokens": 18655,
          "total_cost_usd": 0.034199,
          "total_cost_input_usd": 0.02453,
          "total_cost_output_usd": 0.009669,
          "avg_cost_usd": 0.000561,
          "avg_cost_input_usd": 0.000402,
          "avg_cost_output_usd": 0.000159,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1982.67,
          "latency_p50_ms": 1706.09,
          "latency_p95_ms": 3024.5,
          "latency_p99_ms": 5780.13,
          "latency_total_ms": 120942.92,
          "accuracy": 0.8197,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.7925,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 50,
          "incorrect": 11,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.6885,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7234,
            "mean_kappa": 0.7234,
            "min_kappa": 0.5344,
            "max_kappa": 0.8806,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.09836065573770492,
          "total_tokens_input": 17743,
          "total_tokens_output": 843,
          "total_tokens": 18586,
          "total_cost_usd": 0.033757,
          "total_cost_input_usd": 0.024484,
          "total_cost_output_usd": 0.009273,
          "avg_cost_usd": 0.000553,
          "avg_cost_input_usd": 0.000401,
          "avg_cost_output_usd": 0.000152,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1791.67,
          "latency_p50_ms": 1668.44,
          "latency_p95_ms": 2505.71,
          "latency_p99_ms": 3632.5,
          "latency_total_ms": 109291.64,
          "accuracy": 0.8525,
          "exact_match_rate": 0.0984,
          "llm_approval_rate": 0.8364,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 52,
          "incorrect": 9,
          "accuracy_from_exact_match": 0.0984,
          "accuracy_boost_from_llm": 0.7541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6673,
            "mean_kappa": 0.6673,
            "min_kappa": 0.5238,
            "max_kappa": 0.8432,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.11475409836065574,
          "total_tokens_input": 17680,
          "total_tokens_output": 758,
          "total_tokens": 18438,
          "total_cost_usd": 0.032734,
          "total_cost_input_usd": 0.024396,
          "total_cost_output_usd": 0.008338,
          "avg_cost_usd": 0.000537,
          "avg_cost_input_usd": 0.0004,
          "avg_cost_output_usd": 0.000137,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1758.22,
          "latency_p50_ms": 1635.34,
          "latency_p95_ms": 2396.98,
          "latency_p99_ms": 3137.61,
          "latency_total_ms": 107251.3,
          "accuracy": 0.8197,
          "exact_match_rate": 0.1148,
          "llm_approval_rate": 0.7963,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 50,
          "incorrect": 11,
          "accuracy_from_exact_match": 0.1148,
          "accuracy_boost_from_llm": 0.7049,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6302,
            "mean_kappa": 0.6302,
            "min_kappa": 0.5065,
            "max_kappa": 0.6942,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 17741,
          "total_tokens_output": 853,
          "total_tokens": 18594,
          "total_cost_usd": 0.033864,
          "total_cost_input_usd": 0.024481,
          "total_cost_output_usd": 0.009383,
          "avg_cost_usd": 0.000555,
          "avg_cost_input_usd": 0.000401,
          "avg_cost_output_usd": 0.000154,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 2009.76,
          "latency_p50_ms": 1734.2,
          "latency_p95_ms": 3742.5,
          "latency_p99_ms": 4196.34,
          "latency_total_ms": 122595.49,
          "accuracy": 0.8361,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.8246,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 51,
          "incorrect": 10,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.7705,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6976,
            "mean_kappa": 0.6976,
            "min_kappa": 0.6048,
            "max_kappa": 0.7924,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed44__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 17782,
          "total_tokens_output": 889,
          "total_tokens": 18671,
          "total_cost_usd": 0.034318,
          "total_cost_input_usd": 0.024539,
          "total_cost_output_usd": 0.009779,
          "avg_cost_usd": 0.000563,
          "avg_cost_input_usd": 0.000402,
          "avg_cost_output_usd": 0.00016,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1785.07,
          "latency_p50_ms": 1663.48,
          "latency_p95_ms": 2483.13,
          "latency_p99_ms": 3184.61,
          "latency_total_ms": 108889.23,
          "accuracy": 0.9016,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.9,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 55,
          "incorrect": 6,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.8852,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.53,
            "mean_kappa": 0.53,
            "min_kappa": 0.2879,
            "max_kappa": 0.7877,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed45__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 17776,
          "total_tokens_output": 879,
          "total_tokens": 18655,
          "total_cost_usd": 0.034199,
          "total_cost_input_usd": 0.02453,
          "total_cost_output_usd": 0.009669,
          "avg_cost_usd": 0.000561,
          "avg_cost_input_usd": 0.000402,
          "avg_cost_output_usd": 0.000159,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1982.67,
          "latency_p50_ms": 1706.09,
          "latency_p95_ms": 3024.5,
          "latency_p99_ms": 5780.13,
          "latency_total_ms": 120942.92,
          "accuracy": 0.918,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.9057,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 56,
          "incorrect": 5,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.7869,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7234,
            "mean_kappa": 0.7234,
            "min_kappa": 0.5344,
            "max_kappa": 0.8806,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_few_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.6497,
        "std": 0.06744508877598131
      },
      "mean_kappa": {
        "mean": 0.6497,
        "std": 0.06744508877598131
      },
      "min_kappa": {
        "mean": 0.49148,
        "std": 0.1071434067033525
      },
      "max_kappa": {
        "mean": 0.79962,
        "std": 0.06287220053409932
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "gpt-5.2",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.711075,
        "std": 0.09344065964557399
      },
      "exact_match": {
        "mean": 0.02459016393442623,
        "std": 0.01419713776695801
      },
      "exact_match_rate": {
        "mean": 0.0246,
        "std": 0.014202816622064794
      },
      "llm_approval_rate": {
        "mean": 0.7037375,
        "std": 0.09589030109322841
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 43.375,
        "std": 5.6995065575889985
      },
      "incorrect": {
        "mean": 17.625,
        "std": 5.6995065575889985
      },
      "accuracy_from_exact_match": {
        "mean": 0.0246,
        "std": 0.014202816622064794
      },
      "accuracy_boost_from_llm": {
        "mean": 0.6864812499999999,
        "std": 0.09433057708631651
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 8716.75,
        "std": 40.53008142108772
      },
      "total_tokens_output": {
        "mean": 876,
        "std": 76.06576102294646
      },
      "total_tokens": {
        "mean": 9592.75,
        "std": 113.58559547759566
      },
      "latency_mean_ms": {
        "mean": 2068.18,
        "std": 297.94007409208984
      },
      "latency_p50_ms": {
        "mean": 1809.9625,
        "std": 54.44447739440618
      },
      "latency_p95_ms": {
        "mean": 2689.52,
        "std": 369.57810013581707
      },
      "latency_p99_ms": {
        "mean": 6133.015,
        "std": 5068.451642042666
      },
      "latency_total_ms": {
        "mean": 126158.89,
        "std": 18174.47174552124
      }
    },
    "per_seed": [
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8652,
          "total_tokens_output": 762,
          "total_tokens": 9414,
          "total_cost_usd": 0.020324,
          "total_cost_input_usd": 0.011942,
          "total_cost_output_usd": 0.008382,
          "avg_cost_usd": 0.000333,
          "avg_cost_input_usd": 0.000196,
          "avg_cost_output_usd": 0.000137,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1849.67,
          "latency_p50_ms": 1766.36,
          "latency_p95_ms": 2485.11,
          "latency_p99_ms": 3070.65,
          "latency_total_ms": 112829.68,
          "accuracy": 0.6066,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.6,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.5902,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6211,
            "mean_kappa": 0.6211,
            "min_kappa": 0.4947,
            "max_kappa": 0.7613,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8713,
          "total_tokens_output": 878,
          "total_tokens": 9591,
          "total_cost_usd": 0.021683,
          "total_cost_input_usd": 0.012025,
          "total_cost_output_usd": 0.009658,
          "avg_cost_usd": 0.000355,
          "avg_cost_input_usd": 0.000197,
          "avg_cost_output_usd": 0.000158,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1885.04,
          "latency_p50_ms": 1791.96,
          "latency_p95_ms": 2230.45,
          "latency_p99_ms": 2934.68,
          "latency_total_ms": 114987.21,
          "accuracy": 0.7049,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.6897,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5966,
            "mean_kappa": 0.5966,
            "min_kappa": 0.3992,
            "max_kappa": 0.8872,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8754,
          "total_tokens_output": 888,
          "total_tokens": 9642,
          "total_cost_usd": 0.021849,
          "total_cost_input_usd": 0.012081,
          "total_cost_output_usd": 0.009768,
          "avg_cost_usd": 0.000358,
          "avg_cost_input_usd": 0.000198,
          "avg_cost_output_usd": 0.00016,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 2579.75,
          "latency_p50_ms": 1902.95,
          "latency_p95_ms": 3213.25,
          "latency_p99_ms": 14900.35,
          "latency_total_ms": 157364.87,
          "accuracy": 0.6721,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.6667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6782,
            "mean_kappa": 0.6782,
            "min_kappa": 0.4609,
            "max_kappa": 0.9256,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8748,
          "total_tokens_output": 976,
          "total_tokens": 9724,
          "total_cost_usd": 0.022809,
          "total_cost_input_usd": 0.012073,
          "total_cost_output_usd": 0.010736,
          "avg_cost_usd": 0.000374,
          "avg_cost_input_usd": 0.000198,
          "avg_cost_output_usd": 0.000176,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1958.26,
          "latency_p50_ms": 1778.58,
          "latency_p95_ms": 2829.27,
          "latency_p99_ms": 3626.38,
          "latency_total_ms": 119453.8,
          "accuracy": 0.8033,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.8,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.7869,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8275,
            "mean_kappa": 0.8275,
            "min_kappa": 0.6909,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8652,
          "total_tokens_output": 762,
          "total_tokens": 9414,
          "total_cost_usd": 0.020324,
          "total_cost_input_usd": 0.011942,
          "total_cost_output_usd": 0.008382,
          "avg_cost_usd": 0.000333,
          "avg_cost_input_usd": 0.000196,
          "avg_cost_output_usd": 0.000137,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1849.67,
          "latency_p50_ms": 1766.36,
          "latency_p95_ms": 2485.11,
          "latency_p99_ms": 3070.65,
          "latency_total_ms": 112829.68,
          "accuracy": 0.5902,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.5833,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.5738,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6211,
            "mean_kappa": 0.6211,
            "min_kappa": 0.4947,
            "max_kappa": 0.7613,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8713,
          "total_tokens_output": 878,
          "total_tokens": 9591,
          "total_cost_usd": 0.021683,
          "total_cost_input_usd": 0.012025,
          "total_cost_output_usd": 0.009658,
          "avg_cost_usd": 0.000355,
          "avg_cost_input_usd": 0.000197,
          "avg_cost_output_usd": 0.000158,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1885.04,
          "latency_p50_ms": 1791.96,
          "latency_p95_ms": 2230.45,
          "latency_p99_ms": 2934.68,
          "latency_total_ms": 114987.21,
          "accuracy": 0.6557,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.6379,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.6066,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5966,
            "mean_kappa": 0.5966,
            "min_kappa": 0.3992,
            "max_kappa": 0.8872,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8754,
          "total_tokens_output": 888,
          "total_tokens": 9642,
          "total_cost_usd": 0.021849,
          "total_cost_input_usd": 0.012081,
          "total_cost_output_usd": 0.009768,
          "avg_cost_usd": 0.000358,
          "avg_cost_input_usd": 0.000198,
          "avg_cost_output_usd": 0.00016,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 2579.75,
          "latency_p50_ms": 1902.95,
          "latency_p95_ms": 3213.25,
          "latency_p99_ms": 14900.35,
          "latency_total_ms": 157364.87,
          "accuracy": 0.6721,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.6667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6782,
            "mean_kappa": 0.6782,
            "min_kappa": 0.4609,
            "max_kappa": 0.9256,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8748,
          "total_tokens_output": 976,
          "total_tokens": 9724,
          "total_cost_usd": 0.022809,
          "total_cost_input_usd": 0.012073,
          "total_cost_output_usd": 0.010736,
          "avg_cost_usd": 0.000374,
          "avg_cost_input_usd": 0.000198,
          "avg_cost_output_usd": 0.000176,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1958.26,
          "latency_p50_ms": 1778.58,
          "latency_p95_ms": 2829.27,
          "latency_p99_ms": 3626.38,
          "latency_total_ms": 119453.8,
          "accuracy": 0.7705,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.7667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.7541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8275,
            "mean_kappa": 0.8275,
            "min_kappa": 0.6909,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8652,
          "total_tokens_output": 762,
          "total_tokens": 9414,
          "total_cost_usd": 0.020324,
          "total_cost_input_usd": 0.011942,
          "total_cost_output_usd": 0.008382,
          "avg_cost_usd": 0.000333,
          "avg_cost_input_usd": 0.000196,
          "avg_cost_output_usd": 0.000137,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1849.67,
          "latency_p50_ms": 1766.36,
          "latency_p95_ms": 2485.11,
          "latency_p99_ms": 3070.65,
          "latency_total_ms": 112829.68,
          "accuracy": 0.5574,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.55,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6211,
            "mean_kappa": 0.6211,
            "min_kappa": 0.4947,
            "max_kappa": 0.7613,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8713,
          "total_tokens_output": 878,
          "total_tokens": 9591,
          "total_cost_usd": 0.021683,
          "total_cost_input_usd": 0.012025,
          "total_cost_output_usd": 0.009658,
          "avg_cost_usd": 0.000355,
          "avg_cost_input_usd": 0.000197,
          "avg_cost_output_usd": 0.000158,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1885.04,
          "latency_p50_ms": 1791.96,
          "latency_p95_ms": 2230.45,
          "latency_p99_ms": 2934.68,
          "latency_total_ms": 114987.21,
          "accuracy": 0.623,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.6034,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.5738,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5966,
            "mean_kappa": 0.5966,
            "min_kappa": 0.3992,
            "max_kappa": 0.8872,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8754,
          "total_tokens_output": 888,
          "total_tokens": 9642,
          "total_cost_usd": 0.021849,
          "total_cost_input_usd": 0.012081,
          "total_cost_output_usd": 0.009768,
          "avg_cost_usd": 0.000358,
          "avg_cost_input_usd": 0.000198,
          "avg_cost_output_usd": 0.00016,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 2579.75,
          "latency_p50_ms": 1902.95,
          "latency_p95_ms": 3213.25,
          "latency_p99_ms": 14900.35,
          "latency_total_ms": 157364.87,
          "accuracy": 0.6557,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.65,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6782,
            "mean_kappa": 0.6782,
            "min_kappa": 0.4609,
            "max_kappa": 0.9256,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8748,
          "total_tokens_output": 976,
          "total_tokens": 9724,
          "total_cost_usd": 0.022809,
          "total_cost_input_usd": 0.012073,
          "total_cost_output_usd": 0.010736,
          "avg_cost_usd": 0.000374,
          "avg_cost_input_usd": 0.000198,
          "avg_cost_output_usd": 0.000176,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1958.26,
          "latency_p50_ms": 1778.58,
          "latency_p95_ms": 2829.27,
          "latency_p99_ms": 3626.38,
          "latency_total_ms": 119453.8,
          "accuracy": 0.7705,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.7667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.7541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8275,
            "mean_kappa": 0.8275,
            "min_kappa": 0.6909,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8652,
          "total_tokens_output": 762,
          "total_tokens": 9414,
          "total_cost_usd": 0.020324,
          "total_cost_input_usd": 0.011942,
          "total_cost_output_usd": 0.008382,
          "avg_cost_usd": 0.000333,
          "avg_cost_input_usd": 0.000196,
          "avg_cost_output_usd": 0.000137,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1849.67,
          "latency_p50_ms": 1766.36,
          "latency_p95_ms": 2485.11,
          "latency_p99_ms": 3070.65,
          "latency_total_ms": 112829.68,
          "accuracy": 0.7541,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.75,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.7377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6211,
            "mean_kappa": 0.6211,
            "min_kappa": 0.4947,
            "max_kappa": 0.7613,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 8713,
          "total_tokens_output": 878,
          "total_tokens": 9591,
          "total_cost_usd": 0.021683,
          "total_cost_input_usd": 0.012025,
          "total_cost_output_usd": 0.009658,
          "avg_cost_usd": 0.000355,
          "avg_cost_input_usd": 0.000197,
          "avg_cost_output_usd": 0.000158,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1885.04,
          "latency_p50_ms": 1791.96,
          "latency_p95_ms": 2230.45,
          "latency_p99_ms": 2934.68,
          "latency_total_ms": 114987.21,
          "accuracy": 0.8689,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.8621,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 53,
          "incorrect": 8,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.8197,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5966,
            "mean_kappa": 0.5966,
            "min_kappa": 0.3992,
            "max_kappa": 0.8872,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed44__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8754,
          "total_tokens_output": 888,
          "total_tokens": 9642,
          "total_cost_usd": 0.021849,
          "total_cost_input_usd": 0.012081,
          "total_cost_output_usd": 0.009768,
          "avg_cost_usd": 0.000358,
          "avg_cost_input_usd": 0.000198,
          "avg_cost_output_usd": 0.00016,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 2579.75,
          "latency_p50_ms": 1902.95,
          "latency_p95_ms": 3213.25,
          "latency_p99_ms": 14900.35,
          "latency_total_ms": 157364.87,
          "accuracy": 0.8361,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.8333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 51,
          "incorrect": 10,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.8197,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6782,
            "mean_kappa": 0.6782,
            "min_kappa": 0.4609,
            "max_kappa": 0.9256,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed45__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 8748,
          "total_tokens_output": 976,
          "total_tokens": 9724,
          "total_cost_usd": 0.022809,
          "total_cost_input_usd": 0.012073,
          "total_cost_output_usd": 0.010736,
          "avg_cost_usd": 0.000374,
          "avg_cost_input_usd": 0.000198,
          "avg_cost_output_usd": 0.000176,
          "price_input_per_1k": 0.00138,
          "price_output_per_1k": 0.011,
          "price_input_per_token": 1.38e-06,
          "price_output_per_token": 1.1e-05,
          "latency_mean_ms": 1958.26,
          "latency_p50_ms": 1778.58,
          "latency_p95_ms": 2829.27,
          "latency_p99_ms": 3626.38,
          "latency_total_ms": 119453.8,
          "accuracy": 0.8361,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.8333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 51,
          "incorrect": 10,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.8197,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8275,
            "mean_kappa": 0.8275,
            "min_kappa": 0.6909,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "gpt-5.2_baseline_zero_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.68085,
        "std": 0.08969583323655565
      },
      "mean_kappa": {
        "mean": 0.68085,
        "std": 0.08969583323655565
      },
      "min_kappa": {
        "mean": 0.511425,
        "std": 0.10913091621992366
      },
      "max_kappa": {
        "mean": 0.893525,
        "std": 0.08644244833992153
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "llama-70b",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.7069625,
        "std": 0.12997416990983246
      },
      "exact_match": {
        "mean": 0.0860655737704918,
        "std": 0.029268149297306766
      },
      "exact_match_rate": {
        "mean": 0.086075,
        "std": 0.02924135556023352
      },
      "llm_approval_rate": {
        "mean": 0.6812125,
        "std": 0.13498054894595
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 43.125,
        "std": 7.92839044194974
      },
      "incorrect": {
        "mean": 17.875,
        "std": 7.92839044194974
      },
      "accuracy_from_exact_match": {
        "mean": 0.086075,
        "std": 0.02924135556023352
      },
      "accuracy_boost_from_llm": {
        "mean": 0.6209125,
        "std": 0.1187747283463532
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 18738.25,
        "std": 18.89940475253123
      },
      "total_tokens_output": {
        "mean": 868.75,
        "std": 8.870597499605086
      },
      "total_tokens": {
        "mean": 19607,
        "std": 25.700194551792794
      },
      "latency_mean_ms": {
        "mean": 2205.19,
        "std": 48.477864020602155
      },
      "latency_p50_ms": {
        "mean": 2056.9475,
        "std": 59.93239373452396
      },
      "latency_p95_ms": {
        "mean": 2957.2325,
        "std": 137.9295697765712
      },
      "latency_p99_ms": {
        "mean": 5841.555,
        "std": 309.0318937019287
      },
      "latency_total_ms": {
        "mean": 134516.625,
        "std": 2957.2574681831497
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18721,
          "total_tokens_output": 862,
          "total_tokens": 19583,
          "latency_mean_ms": 2123.3,
          "latency_p50_ms": 1971.71,
          "latency_p95_ms": 2769.35,
          "latency_p99_ms": 5392.73,
          "latency_total_ms": 129521.17,
          "accuracy": 0.7049,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.6786,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5637,
            "mean_kappa": 0.5637,
            "min_kappa": 0.4199,
            "max_kappa": 0.7292,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18718,
          "total_tokens_output": 865,
          "total_tokens": 19583,
          "latency_mean_ms": 2215.0,
          "latency_p50_ms": 2041.59,
          "latency_p95_ms": 2896.09,
          "latency_p99_ms": 5717.4,
          "latency_total_ms": 135114.98,
          "accuracy": 0.6885,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.6607,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.6066,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5862,
            "mean_kappa": 0.5862,
            "min_kappa": 0.3191,
            "max_kappa": 0.8061,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 18760,
          "total_tokens_output": 884,
          "total_tokens": 19644,
          "latency_mean_ms": 2241.7,
          "latency_p50_ms": 2137.3,
          "latency_p95_ms": 3026.73,
          "latency_p99_ms": 6105.78,
          "latency_total_ms": 136743.84,
          "accuracy": 0.5902,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.569,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4891,
            "mean_kappa": 0.4891,
            "min_kappa": 0.1685,
            "max_kappa": 0.8349,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 18754,
          "total_tokens_output": 864,
          "total_tokens": 19618,
          "latency_mean_ms": 2240.76,
          "latency_p50_ms": 2077.19,
          "latency_p95_ms": 3136.76,
          "latency_p99_ms": 6150.31,
          "latency_total_ms": 136686.51,
          "accuracy": 0.7705,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.7358,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6673,
            "mean_kappa": 0.6673,
            "min_kappa": 0.4029,
            "max_kappa": 0.8707,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18721,
          "total_tokens_output": 862,
          "total_tokens": 19583,
          "latency_mean_ms": 2123.3,
          "latency_p50_ms": 1971.71,
          "latency_p95_ms": 2769.35,
          "latency_p99_ms": 5392.73,
          "latency_total_ms": 129521.17,
          "accuracy": 0.7213,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.6964,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5637,
            "mean_kappa": 0.5637,
            "min_kappa": 0.4199,
            "max_kappa": 0.7292,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18718,
          "total_tokens_output": 865,
          "total_tokens": 19583,
          "latency_mean_ms": 2215.0,
          "latency_p50_ms": 2041.59,
          "latency_p95_ms": 2896.09,
          "latency_p99_ms": 5717.4,
          "latency_total_ms": 135114.98,
          "accuracy": 0.7049,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.6786,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5862,
            "mean_kappa": 0.5862,
            "min_kappa": 0.3191,
            "max_kappa": 0.8061,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 18760,
          "total_tokens_output": 884,
          "total_tokens": 19644,
          "latency_mean_ms": 2241.7,
          "latency_p50_ms": 2137.3,
          "latency_p95_ms": 3026.73,
          "latency_p99_ms": 6105.78,
          "latency_total_ms": 136743.84,
          "accuracy": 0.4754,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.4483,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4262,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4891,
            "mean_kappa": 0.4891,
            "min_kappa": 0.1685,
            "max_kappa": 0.8349,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 18754,
          "total_tokens_output": 864,
          "total_tokens": 19618,
          "latency_mean_ms": 2240.76,
          "latency_p50_ms": 2077.19,
          "latency_p95_ms": 3136.76,
          "latency_p99_ms": 6150.31,
          "latency_total_ms": 136686.51,
          "accuracy": 0.7213,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.6792,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.5902,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6673,
            "mean_kappa": 0.6673,
            "min_kappa": 0.4029,
            "max_kappa": 0.8707,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18721,
          "total_tokens_output": 862,
          "total_tokens": 19583,
          "latency_mean_ms": 2123.3,
          "latency_p50_ms": 1971.71,
          "latency_p95_ms": 2769.35,
          "latency_p99_ms": 5392.73,
          "latency_total_ms": 129521.17,
          "accuracy": 0.6721,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.6429,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.5902,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5637,
            "mean_kappa": 0.5637,
            "min_kappa": 0.4199,
            "max_kappa": 0.7292,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18718,
          "total_tokens_output": 865,
          "total_tokens": 19583,
          "latency_mean_ms": 2215.0,
          "latency_p50_ms": 2041.59,
          "latency_p95_ms": 2896.09,
          "latency_p99_ms": 5717.4,
          "latency_total_ms": 135114.98,
          "accuracy": 0.623,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.5893,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5862,
            "mean_kappa": 0.5862,
            "min_kappa": 0.3191,
            "max_kappa": 0.8061,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 18760,
          "total_tokens_output": 884,
          "total_tokens": 19644,
          "latency_mean_ms": 2241.7,
          "latency_p50_ms": 2137.3,
          "latency_p95_ms": 3026.73,
          "latency_p99_ms": 6105.78,
          "latency_total_ms": 136743.84,
          "accuracy": 0.4262,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.3966,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 26,
          "incorrect": 35,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4891,
            "mean_kappa": 0.4891,
            "min_kappa": 0.1685,
            "max_kappa": 0.8349,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 18754,
          "total_tokens_output": 864,
          "total_tokens": 19618,
          "latency_mean_ms": 2240.76,
          "latency_p50_ms": 2077.19,
          "latency_p95_ms": 3136.76,
          "latency_p99_ms": 6150.31,
          "latency_total_ms": 136686.51,
          "accuracy": 0.7213,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.6792,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.5902,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6673,
            "mean_kappa": 0.6673,
            "min_kappa": 0.4029,
            "max_kappa": 0.8707,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18721,
          "total_tokens_output": 862,
          "total_tokens": 19583,
          "latency_mean_ms": 2123.3,
          "latency_p50_ms": 1971.71,
          "latency_p95_ms": 2769.35,
          "latency_p99_ms": 5392.73,
          "latency_total_ms": 129521.17,
          "accuracy": 0.8852,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.875,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 54,
          "incorrect": 7,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.8033,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5637,
            "mean_kappa": 0.5637,
            "min_kappa": 0.4199,
            "max_kappa": 0.7292,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18718,
          "total_tokens_output": 865,
          "total_tokens": 19583,
          "latency_mean_ms": 2215.0,
          "latency_p50_ms": 2041.59,
          "latency_p95_ms": 2896.09,
          "latency_p99_ms": 5717.4,
          "latency_total_ms": 135114.98,
          "accuracy": 0.8689,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.8571,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 53,
          "incorrect": 8,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.7869,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5862,
            "mean_kappa": 0.5862,
            "min_kappa": 0.3191,
            "max_kappa": 0.8061,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed44__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 18760,
          "total_tokens_output": 884,
          "total_tokens": 19644,
          "latency_mean_ms": 2241.7,
          "latency_p50_ms": 2137.3,
          "latency_p95_ms": 3026.73,
          "latency_p99_ms": 6105.78,
          "latency_total_ms": 136743.84,
          "accuracy": 0.8525,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.8448,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 52,
          "incorrect": 9,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.8033,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4891,
            "mean_kappa": 0.4891,
            "min_kappa": 0.1685,
            "max_kappa": 0.8349,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed45__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 18754,
          "total_tokens_output": 864,
          "total_tokens": 19618,
          "latency_mean_ms": 2240.76,
          "latency_p50_ms": 2077.19,
          "latency_p95_ms": 3136.76,
          "latency_p99_ms": 6150.31,
          "latency_total_ms": 136686.51,
          "accuracy": 0.8852,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.8679,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 54,
          "incorrect": 7,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.7541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6673,
            "mean_kappa": 0.6673,
            "min_kappa": 0.4029,
            "max_kappa": 0.8707,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_few_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.5765750000000001,
        "std": 0.06352422274219498
      },
      "mean_kappa": {
        "mean": 0.5765750000000001,
        "std": 0.06352422274219498
      },
      "min_kappa": {
        "mean": 0.3276,
        "std": 0.09946662756925058
      },
      "max_kappa": {
        "mean": 0.810225,
        "std": 0.05207722030792352
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "llama-70b",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.4620875,
        "std": 0.17048222368842447
      },
      "exact_match": {
        "mean": 0.01639344262295082,
        "std": 0.01639344262295082
      },
      "exact_match_rate": {
        "mean": 0.0164,
        "std": 0.0164
      },
      "llm_approval_rate": {
        "mean": 0.4525375,
        "std": 0.17460253389842315
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 28.1875,
        "std": 10.399631904543545
      },
      "incorrect": {
        "mean": 32.8125,
        "std": 10.399631904543545
      },
      "accuracy_from_exact_match": {
        "mean": 0.0164,
        "std": 0.0164
      },
      "accuracy_boost_from_llm": {
        "mean": 0.44569375,
        "std": 0.1737013977662169
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 9624.25,
        "std": 33.83323070591988
      },
      "total_tokens_output": {
        "mean": 794.25,
        "std": 29.422567868899545
      },
      "total_tokens": {
        "mean": 10418.5,
        "std": 59.60075502877459
      },
      "latency_mean_ms": {
        "mean": 1928.0375,
        "std": 78.00409167953947
      },
      "latency_p50_ms": {
        "mean": 1787.275,
        "std": 33.651461706737216
      },
      "latency_p95_ms": {
        "mean": 2731.9875,
        "std": 261.778057175826
      },
      "latency_p99_ms": {
        "mean": 4993.73,
        "std": 893.5612009538015
      },
      "latency_total_ms": {
        "mean": 117610.34,
        "std": 4758.144444097927
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9632,
          "total_tokens_output": 813,
          "total_tokens": 10445,
          "latency_mean_ms": 1953.4,
          "latency_p50_ms": 1785.11,
          "latency_p95_ms": 2779.79,
          "latency_p99_ms": 5287.04,
          "latency_total_ms": 119157.43,
          "accuracy": 0.4098,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.3898,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 25,
          "incorrect": 36,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5438,
            "mean_kappa": 0.5438,
            "min_kappa": 0.3184,
            "max_kappa": 0.7613,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9571,
          "total_tokens_output": 745,
          "total_tokens": 10316,
          "latency_mean_ms": 1820.49,
          "latency_p50_ms": 1766.63,
          "latency_p95_ms": 2416.46,
          "latency_p99_ms": 3573.29,
          "latency_total_ms": 111050.13,
          "accuracy": 0.3607,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.339,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 22,
          "incorrect": 39,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5037,
            "mean_kappa": 0.5037,
            "min_kappa": 0.2784,
            "max_kappa": 0.7867,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9629,
          "total_tokens_output": 820,
          "total_tokens": 10449,
          "latency_mean_ms": 2035.28,
          "latency_p50_ms": 1842.49,
          "latency_p95_ms": 2604.67,
          "latency_p99_ms": 6034.22,
          "latency_total_ms": 124152.01,
          "accuracy": 0.459,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.459,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 28,
          "incorrect": 33,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4406,
            "mean_kappa": 0.4406,
            "min_kappa": 0.2278,
            "max_kappa": 0.6699,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9665,
          "total_tokens_output": 799,
          "total_tokens": 10464,
          "latency_mean_ms": 1902.98,
          "latency_p50_ms": 1754.87,
          "latency_p95_ms": 3127.03,
          "latency_p99_ms": 5080.37,
          "latency_total_ms": 116081.79,
          "accuracy": 0.377,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.377,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 23,
          "incorrect": 38,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.415,
            "mean_kappa": 0.415,
            "min_kappa": 0.2217,
            "max_kappa": 0.6886,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9632,
          "total_tokens_output": 813,
          "total_tokens": 10445,
          "latency_mean_ms": 1953.4,
          "latency_p50_ms": 1785.11,
          "latency_p95_ms": 2779.79,
          "latency_p99_ms": 5287.04,
          "latency_total_ms": 119157.43,
          "accuracy": 0.3934,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.3729,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 24,
          "incorrect": 37,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5438,
            "mean_kappa": 0.5438,
            "min_kappa": 0.3184,
            "max_kappa": 0.7613,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9571,
          "total_tokens_output": 745,
          "total_tokens": 10316,
          "latency_mean_ms": 1820.49,
          "latency_p50_ms": 1766.63,
          "latency_p95_ms": 2416.46,
          "latency_p99_ms": 3573.29,
          "latency_total_ms": 111050.13,
          "accuracy": 0.3607,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.339,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 22,
          "incorrect": 39,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5037,
            "mean_kappa": 0.5037,
            "min_kappa": 0.2784,
            "max_kappa": 0.7867,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9629,
          "total_tokens_output": 820,
          "total_tokens": 10449,
          "latency_mean_ms": 2035.28,
          "latency_p50_ms": 1842.49,
          "latency_p95_ms": 2604.67,
          "latency_p99_ms": 6034.22,
          "latency_total_ms": 124152.01,
          "accuracy": 0.459,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.459,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 28,
          "incorrect": 33,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4406,
            "mean_kappa": 0.4406,
            "min_kappa": 0.2278,
            "max_kappa": 0.6699,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9665,
          "total_tokens_output": 799,
          "total_tokens": 10464,
          "latency_mean_ms": 1902.98,
          "latency_p50_ms": 1754.87,
          "latency_p95_ms": 3127.03,
          "latency_p99_ms": 5080.37,
          "latency_total_ms": 116081.79,
          "accuracy": 0.3934,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.3934,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 24,
          "incorrect": 37,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.415,
            "mean_kappa": 0.415,
            "min_kappa": 0.2217,
            "max_kappa": 0.6886,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9632,
          "total_tokens_output": 813,
          "total_tokens": 10445,
          "latency_mean_ms": 1953.4,
          "latency_p50_ms": 1785.11,
          "latency_p95_ms": 2779.79,
          "latency_p99_ms": 5287.04,
          "latency_total_ms": 119157.43,
          "accuracy": 0.2951,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.2712,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 18,
          "incorrect": 43,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5438,
            "mean_kappa": 0.5438,
            "min_kappa": 0.3184,
            "max_kappa": 0.7613,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9571,
          "total_tokens_output": 745,
          "total_tokens": 10316,
          "latency_mean_ms": 1820.49,
          "latency_p50_ms": 1766.63,
          "latency_p95_ms": 2416.46,
          "latency_p99_ms": 3573.29,
          "latency_total_ms": 111050.13,
          "accuracy": 0.2787,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.2542,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 17,
          "incorrect": 44,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5037,
            "mean_kappa": 0.5037,
            "min_kappa": 0.2784,
            "max_kappa": 0.7867,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9629,
          "total_tokens_output": 820,
          "total_tokens": 10449,
          "latency_mean_ms": 2035.28,
          "latency_p50_ms": 1842.49,
          "latency_p95_ms": 2604.67,
          "latency_p99_ms": 6034.22,
          "latency_total_ms": 124152.01,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.3443,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4406,
            "mean_kappa": 0.4406,
            "min_kappa": 0.2278,
            "max_kappa": 0.6699,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9665,
          "total_tokens_output": 799,
          "total_tokens": 10464,
          "latency_mean_ms": 1902.98,
          "latency_p50_ms": 1754.87,
          "latency_p95_ms": 3127.03,
          "latency_p99_ms": 5080.37,
          "latency_total_ms": 116081.79,
          "accuracy": 0.2951,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2951,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 18,
          "incorrect": 43,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.415,
            "mean_kappa": 0.415,
            "min_kappa": 0.2217,
            "max_kappa": 0.6886,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9632,
          "total_tokens_output": 813,
          "total_tokens": 10445,
          "latency_mean_ms": 1953.4,
          "latency_p50_ms": 1785.11,
          "latency_p95_ms": 2779.79,
          "latency_p99_ms": 5287.04,
          "latency_total_ms": 119157.43,
          "accuracy": 0.6885,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.678,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5438,
            "mean_kappa": 0.5438,
            "min_kappa": 0.3184,
            "max_kappa": 0.7613,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9571,
          "total_tokens_output": 745,
          "total_tokens": 10316,
          "latency_mean_ms": 1820.49,
          "latency_p50_ms": 1766.63,
          "latency_p95_ms": 2416.46,
          "latency_p99_ms": 3573.29,
          "latency_total_ms": 111050.13,
          "accuracy": 0.7049,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.6949,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.6721,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5037,
            "mean_kappa": 0.5037,
            "min_kappa": 0.2784,
            "max_kappa": 0.7867,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9629,
          "total_tokens_output": 820,
          "total_tokens": 10449,
          "latency_mean_ms": 2035.28,
          "latency_p50_ms": 1842.49,
          "latency_p95_ms": 2604.67,
          "latency_p99_ms": 6034.22,
          "latency_total_ms": 124152.01,
          "accuracy": 0.8033,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.8033,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.8033,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4406,
            "mean_kappa": 0.4406,
            "min_kappa": 0.2278,
            "max_kappa": 0.6699,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed44__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9665,
          "total_tokens_output": 799,
          "total_tokens": 10464,
          "latency_mean_ms": 1902.98,
          "latency_p50_ms": 1754.87,
          "latency_p95_ms": 3127.03,
          "latency_p99_ms": 5080.37,
          "latency_total_ms": 116081.79,
          "accuracy": 0.7705,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.7705,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.7705,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.415,
            "mean_kappa": 0.415,
            "min_kappa": 0.2217,
            "max_kappa": 0.6886,
            "n_items": 61
          }
        },
        "source": "llama-70b_baseline_zero_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.475775,
        "std": 0.05083819307371181
      },
      "mean_kappa": {
        "mean": 0.475775,
        "std": 0.05083819307371181
      },
      "min_kappa": {
        "mean": 0.261575,
        "std": 0.03950609921265323
      },
      "max_kappa": {
        "mean": 0.726625,
        "std": 0.048669773730725285
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "llama-8b",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 12,
    "metrics": {
      "accuracy": {
        "mean": 0.502725,
        "std": 0.14027699457977183
      },
      "exact_match": {
        "mean": 0.04918032786885246,
        "std": 0.03541388359785716
      },
      "exact_match_rate": {
        "mean": 0.0492,
        "std": 0.035428049151296305
      },
      "llm_approval_rate": {
        "mean": 0.4772,
        "std": 0.14642965888097945
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 30.666666666666668,
        "std": 8.556998435328957
      },
      "incorrect": {
        "mean": 30.333333333333332,
        "std": 8.556998435328957
      },
      "accuracy_from_exact_match": {
        "mean": 0.0492,
        "std": 0.035428049151296305
      },
      "accuracy_boost_from_llm": {
        "mean": 0.4535416666666667,
        "std": 0.1388184153149558
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 18713.666666666668,
        "std": 41.15283168331865
      },
      "total_tokens_output": {
        "mean": 845.6666666666666,
        "std": 16.048537489614297
      },
      "total_tokens": {
        "mean": 19559.333333333332,
        "std": 43.02970550161314
      },
      "latency_mean_ms": {
        "mean": 759.0666666666666,
        "std": 32.96071331482716
      },
      "latency_p50_ms": {
        "mean": 712.6533333333333,
        "std": 31.759555342535176
      },
      "latency_p95_ms": {
        "mean": 1298.61,
        "std": 162.02605531210097
      },
      "latency_p99_ms": {
        "mean": 1626.8333333333333,
        "std": 202.20807539649735
      },
      "latency_total_ms": {
        "mean": 46303.18,
        "std": 2010.6681480708528
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18721,
          "total_tokens_output": 823,
          "total_tokens": 19544,
          "latency_mean_ms": 724.3,
          "latency_p50_ms": 689.1,
          "latency_p95_ms": 1070.28,
          "latency_p99_ms": 1377.46,
          "latency_total_ms": 44182.43,
          "accuracy": 0.541,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.5,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 33,
          "incorrect": 28,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5995,
            "mean_kappa": 0.5995,
            "min_kappa": 0.3693,
            "max_kappa": 0.8041,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18660,
          "total_tokens_output": 856,
          "total_tokens": 19516,
          "latency_mean_ms": 749.56,
          "latency_p50_ms": 691.31,
          "latency_p95_ms": 1396.11,
          "latency_p99_ms": 1630.31,
          "latency_total_ms": 45723.13,
          "accuracy": 0.4426,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.4035,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 27,
          "incorrect": 34,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5762,
            "mean_kappa": 0.5762,
            "min_kappa": 0.3107,
            "max_kappa": 0.832,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 18760,
          "total_tokens_output": 858,
          "total_tokens": 19618,
          "latency_mean_ms": 803.34,
          "latency_p50_ms": 757.55,
          "latency_p95_ms": 1429.44,
          "latency_p99_ms": 1872.73,
          "latency_total_ms": 49003.98,
          "accuracy": 0.4754,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.4754,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.4754,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6086,
            "mean_kappa": 0.6086,
            "min_kappa": 0.4078,
            "max_kappa": 0.7354,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18721,
          "total_tokens_output": 823,
          "total_tokens": 19544,
          "latency_mean_ms": 724.3,
          "latency_p50_ms": 689.1,
          "latency_p95_ms": 1070.28,
          "latency_p99_ms": 1377.46,
          "latency_total_ms": 44182.43,
          "accuracy": 0.4754,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.4286,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5995,
            "mean_kappa": 0.5995,
            "min_kappa": 0.3693,
            "max_kappa": 0.8041,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18660,
          "total_tokens_output": 856,
          "total_tokens": 19516,
          "latency_mean_ms": 749.56,
          "latency_p50_ms": 691.31,
          "latency_p95_ms": 1396.11,
          "latency_p99_ms": 1630.31,
          "latency_total_ms": 45723.13,
          "accuracy": 0.3934,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.3509,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 24,
          "incorrect": 37,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5762,
            "mean_kappa": 0.5762,
            "min_kappa": 0.3107,
            "max_kappa": 0.832,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 18760,
          "total_tokens_output": 858,
          "total_tokens": 19618,
          "latency_mean_ms": 803.34,
          "latency_p50_ms": 757.55,
          "latency_p95_ms": 1429.44,
          "latency_p99_ms": 1872.73,
          "latency_total_ms": 49003.98,
          "accuracy": 0.4098,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.4098,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 25,
          "incorrect": 36,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6086,
            "mean_kappa": 0.6086,
            "min_kappa": 0.4078,
            "max_kappa": 0.7354,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18721,
          "total_tokens_output": 823,
          "total_tokens": 19544,
          "latency_mean_ms": 724.3,
          "latency_p50_ms": 689.1,
          "latency_p95_ms": 1070.28,
          "latency_p99_ms": 1377.46,
          "latency_total_ms": 44182.43,
          "accuracy": 0.4098,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.3571,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 25,
          "incorrect": 36,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5995,
            "mean_kappa": 0.5995,
            "min_kappa": 0.3693,
            "max_kappa": 0.8041,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18660,
          "total_tokens_output": 856,
          "total_tokens": 19516,
          "latency_mean_ms": 749.56,
          "latency_p50_ms": 691.31,
          "latency_p95_ms": 1396.11,
          "latency_p99_ms": 1630.31,
          "latency_total_ms": 45723.13,
          "accuracy": 0.3607,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.3158,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 22,
          "incorrect": 39,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5762,
            "mean_kappa": 0.5762,
            "min_kappa": 0.3107,
            "max_kappa": 0.832,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 18760,
          "total_tokens_output": 858,
          "total_tokens": 19618,
          "latency_mean_ms": 803.34,
          "latency_p50_ms": 757.55,
          "latency_p95_ms": 1429.44,
          "latency_p99_ms": 1872.73,
          "latency_total_ms": 49003.98,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.3443,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6086,
            "mean_kappa": 0.6086,
            "min_kappa": 0.4078,
            "max_kappa": 0.7354,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18721,
          "total_tokens_output": 823,
          "total_tokens": 19544,
          "latency_mean_ms": 724.3,
          "latency_p50_ms": 689.1,
          "latency_p95_ms": 1070.28,
          "latency_p99_ms": 1377.46,
          "latency_total_ms": 44182.43,
          "accuracy": 0.7541,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.7321,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.6721,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5995,
            "mean_kappa": 0.5995,
            "min_kappa": 0.3693,
            "max_kappa": 0.8041,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_few_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18660,
          "total_tokens_output": 856,
          "total_tokens": 19516,
          "latency_mean_ms": 749.56,
          "latency_p50_ms": 691.31,
          "latency_p95_ms": 1396.11,
          "latency_p99_ms": 1630.31,
          "latency_total_ms": 45723.13,
          "accuracy": 0.7541,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.7368,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.6885,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5762,
            "mean_kappa": 0.5762,
            "min_kappa": 0.3107,
            "max_kappa": 0.832,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_few_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 18760,
          "total_tokens_output": 858,
          "total_tokens": 19618,
          "latency_mean_ms": 803.34,
          "latency_p50_ms": 757.55,
          "latency_p95_ms": 1429.44,
          "latency_p99_ms": 1872.73,
          "latency_total_ms": 49003.98,
          "accuracy": 0.6721,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.6721,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.6721,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6086,
            "mean_kappa": 0.6086,
            "min_kappa": 0.4078,
            "max_kappa": 0.7354,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_few_shot_seed45__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.5947666666666667,
        "std": 0.013644127756006319
      },
      "mean_kappa": {
        "mean": 0.5947666666666667,
        "std": 0.013644127756006319
      },
      "min_kappa": {
        "mean": 0.3626,
        "std": 0.039923009238616615
      },
      "max_kappa": {
        "mean": 0.7905,
        "std": 0.040592363813899746
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "llama-8b",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.24075625,
        "std": 0.12721200792746534
      },
      "exact_match": {
        "mean": 0.004098360655737705,
        "std": 0.007098568883479006
      },
      "exact_match_rate": {
        "mean": 0.0041,
        "std": 0.007101408311032398
      },
      "llm_approval_rate": {
        "mean": 0.23760625000000002,
        "std": 0.12769839206480832
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 14.6875,
        "std": 7.759822404539939
      },
      "incorrect": {
        "mean": 46.3125,
        "std": 7.759822404539939
      },
      "accuracy_from_exact_match": {
        "mean": 0.0041,
        "std": 0.007101408311032398
      },
      "accuracy_boost_from_llm": {
        "mean": 0.23665625,
        "std": 0.12737727902156454
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 9634.75,
        "std": 39.68863187362346
      },
      "total_tokens_output": {
        "mean": 1392.25,
        "std": 241.3683647456725
      },
      "total_tokens": {
        "mean": 11027,
        "std": 257.4577635263695
      },
      "latency_mean_ms": {
        "mean": 1201.265,
        "std": 217.75694081934566
      },
      "latency_p50_ms": {
        "mean": 723.635,
        "std": 22.144182644658603
      },
      "latency_p95_ms": {
        "mean": 1631.355,
        "std": 226.069227505647
      },
      "latency_p99_ms": {
        "mean": 10781.8275,
        "std": 4540.5752752177505
      },
      "latency_total_ms": {
        "mean": 73277.04250000001,
        "std": 13283.210032803396
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9632,
          "total_tokens_output": 997,
          "total_tokens": 10629,
          "latency_mean_ms": 832.14,
          "latency_p50_ms": 757.28,
          "latency_p95_ms": 1299.8,
          "latency_p99_ms": 2935.47,
          "latency_total_ms": 50760.37,
          "accuracy": 0.1639,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.1639,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 10,
          "incorrect": 51,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.1639,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4553,
            "mean_kappa": 0.4553,
            "min_kappa": 0.1953,
            "max_kappa": 0.7125,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9571,
          "total_tokens_output": 1409,
          "total_tokens": 10980,
          "latency_mean_ms": 1254.9,
          "latency_p50_ms": 710.68,
          "latency_p95_ms": 1718.11,
          "latency_p99_ms": 13854.81,
          "latency_total_ms": 76548.63,
          "accuracy": 0.1967,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.1967,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 12,
          "incorrect": 49,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6346,
            "mean_kappa": 0.6346,
            "min_kappa": 0.3779,
            "max_kappa": 0.8963,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9671,
          "total_tokens_output": 1631,
          "total_tokens": 11302,
          "latency_mean_ms": 1378.7,
          "latency_p50_ms": 728.25,
          "latency_p95_ms": 1584.92,
          "latency_p99_ms": 12986.59,
          "latency_total_ms": 84100.46,
          "accuracy": 0.2131,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.2,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 13,
          "incorrect": 48,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6188,
            "mean_kappa": 0.6188,
            "min_kappa": 0.3779,
            "max_kappa": 0.8806,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9665,
          "total_tokens_output": 1532,
          "total_tokens": 11197,
          "latency_mean_ms": 1339.32,
          "latency_p50_ms": 698.33,
          "latency_p95_ms": 1922.59,
          "latency_p99_ms": 13350.44,
          "latency_total_ms": 81698.71,
          "accuracy": 0.2295,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2295,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 14,
          "incorrect": 47,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.562,
            "mean_kappa": 0.562,
            "min_kappa": 0.2561,
            "max_kappa": 0.8282,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9632,
          "total_tokens_output": 997,
          "total_tokens": 10629,
          "latency_mean_ms": 832.14,
          "latency_p50_ms": 757.28,
          "latency_p95_ms": 1299.8,
          "latency_p99_ms": 2935.47,
          "latency_total_ms": 50760.37,
          "accuracy": 0.1803,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.1803,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 11,
          "incorrect": 50,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.1803,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4553,
            "mean_kappa": 0.4553,
            "min_kappa": 0.1953,
            "max_kappa": 0.7125,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9571,
          "total_tokens_output": 1409,
          "total_tokens": 10980,
          "latency_mean_ms": 1254.9,
          "latency_p50_ms": 710.68,
          "latency_p95_ms": 1718.11,
          "latency_p99_ms": 13854.81,
          "latency_total_ms": 76548.63,
          "accuracy": 0.1967,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.1967,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 12,
          "incorrect": 49,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6346,
            "mean_kappa": 0.6346,
            "min_kappa": 0.3779,
            "max_kappa": 0.8963,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9671,
          "total_tokens_output": 1631,
          "total_tokens": 11302,
          "latency_mean_ms": 1378.7,
          "latency_p50_ms": 728.25,
          "latency_p95_ms": 1584.92,
          "latency_p99_ms": 12986.59,
          "latency_total_ms": 84100.46,
          "accuracy": 0.1803,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.1667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 11,
          "incorrect": 50,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.1639,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6188,
            "mean_kappa": 0.6188,
            "min_kappa": 0.3779,
            "max_kappa": 0.8806,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9665,
          "total_tokens_output": 1532,
          "total_tokens": 11197,
          "latency_mean_ms": 1339.32,
          "latency_p50_ms": 698.33,
          "latency_p95_ms": 1922.59,
          "latency_p99_ms": 13350.44,
          "latency_total_ms": 81698.71,
          "accuracy": 0.1967,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.1967,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 12,
          "incorrect": 49,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.562,
            "mean_kappa": 0.562,
            "min_kappa": 0.2561,
            "max_kappa": 0.8282,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9632,
          "total_tokens_output": 997,
          "total_tokens": 10629,
          "latency_mean_ms": 832.14,
          "latency_p50_ms": 757.28,
          "latency_p95_ms": 1299.8,
          "latency_p99_ms": 2935.47,
          "latency_total_ms": 50760.37,
          "accuracy": 0.0656,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0656,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 4,
          "incorrect": 57,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0656,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4553,
            "mean_kappa": 0.4553,
            "min_kappa": 0.1953,
            "max_kappa": 0.7125,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9571,
          "total_tokens_output": 1409,
          "total_tokens": 10980,
          "latency_mean_ms": 1254.9,
          "latency_p50_ms": 710.68,
          "latency_p95_ms": 1718.11,
          "latency_p99_ms": 13854.81,
          "latency_total_ms": 76548.63,
          "accuracy": 0.1475,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.1475,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 9,
          "incorrect": 52,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.1475,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6346,
            "mean_kappa": 0.6346,
            "min_kappa": 0.3779,
            "max_kappa": 0.8963,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9671,
          "total_tokens_output": 1631,
          "total_tokens": 11302,
          "latency_mean_ms": 1378.7,
          "latency_p50_ms": 728.25,
          "latency_p95_ms": 1584.92,
          "latency_p99_ms": 12986.59,
          "latency_total_ms": 84100.46,
          "accuracy": 0.1475,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.1333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 9,
          "incorrect": 52,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.1311,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6188,
            "mean_kappa": 0.6188,
            "min_kappa": 0.3779,
            "max_kappa": 0.8806,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9665,
          "total_tokens_output": 1532,
          "total_tokens": 11197,
          "latency_mean_ms": 1339.32,
          "latency_p50_ms": 698.33,
          "latency_p95_ms": 1922.59,
          "latency_p99_ms": 13350.44,
          "latency_total_ms": 81698.71,
          "accuracy": 0.1475,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.1475,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 9,
          "incorrect": 52,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.1475,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.562,
            "mean_kappa": 0.562,
            "min_kappa": 0.2561,
            "max_kappa": 0.8282,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9632,
          "total_tokens_output": 997,
          "total_tokens": 10629,
          "latency_mean_ms": 832.14,
          "latency_p50_ms": 757.28,
          "latency_p95_ms": 1299.8,
          "latency_p99_ms": 2935.47,
          "latency_total_ms": 50760.37,
          "accuracy": 0.3934,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.3934,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 24,
          "incorrect": 37,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4553,
            "mean_kappa": 0.4553,
            "min_kappa": 0.1953,
            "max_kappa": 0.7125,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9571,
          "total_tokens_output": 1409,
          "total_tokens": 10980,
          "latency_mean_ms": 1254.9,
          "latency_p50_ms": 710.68,
          "latency_p95_ms": 1718.11,
          "latency_p99_ms": 13854.81,
          "latency_total_ms": 76548.63,
          "accuracy": 0.4262,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.4262,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 26,
          "incorrect": 35,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.4262,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6346,
            "mean_kappa": 0.6346,
            "min_kappa": 0.3779,
            "max_kappa": 0.8963,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9671,
          "total_tokens_output": 1631,
          "total_tokens": 11302,
          "latency_mean_ms": 1378.7,
          "latency_p50_ms": 728.25,
          "latency_p95_ms": 1584.92,
          "latency_p99_ms": 12986.59,
          "latency_total_ms": 84100.46,
          "accuracy": 0.4262,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.4167,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 26,
          "incorrect": 35,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6188,
            "mean_kappa": 0.6188,
            "min_kappa": 0.3779,
            "max_kappa": 0.8806,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed45__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9665,
          "total_tokens_output": 1532,
          "total_tokens": 11197,
          "latency_mean_ms": 1339.32,
          "latency_p50_ms": 698.33,
          "latency_p95_ms": 1922.59,
          "latency_p99_ms": 13350.44,
          "latency_total_ms": 81698.71,
          "accuracy": 0.541,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.541,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 33,
          "incorrect": 28,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.562,
            "mean_kappa": 0.562,
            "min_kappa": 0.2561,
            "max_kappa": 0.8282,
            "n_items": 61
          }
        },
        "source": "llama-8b_baseline_zero_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.567675,
        "std": 0.07027280323852182
      },
      "mean_kappa": {
        "mean": 0.567675,
        "std": 0.07027280323852182
      },
      "min_kappa": {
        "mean": 0.3018,
        "std": 0.07907774655362912
      },
      "max_kappa": {
        "mean": 0.8294,
        "std": 0.0720487682059867
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "llama-8b",
    "condition": "finetuned_few_shot",
    "finetuned": true,
    "few_shot": true,
    "num_seeds": 20,
    "metrics": {
      "accuracy": {
        "mean": 0.70573,
        "std": 0.08287216722157084
      },
      "exact_match": {
        "mean": 0.4262295081967213,
        "std": 0.0725768643317333
      },
      "exact_match_rate": {
        "mean": 0.42622,
        "std": 0.07256975678614336
      },
      "llm_approval_rate": {
        "mean": 0.48861,
        "std": 0.11669451957996999
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 43.05,
        "std": 5.054453481831641
      },
      "incorrect": {
        "mean": 17.95,
        "std": 5.054453481831641
      },
      "accuracy_from_exact_match": {
        "mean": 0.42622,
        "std": 0.07256975678614336
      },
      "accuracy_boost_from_llm": {
        "mean": 0.27951,
        "std": 0.0748601689819092
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 18722.6,
        "std": 35.57302348690648
      },
      "total_tokens_output": {
        "mean": 778.2,
        "std": 14.5657131648265
      },
      "total_tokens": {
        "mean": 19500.8,
        "std": 43.43454846087386
      },
      "latency_mean_ms": {
        "mean": 1210.152,
        "std": 29.580850156816005
      },
      "latency_p50_ms": {
        "mean": 1171.69,
        "std": 45.563567463489996
      },
      "latency_p95_ms": {
        "mean": 1746.102,
        "std": 38.02294065429449
      },
      "latency_p99_ms": {
        "mean": 2364.2,
        "std": 475.1486042913311
      },
      "latency_total_ms": {
        "mean": 73819.158,
        "std": 1804.467575828396
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 18721,
          "total_tokens_output": 783,
          "total_tokens": 19504,
          "latency_mean_ms": 1213.88,
          "latency_p50_ms": 1222.88,
          "latency_p95_ms": 1692.78,
          "latency_p99_ms": 2069.7,
          "latency_total_ms": 74046.52,
          "accuracy": 0.7213,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.5143,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7945,
            "mean_kappa": 0.7945,
            "min_kappa": 0.6488,
            "max_kappa": 0.9184,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.47540983606557374,
          "total_tokens_input": 18660,
          "total_tokens_output": 759,
          "total_tokens": 19419,
          "latency_mean_ms": 1169.85,
          "latency_p50_ms": 1133.31,
          "latency_p95_ms": 1774.56,
          "latency_p99_ms": 2108.07,
          "latency_total_ms": 71360.65,
          "accuracy": 0.7213,
          "exact_match_rate": 0.4754,
          "llm_approval_rate": 0.4688,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.4754,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7731,
            "mean_kappa": 0.7731,
            "min_kappa": 0.5612,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 18718,
          "total_tokens_output": 793,
          "total_tokens": 19511,
          "latency_mean_ms": 1244.46,
          "latency_p50_ms": 1230.88,
          "latency_p95_ms": 1785.96,
          "latency_p99_ms": 2710.25,
          "latency_total_ms": 75911.85,
          "accuracy": 0.7213,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.5143,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7434,
            "mean_kappa": 0.7434,
            "min_kappa": 0.5612,
            "max_kappa": 0.884,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.29508196721311475,
          "total_tokens_input": 18760,
          "total_tokens_output": 763,
          "total_tokens": 19523,
          "latency_mean_ms": 1183.38,
          "latency_p50_ms": 1125.91,
          "latency_p95_ms": 1769.22,
          "latency_p99_ms": 1820.03,
          "latency_total_ms": 72186.09,
          "accuracy": 0.6393,
          "exact_match_rate": 0.2951,
          "llm_approval_rate": 0.4884,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.2951,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6302,
            "mean_kappa": 0.6302,
            "min_kappa": 0.4475,
            "max_kappa": 0.771,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5081967213114754,
          "total_tokens_input": 18754,
          "total_tokens_output": 793,
          "total_tokens": 19547,
          "latency_mean_ms": 1239.19,
          "latency_p50_ms": 1145.47,
          "latency_p95_ms": 1707.99,
          "latency_p99_ms": 3112.95,
          "latency_total_ms": 75590.68,
          "accuracy": 0.7869,
          "exact_match_rate": 0.5082,
          "llm_approval_rate": 0.5667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 48,
          "incorrect": 13,
          "accuracy_from_exact_match": 0.5082,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.827,
            "mean_kappa": 0.827,
            "min_kappa": 0.7024,
            "max_kappa": 0.9497,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 18721,
          "total_tokens_output": 783,
          "total_tokens": 19504,
          "latency_mean_ms": 1213.88,
          "latency_p50_ms": 1222.88,
          "latency_p95_ms": 1692.78,
          "latency_p99_ms": 2069.7,
          "latency_total_ms": 74046.52,
          "accuracy": 0.7213,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.5143,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7945,
            "mean_kappa": 0.7945,
            "min_kappa": 0.6488,
            "max_kappa": 0.9184,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.47540983606557374,
          "total_tokens_input": 18660,
          "total_tokens_output": 759,
          "total_tokens": 19419,
          "latency_mean_ms": 1169.85,
          "latency_p50_ms": 1133.31,
          "latency_p95_ms": 1774.56,
          "latency_p99_ms": 2108.07,
          "latency_total_ms": 71360.65,
          "accuracy": 0.7213,
          "exact_match_rate": 0.4754,
          "llm_approval_rate": 0.4688,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.4754,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7731,
            "mean_kappa": 0.7731,
            "min_kappa": 0.5612,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 18718,
          "total_tokens_output": 793,
          "total_tokens": 19511,
          "latency_mean_ms": 1244.46,
          "latency_p50_ms": 1230.88,
          "latency_p95_ms": 1785.96,
          "latency_p99_ms": 2710.25,
          "latency_total_ms": 75911.85,
          "accuracy": 0.6721,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.4286,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7434,
            "mean_kappa": 0.7434,
            "min_kappa": 0.5612,
            "max_kappa": 0.884,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.29508196721311475,
          "total_tokens_input": 18760,
          "total_tokens_output": 763,
          "total_tokens": 19523,
          "latency_mean_ms": 1183.38,
          "latency_p50_ms": 1125.91,
          "latency_p95_ms": 1769.22,
          "latency_p99_ms": 1820.03,
          "latency_total_ms": 72186.09,
          "accuracy": 0.5738,
          "exact_match_rate": 0.2951,
          "llm_approval_rate": 0.3953,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.2951,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6302,
            "mean_kappa": 0.6302,
            "min_kappa": 0.4475,
            "max_kappa": 0.771,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5081967213114754,
          "total_tokens_input": 18754,
          "total_tokens_output": 793,
          "total_tokens": 19547,
          "latency_mean_ms": 1239.19,
          "latency_p50_ms": 1145.47,
          "latency_p95_ms": 1707.99,
          "latency_p99_ms": 3112.95,
          "latency_total_ms": 75590.68,
          "accuracy": 0.7377,
          "exact_match_rate": 0.5082,
          "llm_approval_rate": 0.4667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.5082,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.827,
            "mean_kappa": 0.827,
            "min_kappa": 0.7024,
            "max_kappa": 0.9497,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 18721,
          "total_tokens_output": 783,
          "total_tokens": 19504,
          "latency_mean_ms": 1213.88,
          "latency_p50_ms": 1222.88,
          "latency_p95_ms": 1692.78,
          "latency_p99_ms": 2069.7,
          "latency_total_ms": 74046.52,
          "accuracy": 0.6393,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.3714,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7945,
            "mean_kappa": 0.7945,
            "min_kappa": 0.6488,
            "max_kappa": 0.9184,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.47540983606557374,
          "total_tokens_input": 18660,
          "total_tokens_output": 759,
          "total_tokens": 19419,
          "latency_mean_ms": 1169.85,
          "latency_p50_ms": 1133.31,
          "latency_p95_ms": 1774.56,
          "latency_p99_ms": 2108.07,
          "latency_total_ms": 71360.65,
          "accuracy": 0.6393,
          "exact_match_rate": 0.4754,
          "llm_approval_rate": 0.3125,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.4754,
          "accuracy_boost_from_llm": 0.1639,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7731,
            "mean_kappa": 0.7731,
            "min_kappa": 0.5612,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 18718,
          "total_tokens_output": 793,
          "total_tokens": 19511,
          "latency_mean_ms": 1244.46,
          "latency_p50_ms": 1230.88,
          "latency_p95_ms": 1785.96,
          "latency_p99_ms": 2710.25,
          "latency_total_ms": 75911.85,
          "accuracy": 0.6393,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.3714,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7434,
            "mean_kappa": 0.7434,
            "min_kappa": 0.5612,
            "max_kappa": 0.884,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.29508196721311475,
          "total_tokens_input": 18760,
          "total_tokens_output": 763,
          "total_tokens": 19523,
          "latency_mean_ms": 1183.38,
          "latency_p50_ms": 1125.91,
          "latency_p95_ms": 1769.22,
          "latency_p99_ms": 1820.03,
          "latency_total_ms": 72186.09,
          "accuracy": 0.4918,
          "exact_match_rate": 0.2951,
          "llm_approval_rate": 0.2791,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 30,
          "incorrect": 31,
          "accuracy_from_exact_match": 0.2951,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6302,
            "mean_kappa": 0.6302,
            "min_kappa": 0.4475,
            "max_kappa": 0.771,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5081967213114754,
          "total_tokens_input": 18754,
          "total_tokens_output": 793,
          "total_tokens": 19547,
          "latency_mean_ms": 1239.19,
          "latency_p50_ms": 1145.47,
          "latency_p95_ms": 1707.99,
          "latency_p99_ms": 3112.95,
          "latency_total_ms": 75590.68,
          "accuracy": 0.6885,
          "exact_match_rate": 0.5082,
          "llm_approval_rate": 0.3667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.5082,
          "accuracy_boost_from_llm": 0.1803,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.827,
            "mean_kappa": 0.827,
            "min_kappa": 0.7024,
            "max_kappa": 0.9497,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 18721,
          "total_tokens_output": 783,
          "total_tokens": 19504,
          "latency_mean_ms": 1213.88,
          "latency_p50_ms": 1222.88,
          "latency_p95_ms": 1692.78,
          "latency_p99_ms": 2069.7,
          "latency_total_ms": 74046.52,
          "accuracy": 0.7869,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.6286,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 48,
          "incorrect": 13,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7945,
            "mean_kappa": 0.7945,
            "min_kappa": 0.6488,
            "max_kappa": 0.9184,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.47540983606557374,
          "total_tokens_input": 18660,
          "total_tokens_output": 759,
          "total_tokens": 19419,
          "latency_mean_ms": 1169.85,
          "latency_p50_ms": 1133.31,
          "latency_p95_ms": 1774.56,
          "latency_p99_ms": 2108.07,
          "latency_total_ms": 71360.65,
          "accuracy": 0.8197,
          "exact_match_rate": 0.4754,
          "llm_approval_rate": 0.6562,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 50,
          "incorrect": 11,
          "accuracy_from_exact_match": 0.4754,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7731,
            "mean_kappa": 0.7731,
            "min_kappa": 0.5612,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 18718,
          "total_tokens_output": 793,
          "total_tokens": 19511,
          "latency_mean_ms": 1244.46,
          "latency_p50_ms": 1230.88,
          "latency_p95_ms": 1785.96,
          "latency_p99_ms": 2710.25,
          "latency_total_ms": 75911.85,
          "accuracy": 0.8197,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.6857,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 50,
          "incorrect": 11,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7434,
            "mean_kappa": 0.7434,
            "min_kappa": 0.5612,
            "max_kappa": 0.884,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed44__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.29508196721311475,
          "total_tokens_input": 18760,
          "total_tokens_output": 763,
          "total_tokens": 19523,
          "latency_mean_ms": 1183.38,
          "latency_p50_ms": 1125.91,
          "latency_p95_ms": 1769.22,
          "latency_p99_ms": 1820.03,
          "latency_total_ms": 72186.09,
          "accuracy": 0.7705,
          "exact_match_rate": 0.2951,
          "llm_approval_rate": 0.6744,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.2951,
          "accuracy_boost_from_llm": 0.4754,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6302,
            "mean_kappa": 0.6302,
            "min_kappa": 0.4475,
            "max_kappa": 0.771,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed45__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5081967213114754,
          "total_tokens_input": 18754,
          "total_tokens_output": 793,
          "total_tokens": 19547,
          "latency_mean_ms": 1239.19,
          "latency_p50_ms": 1145.47,
          "latency_p95_ms": 1707.99,
          "latency_p99_ms": 3112.95,
          "latency_total_ms": 75590.68,
          "accuracy": 0.8033,
          "exact_match_rate": 0.5082,
          "llm_approval_rate": 0.6,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.5082,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.827,
            "mean_kappa": 0.827,
            "min_kappa": 0.7024,
            "max_kappa": 0.9497,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_few_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.75364,
        "std": 0.06748660904209071
      },
      "mean_kappa": {
        "mean": 0.75364,
        "std": 0.06748660904209071
      },
      "min_kappa": {
        "mean": 0.5842200000000001,
        "std": 0.08705089086275913
      },
      "max_kappa": {
        "mean": 0.90462,
        "std": 0.07694014296841407
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "llama-8b",
    "condition": "finetuned_zero_shot",
    "finetuned": true,
    "few_shot": false,
    "num_seeds": 20,
    "metrics": {
      "accuracy": {
        "mean": 0.70738,
        "std": 0.08168490435814932
      },
      "exact_match": {
        "mean": 0.4262295081967213,
        "std": 0.05286726392326918
      },
      "exact_match_rate": {
        "mean": 0.42622,
        "std": 0.052857408184662245
      },
      "llm_approval_rate": {
        "mean": 0.491205,
        "std": 0.12507419987751273
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 43.15,
        "std": 4.982720140646071
      },
      "incorrect": {
        "mean": 17.85,
        "std": 4.982720140646071
      },
      "accuracy_from_exact_match": {
        "mean": 0.42622,
        "std": 0.052857408184662245
      },
      "accuracy_boost_from_llm": {
        "mean": 0.281145,
        "std": 0.0748202343955163
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 9633.6,
        "std": 35.57302348690648
      },
      "total_tokens_output": {
        "mean": 775.4,
        "std": 13.215142829345432
      },
      "total_tokens": {
        "mean": 10409,
        "std": 47.82467982119692
      },
      "latency_mean_ms": {
        "mean": 1183.3780000000002,
        "std": 50.88328582157405
      },
      "latency_p50_ms": {
        "mean": 1162.81,
        "std": 65.2762768546124
      },
      "latency_p95_ms": {
        "mean": 1682.658,
        "std": 69.3190153998165
      },
      "latency_p99_ms": {
        "mean": 2353.302,
        "std": 358.33797261244865
      },
      "latency_total_ms": {
        "mean": 72186.212,
        "std": 3103.9453590061794
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 9632,
          "total_tokens_output": 766,
          "total_tokens": 10398,
          "latency_mean_ms": 1140.93,
          "latency_p50_ms": 1174.66,
          "latency_p95_ms": 1617.34,
          "latency_p99_ms": 1660.13,
          "latency_total_ms": 69597.02,
          "accuracy": 0.7049,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.4857,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7632,
            "mean_kappa": 0.7632,
            "min_kappa": 0.6362,
            "max_kappa": 0.8424,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4426229508196721,
          "total_tokens_input": 9571,
          "total_tokens_output": 754,
          "total_tokens": 10325,
          "latency_mean_ms": 1121.38,
          "latency_p50_ms": 1086.58,
          "latency_p95_ms": 1698.79,
          "latency_p99_ms": 2440.58,
          "latency_total_ms": 68404.03,
          "accuracy": 0.7377,
          "exact_match_rate": 0.4426,
          "llm_approval_rate": 0.5294,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.4426,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7588,
            "mean_kappa": 0.7588,
            "min_kappa": 0.5481,
            "max_kappa": 0.9585,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 9629,
          "total_tokens_output": 783,
          "total_tokens": 10412,
          "latency_mean_ms": 1256.45,
          "latency_p50_ms": 1250.44,
          "latency_p95_ms": 1668.36,
          "latency_p99_ms": 2465.53,
          "latency_total_ms": 76643.67,
          "accuracy": 0.7377,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.5556,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8043,
            "mean_kappa": 0.8043,
            "min_kappa": 0.6544,
            "max_kappa": 0.9585,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 9671,
          "total_tokens_output": 787,
          "total_tokens": 10458,
          "latency_mean_ms": 1226.16,
          "latency_p50_ms": 1212.03,
          "latency_p95_ms": 1807.35,
          "latency_p99_ms": 2501.45,
          "latency_total_ms": 74795.91,
          "accuracy": 0.623,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.425,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6732,
            "mean_kappa": 0.6732,
            "min_kappa": 0.4707,
            "max_kappa": 0.8299,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5081967213114754,
          "total_tokens_input": 9665,
          "total_tokens_output": 787,
          "total_tokens": 10452,
          "latency_mean_ms": 1171.97,
          "latency_p50_ms": 1090.34,
          "latency_p95_ms": 1621.45,
          "latency_p99_ms": 2698.82,
          "latency_total_ms": 71490.43,
          "accuracy": 0.7541,
          "exact_match_rate": 0.5082,
          "llm_approval_rate": 0.5,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.5082,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7545,
            "mean_kappa": 0.7545,
            "min_kappa": 0.5906,
            "max_kappa": 0.8703,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 9632,
          "total_tokens_output": 766,
          "total_tokens": 10398,
          "latency_mean_ms": 1140.93,
          "latency_p50_ms": 1174.66,
          "latency_p95_ms": 1617.34,
          "latency_p99_ms": 1660.13,
          "latency_total_ms": 69597.02,
          "accuracy": 0.7049,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.4857,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7632,
            "mean_kappa": 0.7632,
            "min_kappa": 0.6362,
            "max_kappa": 0.8424,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4426229508196721,
          "total_tokens_input": 9571,
          "total_tokens_output": 754,
          "total_tokens": 10325,
          "latency_mean_ms": 1121.38,
          "latency_p50_ms": 1086.58,
          "latency_p95_ms": 1698.79,
          "latency_p99_ms": 2440.58,
          "latency_total_ms": 68404.03,
          "accuracy": 0.7213,
          "exact_match_rate": 0.4426,
          "llm_approval_rate": 0.5,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.4426,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7588,
            "mean_kappa": 0.7588,
            "min_kappa": 0.5481,
            "max_kappa": 0.9585,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 9629,
          "total_tokens_output": 783,
          "total_tokens": 10412,
          "latency_mean_ms": 1256.45,
          "latency_p50_ms": 1250.44,
          "latency_p95_ms": 1668.36,
          "latency_p99_ms": 2465.53,
          "latency_total_ms": 76643.67,
          "accuracy": 0.7213,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.5278,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8043,
            "mean_kappa": 0.8043,
            "min_kappa": 0.6544,
            "max_kappa": 0.9585,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 9671,
          "total_tokens_output": 787,
          "total_tokens": 10458,
          "latency_mean_ms": 1226.16,
          "latency_p50_ms": 1212.03,
          "latency_p95_ms": 1807.35,
          "latency_p99_ms": 2501.45,
          "latency_total_ms": 74795.91,
          "accuracy": 0.5738,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.35,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6732,
            "mean_kappa": 0.6732,
            "min_kappa": 0.4707,
            "max_kappa": 0.8299,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5081967213114754,
          "total_tokens_input": 9665,
          "total_tokens_output": 787,
          "total_tokens": 10452,
          "latency_mean_ms": 1171.97,
          "latency_p50_ms": 1090.34,
          "latency_p95_ms": 1621.45,
          "latency_p99_ms": 2698.82,
          "latency_total_ms": 71490.43,
          "accuracy": 0.7377,
          "exact_match_rate": 0.5082,
          "llm_approval_rate": 0.4667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.5082,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7545,
            "mean_kappa": 0.7545,
            "min_kappa": 0.5906,
            "max_kappa": 0.8703,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 9632,
          "total_tokens_output": 766,
          "total_tokens": 10398,
          "latency_mean_ms": 1140.93,
          "latency_p50_ms": 1174.66,
          "latency_p95_ms": 1617.34,
          "latency_p99_ms": 1660.13,
          "latency_total_ms": 69597.02,
          "accuracy": 0.6557,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.4,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7632,
            "mean_kappa": 0.7632,
            "min_kappa": 0.6362,
            "max_kappa": 0.8424,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4426229508196721,
          "total_tokens_input": 9571,
          "total_tokens_output": 754,
          "total_tokens": 10325,
          "latency_mean_ms": 1121.38,
          "latency_p50_ms": 1086.58,
          "latency_p95_ms": 1698.79,
          "latency_p99_ms": 2440.58,
          "latency_total_ms": 68404.03,
          "accuracy": 0.6066,
          "exact_match_rate": 0.4426,
          "llm_approval_rate": 0.2941,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.4426,
          "accuracy_boost_from_llm": 0.1639,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7588,
            "mean_kappa": 0.7588,
            "min_kappa": 0.5481,
            "max_kappa": 0.9585,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 9629,
          "total_tokens_output": 783,
          "total_tokens": 10412,
          "latency_mean_ms": 1256.45,
          "latency_p50_ms": 1250.44,
          "latency_p95_ms": 1668.36,
          "latency_p99_ms": 2465.53,
          "latency_total_ms": 76643.67,
          "accuracy": 0.6885,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.4722,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8043,
            "mean_kappa": 0.8043,
            "min_kappa": 0.6544,
            "max_kappa": 0.9585,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 9671,
          "total_tokens_output": 787,
          "total_tokens": 10458,
          "latency_mean_ms": 1226.16,
          "latency_p50_ms": 1212.03,
          "latency_p95_ms": 1807.35,
          "latency_p99_ms": 2501.45,
          "latency_total_ms": 74795.91,
          "accuracy": 0.5082,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.25,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 31,
          "incorrect": 30,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.1639,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6732,
            "mean_kappa": 0.6732,
            "min_kappa": 0.4707,
            "max_kappa": 0.8299,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5081967213114754,
          "total_tokens_input": 9665,
          "total_tokens_output": 787,
          "total_tokens": 10452,
          "latency_mean_ms": 1171.97,
          "latency_p50_ms": 1090.34,
          "latency_p95_ms": 1621.45,
          "latency_p99_ms": 2698.82,
          "latency_total_ms": 71490.43,
          "accuracy": 0.6557,
          "exact_match_rate": 0.5082,
          "llm_approval_rate": 0.3,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.5082,
          "accuracy_boost_from_llm": 0.1475,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7545,
            "mean_kappa": 0.7545,
            "min_kappa": 0.5906,
            "max_kappa": 0.8703,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 9632,
          "total_tokens_output": 766,
          "total_tokens": 10398,
          "latency_mean_ms": 1140.93,
          "latency_p50_ms": 1174.66,
          "latency_p95_ms": 1617.34,
          "latency_p99_ms": 1660.13,
          "latency_total_ms": 69597.02,
          "accuracy": 0.8033,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.6571,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7632,
            "mean_kappa": 0.7632,
            "min_kappa": 0.6362,
            "max_kappa": 0.8424,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4426229508196721,
          "total_tokens_input": 9571,
          "total_tokens_output": 754,
          "total_tokens": 10325,
          "latency_mean_ms": 1121.38,
          "latency_p50_ms": 1086.58,
          "latency_p95_ms": 1698.79,
          "latency_p99_ms": 2440.58,
          "latency_total_ms": 68404.03,
          "accuracy": 0.8033,
          "exact_match_rate": 0.4426,
          "llm_approval_rate": 0.6471,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.4426,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7588,
            "mean_kappa": 0.7588,
            "min_kappa": 0.5481,
            "max_kappa": 0.9585,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 9629,
          "total_tokens_output": 783,
          "total_tokens": 10412,
          "latency_mean_ms": 1256.45,
          "latency_p50_ms": 1250.44,
          "latency_p95_ms": 1668.36,
          "latency_p99_ms": 2465.53,
          "latency_total_ms": 76643.67,
          "accuracy": 0.8197,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.6944,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 50,
          "incorrect": 11,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8043,
            "mean_kappa": 0.8043,
            "min_kappa": 0.6544,
            "max_kappa": 0.9585,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed44__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 9671,
          "total_tokens_output": 787,
          "total_tokens": 10458,
          "latency_mean_ms": 1226.16,
          "latency_p50_ms": 1212.03,
          "latency_p95_ms": 1807.35,
          "latency_p99_ms": 2501.45,
          "latency_total_ms": 74795.91,
          "accuracy": 0.7705,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.65,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.4262,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6732,
            "mean_kappa": 0.6732,
            "min_kappa": 0.4707,
            "max_kappa": 0.8299,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed45__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5081967213114754,
          "total_tokens_input": 9665,
          "total_tokens_output": 787,
          "total_tokens": 10452,
          "latency_mean_ms": 1171.97,
          "latency_p50_ms": 1090.34,
          "latency_p95_ms": 1621.45,
          "latency_p99_ms": 2698.82,
          "latency_total_ms": 71490.43,
          "accuracy": 0.8197,
          "exact_match_rate": 0.5082,
          "llm_approval_rate": 0.6333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 50,
          "incorrect": 11,
          "accuracy_from_exact_match": 0.5082,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7545,
            "mean_kappa": 0.7545,
            "min_kappa": 0.5906,
            "max_kappa": 0.8703,
            "n_items": 61
          }
        },
        "source": "llama-8b_finetuned_zero_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.7508,
        "std": 0.04269768143588126
      },
      "mean_kappa": {
        "mean": 0.7508,
        "std": 0.04269768143588126
      },
      "min_kappa": {
        "mean": 0.58,
        "std": 0.06598524077397913
      },
      "max_kappa": {
        "mean": 0.89192,
        "std": 0.05591409124719816
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "mistral",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.581975,
        "std": 0.12061522240165211
      },
      "exact_match": {
        "mean": 0.028688524590163935,
        "std": 0.021295706650437014
      },
      "exact_match_rate": {
        "mean": 0.0287,
        "std": 0.02130422493309719
      },
      "llm_approval_rate": {
        "mean": 0.5695125,
        "std": 0.12373077060194042
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 35.5,
        "std": 7.3569694847810805
      },
      "incorrect": {
        "mean": 25.5,
        "std": 7.3569694847810805
      },
      "accuracy_from_exact_match": {
        "mean": 0.0287,
        "std": 0.02130422493309719
      },
      "accuracy_boost_from_llm": {
        "mean": 0.553275,
        "std": 0.1217940962239139
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 23534.25,
        "std": 39.55613100392909
      },
      "total_tokens_output": {
        "mean": 1735,
        "std": 150.9055996310276
      },
      "total_tokens": {
        "mean": 25269.25,
        "std": 118.56722776551706
      },
      "latency_mean_ms": {
        "mean": 1478.8275,
        "std": 133.86816768279903
      },
      "latency_p50_ms": {
        "mean": 1295.4425,
        "std": 39.82945855456741
      },
      "latency_p95_ms": {
        "mean": 1913.3525,
        "std": 83.81102027030809
      },
      "latency_p99_ms": {
        "mean": 6796.6224999999995,
        "std": 4063.1230788358785
      },
      "latency_total_ms": {
        "mean": 90208.4625,
        "std": 8165.827946572149
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 23537,
          "total_tokens_output": 1818,
          "total_tokens": 25355,
          "latency_mean_ms": 1593.8,
          "latency_p50_ms": 1332.67,
          "latency_p95_ms": 2001.75,
          "latency_p99_ms": 7444.57,
          "latency_total_ms": 97221.76,
          "accuracy": 0.5902,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.569,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.636,
            "mean_kappa": 0.636,
            "min_kappa": 0.4035,
            "max_kappa": 0.7415,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 23474,
          "total_tokens_output": 1941,
          "total_tokens": 25415,
          "latency_mean_ms": 1630.13,
          "latency_p50_ms": 1229.77,
          "latency_p95_ms": 1927.87,
          "latency_p99_ms": 13170.31,
          "latency_total_ms": 99437.7,
          "accuracy": 0.5738,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.5517,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.5246,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6737,
            "mean_kappa": 0.6737,
            "min_kappa": 0.4874,
            "max_kappa": 0.8365,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 23541,
          "total_tokens_output": 1592,
          "total_tokens": 25133,
          "latency_mean_ms": 1353.45,
          "latency_p50_ms": 1298.66,
          "latency_p95_ms": 1947.85,
          "latency_p99_ms": 2873.21,
          "latency_total_ms": 82560.4,
          "accuracy": 0.5574,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.55,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.556,
            "mean_kappa": 0.556,
            "min_kappa": 0.3428,
            "max_kappa": 0.7066,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 23585,
          "total_tokens_output": 1589,
          "total_tokens": 25174,
          "latency_mean_ms": 1337.93,
          "latency_p50_ms": 1320.67,
          "latency_p95_ms": 1775.94,
          "latency_p99_ms": 3698.4,
          "latency_total_ms": 81613.99,
          "accuracy": 0.5902,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.5902,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.5902,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5719,
            "mean_kappa": 0.5719,
            "min_kappa": 0.2996,
            "max_kappa": 0.8356,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 23537,
          "total_tokens_output": 1818,
          "total_tokens": 25355,
          "latency_mean_ms": 1593.8,
          "latency_p50_ms": 1332.67,
          "latency_p95_ms": 2001.75,
          "latency_p99_ms": 7444.57,
          "latency_total_ms": 97221.76,
          "accuracy": 0.5902,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.569,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.636,
            "mean_kappa": 0.636,
            "min_kappa": 0.4035,
            "max_kappa": 0.7415,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 23474,
          "total_tokens_output": 1941,
          "total_tokens": 25415,
          "latency_mean_ms": 1630.13,
          "latency_p50_ms": 1229.77,
          "latency_p95_ms": 1927.87,
          "latency_p99_ms": 13170.31,
          "latency_total_ms": 99437.7,
          "accuracy": 0.5246,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.5,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 32,
          "incorrect": 29,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4754,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6737,
            "mean_kappa": 0.6737,
            "min_kappa": 0.4874,
            "max_kappa": 0.8365,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 23541,
          "total_tokens_output": 1592,
          "total_tokens": 25133,
          "latency_mean_ms": 1353.45,
          "latency_p50_ms": 1298.66,
          "latency_p95_ms": 1947.85,
          "latency_p99_ms": 2873.21,
          "latency_total_ms": 82560.4,
          "accuracy": 0.4754,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.4667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.556,
            "mean_kappa": 0.556,
            "min_kappa": 0.3428,
            "max_kappa": 0.7066,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 23585,
          "total_tokens_output": 1589,
          "total_tokens": 25174,
          "latency_mean_ms": 1337.93,
          "latency_p50_ms": 1320.67,
          "latency_p95_ms": 1775.94,
          "latency_p99_ms": 3698.4,
          "latency_total_ms": 81613.99,
          "accuracy": 0.5082,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.5082,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 31,
          "incorrect": 30,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.5082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5719,
            "mean_kappa": 0.5719,
            "min_kappa": 0.2996,
            "max_kappa": 0.8356,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 23537,
          "total_tokens_output": 1818,
          "total_tokens": 25355,
          "latency_mean_ms": 1593.8,
          "latency_p50_ms": 1332.67,
          "latency_p95_ms": 2001.75,
          "latency_p99_ms": 7444.57,
          "latency_total_ms": 97221.76,
          "accuracy": 0.459,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.431,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 28,
          "incorrect": 33,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.636,
            "mean_kappa": 0.636,
            "min_kappa": 0.4035,
            "max_kappa": 0.7415,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 23474,
          "total_tokens_output": 1941,
          "total_tokens": 25415,
          "latency_mean_ms": 1630.13,
          "latency_p50_ms": 1229.77,
          "latency_p95_ms": 1927.87,
          "latency_p99_ms": 13170.31,
          "latency_total_ms": 99437.7,
          "accuracy": 0.4754,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.4483,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.4262,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6737,
            "mean_kappa": 0.6737,
            "min_kappa": 0.4874,
            "max_kappa": 0.8365,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 23541,
          "total_tokens_output": 1592,
          "total_tokens": 25133,
          "latency_mean_ms": 1353.45,
          "latency_p50_ms": 1298.66,
          "latency_p95_ms": 1947.85,
          "latency_p99_ms": 2873.21,
          "latency_total_ms": 82560.4,
          "accuracy": 0.4098,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.4,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 25,
          "incorrect": 36,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.556,
            "mean_kappa": 0.556,
            "min_kappa": 0.3428,
            "max_kappa": 0.7066,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 23585,
          "total_tokens_output": 1589,
          "total_tokens": 25174,
          "latency_mean_ms": 1337.93,
          "latency_p50_ms": 1320.67,
          "latency_p95_ms": 1775.94,
          "latency_p99_ms": 3698.4,
          "latency_total_ms": 81613.99,
          "accuracy": 0.4754,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.4754,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.4754,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5719,
            "mean_kappa": 0.5719,
            "min_kappa": 0.2996,
            "max_kappa": 0.8356,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 23537,
          "total_tokens_output": 1818,
          "total_tokens": 25355,
          "latency_mean_ms": 1593.8,
          "latency_p50_ms": 1332.67,
          "latency_p95_ms": 2001.75,
          "latency_p99_ms": 7444.57,
          "latency_total_ms": 97221.76,
          "accuracy": 0.7705,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.7586,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.7213,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.636,
            "mean_kappa": 0.636,
            "min_kappa": 0.4035,
            "max_kappa": 0.7415,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 23474,
          "total_tokens_output": 1941,
          "total_tokens": 25415,
          "latency_mean_ms": 1630.13,
          "latency_p50_ms": 1229.77,
          "latency_p95_ms": 1927.87,
          "latency_p99_ms": 13170.31,
          "latency_total_ms": 99437.7,
          "accuracy": 0.7377,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.7241,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.6885,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6737,
            "mean_kappa": 0.6737,
            "min_kappa": 0.4874,
            "max_kappa": 0.8365,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed43__judge-llama-70b.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 23541,
          "total_tokens_output": 1592,
          "total_tokens": 25133,
          "latency_mean_ms": 1353.45,
          "latency_p50_ms": 1298.66,
          "latency_p95_ms": 1947.85,
          "latency_p99_ms": 2873.21,
          "latency_total_ms": 82560.4,
          "accuracy": 0.7705,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.7667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.7541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.556,
            "mean_kappa": 0.556,
            "min_kappa": 0.3428,
            "max_kappa": 0.7066,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed44__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 23585,
          "total_tokens_output": 1589,
          "total_tokens": 25174,
          "latency_mean_ms": 1337.93,
          "latency_p50_ms": 1320.67,
          "latency_p95_ms": 1775.94,
          "latency_p99_ms": 3698.4,
          "latency_total_ms": 81613.99,
          "accuracy": 0.8033,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.8033,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.8033,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5719,
            "mean_kappa": 0.5719,
            "min_kappa": 0.2996,
            "max_kappa": 0.8356,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_few_shot_seed45__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.6093999999999999,
        "std": 0.04769659316974325
      },
      "mean_kappa": {
        "mean": 0.6093999999999999,
        "std": 0.04769659316974325
      },
      "min_kappa": {
        "mean": 0.383325,
        "std": 0.07051735158810207
      },
      "max_kappa": {
        "mean": 0.78005,
        "std": 0.057344158377292447
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "mistral",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 11,
    "metrics": {
      "accuracy": {
        "mean": 0.09092727272727273,
        "std": 0.06716925826744216
      },
      "exact_match": {
        "mean": 0.0,
        "std": 0.0
      },
      "exact_match_rate": {
        "mean": 0.0,
        "std": 0.0
      },
      "llm_approval_rate": {
        "mean": 0.09092727272727273,
        "std": 0.06716925826744216
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 5.545454545454546,
        "std": 4.09797369803078
      },
      "incorrect": {
        "mean": 55.45454545454545,
        "std": 4.09797369803078
      },
      "accuracy_from_exact_match": {
        "mean": 0.0,
        "std": 0.0
      },
      "accuracy_boost_from_llm": {
        "mean": 0.09092727272727273,
        "std": 0.06716925826744216
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 12663.454545454546,
        "std": 37.42231623064125
      },
      "total_tokens_output": {
        "mean": 3653.5454545454545,
        "std": 380.70374156681885
      },
      "total_tokens": {
        "mean": 16317,
        "std": 416.87887929229515
      },
      "latency_mean_ms": {
        "mean": 3019.9672727272728,
        "std": 375.30226986429125
      },
      "latency_p50_ms": {
        "mean": 1483.7436363636364,
        "std": 116.11463483618458
      },
      "latency_p95_ms": {
        "mean": 12783.469090909091,
        "std": 407.68126987668245
      },
      "latency_p99_ms": {
        "mean": 12978.043636363636,
        "std": 380.71240950409447
      },
      "latency_total_ms": {
        "mean": 184217.74636363637,
        "std": 22893.466474782417
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 12679,
          "total_tokens_output": 3934,
          "total_tokens": 16613,
          "latency_mean_ms": 3185.73,
          "latency_p50_ms": 1586.92,
          "latency_p95_ms": 12572.07,
          "latency_p99_ms": 12808.5,
          "latency_total_ms": 194329.31,
          "accuracy": 0.082,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.082,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 5,
          "incorrect": 56,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5954,
            "mean_kappa": 0.5954,
            "min_kappa": 0.4116,
            "max_kappa": 0.8802,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 12616,
          "total_tokens_output": 3150,
          "total_tokens": 15766,
          "latency_mean_ms": 2541.19,
          "latency_p50_ms": 1331.4,
          "latency_p95_ms": 12497.1,
          "latency_p99_ms": 12685.74,
          "latency_total_ms": 155012.29,
          "accuracy": 0.0328,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0328,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 2,
          "incorrect": 59,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0328,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5129,
            "mean_kappa": 0.5129,
            "min_kappa": 0.1528,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 12706,
          "total_tokens_output": 3951,
          "total_tokens": 16657,
          "latency_mean_ms": 3437.32,
          "latency_p50_ms": 1549.3,
          "latency_p95_ms": 13447.16,
          "latency_p99_ms": 13593.84,
          "latency_total_ms": 209676.27,
          "accuracy": 0.0492,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0492,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 3,
          "incorrect": 58,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0492,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7409,
            "mean_kappa": 0.7409,
            "min_kappa": 0.6405,
            "max_kappa": 0.8486,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 12679,
          "total_tokens_output": 3934,
          "total_tokens": 16613,
          "latency_mean_ms": 3185.73,
          "latency_p50_ms": 1586.92,
          "latency_p95_ms": 12572.07,
          "latency_p99_ms": 12808.5,
          "latency_total_ms": 194329.31,
          "accuracy": 0.0656,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0656,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 4,
          "incorrect": 57,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0656,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5954,
            "mean_kappa": 0.5954,
            "min_kappa": 0.4116,
            "max_kappa": 0.8802,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 12616,
          "total_tokens_output": 3150,
          "total_tokens": 15766,
          "latency_mean_ms": 2541.19,
          "latency_p50_ms": 1331.4,
          "latency_p95_ms": 12497.1,
          "latency_p99_ms": 12685.74,
          "latency_total_ms": 155012.29,
          "accuracy": 0.0492,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0492,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 3,
          "incorrect": 58,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0492,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5129,
            "mean_kappa": 0.5129,
            "min_kappa": 0.1528,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 12706,
          "total_tokens_output": 3951,
          "total_tokens": 16657,
          "latency_mean_ms": 3437.32,
          "latency_p50_ms": 1549.3,
          "latency_p95_ms": 13447.16,
          "latency_p99_ms": 13593.84,
          "latency_total_ms": 209676.27,
          "accuracy": 0.0656,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0656,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 4,
          "incorrect": 57,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0656,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7409,
            "mean_kappa": 0.7409,
            "min_kappa": 0.6405,
            "max_kappa": 0.8486,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 12679,
          "total_tokens_output": 3934,
          "total_tokens": 16613,
          "latency_mean_ms": 3185.73,
          "latency_p50_ms": 1586.92,
          "latency_p95_ms": 12572.07,
          "latency_p99_ms": 12808.5,
          "latency_total_ms": 194329.31,
          "accuracy": 0.0656,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0656,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 4,
          "incorrect": 57,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0656,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5954,
            "mean_kappa": 0.5954,
            "min_kappa": 0.4116,
            "max_kappa": 0.8802,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 12616,
          "total_tokens_output": 3150,
          "total_tokens": 15766,
          "latency_mean_ms": 2541.19,
          "latency_p50_ms": 1331.4,
          "latency_p95_ms": 12497.1,
          "latency_p99_ms": 12685.74,
          "latency_total_ms": 155012.29,
          "accuracy": 0.0492,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0492,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 3,
          "incorrect": 58,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0492,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5129,
            "mean_kappa": 0.5129,
            "min_kappa": 0.1528,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 12706,
          "total_tokens_output": 3951,
          "total_tokens": 16657,
          "latency_mean_ms": 3437.32,
          "latency_p50_ms": 1549.3,
          "latency_p95_ms": 13447.16,
          "latency_p99_ms": 13593.84,
          "latency_total_ms": 209676.27,
          "accuracy": 0.082,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.082,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 5,
          "incorrect": 56,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7409,
            "mean_kappa": 0.7409,
            "min_kappa": 0.6405,
            "max_kappa": 0.8486,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 12679,
          "total_tokens_output": 3934,
          "total_tokens": 16613,
          "latency_mean_ms": 3185.73,
          "latency_p50_ms": 1586.92,
          "latency_p95_ms": 12572.07,
          "latency_p99_ms": 12808.5,
          "latency_total_ms": 194329.31,
          "accuracy": 0.2131,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2131,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 13,
          "incorrect": 48,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5954,
            "mean_kappa": 0.5954,
            "min_kappa": 0.4116,
            "max_kappa": 0.8802,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_zero_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 12616,
          "total_tokens_output": 3150,
          "total_tokens": 15766,
          "latency_mean_ms": 2541.19,
          "latency_p50_ms": 1331.4,
          "latency_p95_ms": 12497.1,
          "latency_p99_ms": 12685.74,
          "latency_total_ms": 155012.29,
          "accuracy": 0.2459,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2459,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 15,
          "incorrect": 46,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5129,
            "mean_kappa": 0.5129,
            "min_kappa": 0.1528,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "mistral_baseline_zero_shot_seed43__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.6050818181818182,
        "std": 0.09030485558456289
      },
      "mean_kappa": {
        "mean": 0.6050818181818182,
        "std": 0.09030485558456289
      },
      "min_kappa": {
        "mean": 0.3799181818181818,
        "std": 0.19401365377529403
      },
      "max_kappa": {
        "mean": 0.9151454545454546,
        "std": 0.06534579855223863
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "mistral",
    "condition": "finetuned_few_shot",
    "finetuned": true,
    "few_shot": true,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.67314375,
        "std": 0.07296007443072891
      },
      "exact_match": {
        "mean": 0.41700819672131145,
        "std": 0.08497923889239331
      },
      "exact_match_rate": {
        "mean": 0.4170125,
        "std": 0.08497751816657154
      },
      "llm_approval_rate": {
        "mean": 0.43498749999999997,
        "std": 0.11218173801359115
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 41.0625,
        "std": 4.450684638344982
      },
      "incorrect": {
        "mean": 19.9375,
        "std": 4.450684638344982
      },
      "accuracy_from_exact_match": {
        "mean": 0.4170125,
        "std": 0.08497751816657154
      },
      "accuracy_boost_from_llm": {
        "mean": 0.25615,
        "std": 0.08256369510868564
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 23521.25,
        "std": 72.83757615407036
      },
      "total_tokens_output": {
        "mean": 1351.4375,
        "std": 51.79764563906356
      },
      "total_tokens": {
        "mean": 24872.6875,
        "std": 112.66805156631581
      },
      "latency_mean_ms": {
        "mean": 2032.313125,
        "std": 90.83789770235978
      },
      "latency_p50_ms": {
        "mean": 1991.546875,
        "std": 93.03483478775227
      },
      "latency_p95_ms": {
        "mean": 2547.4625,
        "std": 126.8812509051278
      },
      "latency_p99_ms": {
        "mean": 3285.2581250000003,
        "std": 1026.8886421626905
      },
      "latency_total_ms": {
        "mean": 123971.046875,
        "std": 5541.120294024169
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 23537,
          "total_tokens_output": 1358,
          "total_tokens": 24895,
          "latency_mean_ms": 2097.94,
          "latency_p50_ms": 2069.29,
          "latency_p95_ms": 2706.74,
          "latency_p99_ms": 2715.65,
          "latency_total_ms": 127974.14,
          "accuracy": 0.7377,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.5789,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8052,
            "mean_kappa": 0.8052,
            "min_kappa": 0.6685,
            "max_kappa": 0.9186,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 23374,
          "total_tokens_output": 1293,
          "total_tokens": 24667,
          "latency_mean_ms": 1848.37,
          "latency_p50_ms": 1823.41,
          "latency_p95_ms": 2345.02,
          "latency_p99_ms": 2502.4,
          "latency_total_ms": 112750.48,
          "accuracy": 0.7541,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.4828,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7957,
            "mean_kappa": 0.7957,
            "min_kappa": 0.6976,
            "max_kappa": 0.9568,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 23541,
          "total_tokens_output": 1361,
          "total_tokens": 24902,
          "latency_mean_ms": 2079.35,
          "latency_p50_ms": 2051.93,
          "latency_p95_ms": 2523.46,
          "latency_p99_ms": 3439.77,
          "latency_total_ms": 126840.26,
          "accuracy": 0.6557,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.475,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8171,
            "mean_kappa": 0.8171,
            "min_kappa": 0.7629,
            "max_kappa": 0.8923,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.32786885245901637,
          "total_tokens_input": 23585,
          "total_tokens_output": 1442,
          "total_tokens": 25027,
          "latency_mean_ms": 2079.35,
          "latency_p50_ms": 1938.01,
          "latency_p95_ms": 2626.53,
          "latency_p99_ms": 5319.25,
          "latency_total_ms": 126840.55,
          "accuracy": 0.6721,
          "exact_match_rate": 0.3279,
          "llm_approval_rate": 0.5122,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.3279,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7758,
            "mean_kappa": 0.7758,
            "min_kappa": 0.6998,
            "max_kappa": 0.8349,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 23564,
          "total_tokens_output": 1301,
          "total_tokens": 24865,
          "latency_mean_ms": 2034.68,
          "latency_p50_ms": 2049.18,
          "latency_p95_ms": 2482.47,
          "latency_p99_ms": 2639.09,
          "latency_total_ms": 124115.44,
          "accuracy": 0.7377,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.4483,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8435,
            "mean_kappa": 0.8435,
            "min_kappa": 0.8003,
            "max_kappa": 0.887,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 23537,
          "total_tokens_output": 1358,
          "total_tokens": 24895,
          "latency_mean_ms": 2097.94,
          "latency_p50_ms": 2069.29,
          "latency_p95_ms": 2706.74,
          "latency_p99_ms": 2715.65,
          "latency_total_ms": 127974.14,
          "accuracy": 0.7049,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.5263,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8052,
            "mean_kappa": 0.8052,
            "min_kappa": 0.6685,
            "max_kappa": 0.9186,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 23374,
          "total_tokens_output": 1293,
          "total_tokens": 24667,
          "latency_mean_ms": 1848.37,
          "latency_p50_ms": 1823.41,
          "latency_p95_ms": 2345.02,
          "latency_p99_ms": 2502.4,
          "latency_total_ms": 112750.48,
          "accuracy": 0.7377,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.4483,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7957,
            "mean_kappa": 0.7957,
            "min_kappa": 0.6976,
            "max_kappa": 0.9568,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 23541,
          "total_tokens_output": 1361,
          "total_tokens": 24902,
          "latency_mean_ms": 2079.35,
          "latency_p50_ms": 2051.93,
          "latency_p95_ms": 2523.46,
          "latency_p99_ms": 3439.77,
          "latency_total_ms": 126840.26,
          "accuracy": 0.6393,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.45,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8171,
            "mean_kappa": 0.8171,
            "min_kappa": 0.7629,
            "max_kappa": 0.8923,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.32786885245901637,
          "total_tokens_input": 23585,
          "total_tokens_output": 1442,
          "total_tokens": 25027,
          "latency_mean_ms": 2079.35,
          "latency_p50_ms": 1938.01,
          "latency_p95_ms": 2626.53,
          "latency_p99_ms": 5319.25,
          "latency_total_ms": 126840.55,
          "accuracy": 0.5738,
          "exact_match_rate": 0.3279,
          "llm_approval_rate": 0.3659,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.3279,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7758,
            "mean_kappa": 0.7758,
            "min_kappa": 0.6998,
            "max_kappa": 0.8349,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 23564,
          "total_tokens_output": 1301,
          "total_tokens": 24865,
          "latency_mean_ms": 2034.68,
          "latency_p50_ms": 2049.18,
          "latency_p95_ms": 2482.47,
          "latency_p99_ms": 2639.09,
          "latency_total_ms": 124115.44,
          "accuracy": 0.6721,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.3103,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.1475,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8435,
            "mean_kappa": 0.8435,
            "min_kappa": 0.8003,
            "max_kappa": 0.887,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 23537,
          "total_tokens_output": 1358,
          "total_tokens": 24895,
          "latency_mean_ms": 2097.94,
          "latency_p50_ms": 2069.29,
          "latency_p95_ms": 2706.74,
          "latency_p99_ms": 2715.65,
          "latency_total_ms": 127974.14,
          "accuracy": 0.6721,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.4737,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8052,
            "mean_kappa": 0.8052,
            "min_kappa": 0.6685,
            "max_kappa": 0.9186,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 23374,
          "total_tokens_output": 1293,
          "total_tokens": 24667,
          "latency_mean_ms": 1848.37,
          "latency_p50_ms": 1823.41,
          "latency_p95_ms": 2345.02,
          "latency_p99_ms": 2502.4,
          "latency_total_ms": 112750.48,
          "accuracy": 0.6393,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.2414,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.1148,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7957,
            "mean_kappa": 0.7957,
            "min_kappa": 0.6976,
            "max_kappa": 0.9568,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 23541,
          "total_tokens_output": 1361,
          "total_tokens": 24902,
          "latency_mean_ms": 2079.35,
          "latency_p50_ms": 2051.93,
          "latency_p95_ms": 2523.46,
          "latency_p99_ms": 3439.77,
          "latency_total_ms": 126840.26,
          "accuracy": 0.5574,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.325,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8171,
            "mean_kappa": 0.8171,
            "min_kappa": 0.7629,
            "max_kappa": 0.8923,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.32786885245901637,
          "total_tokens_input": 23585,
          "total_tokens_output": 1442,
          "total_tokens": 25027,
          "latency_mean_ms": 2079.35,
          "latency_p50_ms": 1938.01,
          "latency_p95_ms": 2626.53,
          "latency_p99_ms": 5319.25,
          "latency_total_ms": 126840.55,
          "accuracy": 0.5246,
          "exact_match_rate": 0.3279,
          "llm_approval_rate": 0.2927,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 32,
          "incorrect": 29,
          "accuracy_from_exact_match": 0.3279,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7758,
            "mean_kappa": 0.7758,
            "min_kappa": 0.6998,
            "max_kappa": 0.8349,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 23564,
          "total_tokens_output": 1301,
          "total_tokens": 24865,
          "latency_mean_ms": 2034.68,
          "latency_p50_ms": 2049.18,
          "latency_p95_ms": 2482.47,
          "latency_p99_ms": 2639.09,
          "latency_total_ms": 124115.44,
          "accuracy": 0.6885,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.3448,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.1639,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8435,
            "mean_kappa": 0.8435,
            "min_kappa": 0.8003,
            "max_kappa": 0.887,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 23537,
          "total_tokens_output": 1358,
          "total_tokens": 24895,
          "latency_mean_ms": 2097.94,
          "latency_p50_ms": 2069.29,
          "latency_p95_ms": 2706.74,
          "latency_p99_ms": 2715.65,
          "latency_total_ms": 127974.14,
          "accuracy": 0.8033,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.6842,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.4262,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8052,
            "mean_kappa": 0.8052,
            "min_kappa": 0.6685,
            "max_kappa": 0.9186,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_few_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.80731875,
        "std": 0.02181957890147058
      },
      "mean_kappa": {
        "mean": 0.80731875,
        "std": 0.02181957890147058
      },
      "min_kappa": {
        "mean": 0.7222375,
        "std": 0.04881329064660568
      },
      "max_kappa": {
        "mean": 0.8992125,
        "std": 0.039092468504176095
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "mistral",
    "condition": "finetuned_zero_shot",
    "finetuned": true,
    "few_shot": false,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.68031875,
        "std": 0.06978892479066791
      },
      "exact_match": {
        "mean": 0.4057377049180328,
        "std": 0.07478806389710926
      },
      "exact_match_rate": {
        "mean": 0.4057375,
        "std": 0.0747789398410408
      },
      "llm_approval_rate": {
        "mean": 0.46140625,
        "std": 0.093880405761466
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 41.5,
        "std": 4.257346591481601
      },
      "incorrect": {
        "mean": 19.5,
        "std": 4.257346591481601
      },
      "accuracy_from_exact_match": {
        "mean": 0.4057375,
        "std": 0.0747789398410408
      },
      "accuracy_boost_from_llm": {
        "mean": 0.27459375,
        "std": 0.06748199267906588
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 12663.25,
        "std": 72.83757615407036
      },
      "total_tokens_output": {
        "mean": 1344.25,
        "std": 35.756992323180654
      },
      "total_tokens": {
        "mean": 14007.5,
        "std": 100.45521390151931
      },
      "latency_mean_ms": {
        "mean": 2014.3512500000002,
        "std": 37.95353621123461
      },
      "latency_p50_ms": {
        "mean": 1981.8899999999999,
        "std": 48.091040615690595
      },
      "latency_p95_ms": {
        "mean": 2526.763125,
        "std": 85.39706696652038
      },
      "latency_p99_ms": {
        "mean": 3239.495625,
        "std": 781.8202271140148
      },
      "latency_total_ms": {
        "mean": 122875.21125,
        "std": 2315.175633755663
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.39344262295081966,
          "total_tokens_input": 12679,
          "total_tokens_output": 1357,
          "total_tokens": 14036,
          "latency_mean_ms": 2004.68,
          "latency_p50_ms": 1977.06,
          "latency_p95_ms": 2557.74,
          "latency_p99_ms": 2605.17,
          "latency_total_ms": 122285.37,
          "accuracy": 0.7377,
          "exact_match_rate": 0.3934,
          "llm_approval_rate": 0.5676,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.3934,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7705,
            "mean_kappa": 0.7705,
            "min_kappa": 0.6054,
            "max_kappa": 0.9153,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.45901639344262296,
          "total_tokens_input": 12516,
          "total_tokens_output": 1292,
          "total_tokens": 13808,
          "latency_mean_ms": 1967.17,
          "latency_p50_ms": 1924.86,
          "latency_p95_ms": 2474.56,
          "latency_p99_ms": 2727.6,
          "latency_total_ms": 119997.09,
          "accuracy": 0.7377,
          "exact_match_rate": 0.459,
          "llm_approval_rate": 0.5152,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.459,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8694,
            "mean_kappa": 0.8694,
            "min_kappa": 0.8066,
            "max_kappa": 0.9585,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3114754098360656,
          "total_tokens_input": 12683,
          "total_tokens_output": 1381,
          "total_tokens": 14064,
          "latency_mean_ms": 1994.94,
          "latency_p50_ms": 1933.86,
          "latency_p95_ms": 2452.57,
          "latency_p99_ms": 4454.64,
          "latency_total_ms": 121691.1,
          "accuracy": 0.6557,
          "exact_match_rate": 0.3115,
          "llm_approval_rate": 0.5,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.3115,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8401,
            "mean_kappa": 0.8401,
            "min_kappa": 0.7611,
            "max_kappa": 0.9633,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 12727,
          "total_tokens_output": 1379,
          "total_tokens": 14106,
          "latency_mean_ms": 2084.06,
          "latency_p50_ms": 2021.39,
          "latency_p95_ms": 2682.81,
          "latency_p99_ms": 4008.86,
          "latency_total_ms": 127127.45,
          "accuracy": 0.6557,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.475,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8414,
            "mean_kappa": 0.8414,
            "min_kappa": 0.796,
            "max_kappa": 0.8999,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 12706,
          "total_tokens_output": 1308,
          "total_tokens": 14014,
          "latency_mean_ms": 2024.13,
          "latency_p50_ms": 2053.89,
          "latency_p95_ms": 2455.81,
          "latency_p99_ms": 2612.65,
          "latency_total_ms": 123471.66,
          "accuracy": 0.7541,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.4828,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8094,
            "mean_kappa": 0.8094,
            "min_kappa": 0.7929,
            "max_kappa": 0.8424,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.39344262295081966,
          "total_tokens_input": 12679,
          "total_tokens_output": 1357,
          "total_tokens": 14036,
          "latency_mean_ms": 2004.68,
          "latency_p50_ms": 1977.06,
          "latency_p95_ms": 2557.74,
          "latency_p99_ms": 2605.17,
          "latency_total_ms": 122285.37,
          "accuracy": 0.7377,
          "exact_match_rate": 0.3934,
          "llm_approval_rate": 0.5676,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.3934,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7705,
            "mean_kappa": 0.7705,
            "min_kappa": 0.6054,
            "max_kappa": 0.9153,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.45901639344262296,
          "total_tokens_input": 12516,
          "total_tokens_output": 1292,
          "total_tokens": 13808,
          "latency_mean_ms": 1967.17,
          "latency_p50_ms": 1924.86,
          "latency_p95_ms": 2474.56,
          "latency_p99_ms": 2727.6,
          "latency_total_ms": 119997.09,
          "accuracy": 0.7213,
          "exact_match_rate": 0.459,
          "llm_approval_rate": 0.4848,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.459,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8694,
            "mean_kappa": 0.8694,
            "min_kappa": 0.8066,
            "max_kappa": 0.9585,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3114754098360656,
          "total_tokens_input": 12683,
          "total_tokens_output": 1381,
          "total_tokens": 14064,
          "latency_mean_ms": 1994.94,
          "latency_p50_ms": 1933.86,
          "latency_p95_ms": 2452.57,
          "latency_p99_ms": 4454.64,
          "latency_total_ms": 121691.1,
          "accuracy": 0.6721,
          "exact_match_rate": 0.3115,
          "llm_approval_rate": 0.5238,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.3115,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8401,
            "mean_kappa": 0.8401,
            "min_kappa": 0.7611,
            "max_kappa": 0.9633,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 12727,
          "total_tokens_output": 1379,
          "total_tokens": 14106,
          "latency_mean_ms": 2084.06,
          "latency_p50_ms": 2021.39,
          "latency_p95_ms": 2682.81,
          "latency_p99_ms": 4008.86,
          "latency_total_ms": 127127.45,
          "accuracy": 0.5738,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.35,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8414,
            "mean_kappa": 0.8414,
            "min_kappa": 0.796,
            "max_kappa": 0.8999,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 12706,
          "total_tokens_output": 1308,
          "total_tokens": 14014,
          "latency_mean_ms": 2024.13,
          "latency_p50_ms": 2053.89,
          "latency_p95_ms": 2455.81,
          "latency_p99_ms": 2612.65,
          "latency_total_ms": 123471.66,
          "accuracy": 0.7049,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.3793,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.1803,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8094,
            "mean_kappa": 0.8094,
            "min_kappa": 0.7929,
            "max_kappa": 0.8424,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.39344262295081966,
          "total_tokens_input": 12679,
          "total_tokens_output": 1357,
          "total_tokens": 14036,
          "latency_mean_ms": 2004.68,
          "latency_p50_ms": 1977.06,
          "latency_p95_ms": 2557.74,
          "latency_p99_ms": 2605.17,
          "latency_total_ms": 122285.37,
          "accuracy": 0.6393,
          "exact_match_rate": 0.3934,
          "llm_approval_rate": 0.4054,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.3934,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7705,
            "mean_kappa": 0.7705,
            "min_kappa": 0.6054,
            "max_kappa": 0.9153,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.45901639344262296,
          "total_tokens_input": 12516,
          "total_tokens_output": 1292,
          "total_tokens": 13808,
          "latency_mean_ms": 1967.17,
          "latency_p50_ms": 1924.86,
          "latency_p95_ms": 2474.56,
          "latency_p99_ms": 2727.6,
          "latency_total_ms": 119997.09,
          "accuracy": 0.6721,
          "exact_match_rate": 0.459,
          "llm_approval_rate": 0.3939,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.459,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8694,
            "mean_kappa": 0.8694,
            "min_kappa": 0.8066,
            "max_kappa": 0.9585,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3114754098360656,
          "total_tokens_input": 12683,
          "total_tokens_output": 1381,
          "total_tokens": 14064,
          "latency_mean_ms": 1994.94,
          "latency_p50_ms": 1933.86,
          "latency_p95_ms": 2452.57,
          "latency_p99_ms": 4454.64,
          "latency_total_ms": 121691.1,
          "accuracy": 0.5574,
          "exact_match_rate": 0.3115,
          "llm_approval_rate": 0.3571,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.3115,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8401,
            "mean_kappa": 0.8401,
            "min_kappa": 0.7611,
            "max_kappa": 0.9633,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 12727,
          "total_tokens_output": 1379,
          "total_tokens": 14106,
          "latency_mean_ms": 2084.06,
          "latency_p50_ms": 2021.39,
          "latency_p95_ms": 2682.81,
          "latency_p99_ms": 4008.86,
          "latency_total_ms": 127127.45,
          "accuracy": 0.5574,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.325,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8414,
            "mean_kappa": 0.8414,
            "min_kappa": 0.796,
            "max_kappa": 0.8999,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 12706,
          "total_tokens_output": 1308,
          "total_tokens": 14014,
          "latency_mean_ms": 2024.13,
          "latency_p50_ms": 2053.89,
          "latency_p95_ms": 2455.81,
          "latency_p99_ms": 2612.65,
          "latency_total_ms": 123471.66,
          "accuracy": 0.7049,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.3793,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.1803,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8094,
            "mean_kappa": 0.8094,
            "min_kappa": 0.7929,
            "max_kappa": 0.8424,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.39344262295081966,
          "total_tokens_input": 12679,
          "total_tokens_output": 1357,
          "total_tokens": 14036,
          "latency_mean_ms": 2004.68,
          "latency_p50_ms": 1977.06,
          "latency_p95_ms": 2557.74,
          "latency_p99_ms": 2605.17,
          "latency_total_ms": 122285.37,
          "accuracy": 0.8033,
          "exact_match_rate": 0.3934,
          "llm_approval_rate": 0.6757,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.3934,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7705,
            "mean_kappa": 0.7705,
            "min_kappa": 0.6054,
            "max_kappa": 0.9153,
            "n_items": 61
          }
        },
        "source": "mistral_finetuned_zero_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.82268125,
        "std": 0.03529345227428878
      },
      "mean_kappa": {
        "mean": 0.82268125,
        "std": 0.03529345227428878
      },
      "min_kappa": {
        "mean": 0.7432125,
        "std": 0.08091239765171959
      },
      "max_kappa": {
        "mean": 0.9158437500000001,
        "std": 0.0426912603578004
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "phi3",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 13,
    "metrics": {
      "accuracy": {
        "mean": 0.40226153846153845,
        "std": 0.11331989124367924
      },
      "exact_match": {
        "mean": 0.031525851197982346,
        "std": 0.01634486935285715
      },
      "exact_match_rate": {
        "mean": 0.03153846153846154,
        "std": 0.016351407300598295
      },
      "llm_approval_rate": {
        "mean": 0.3822615384615385,
        "std": 0.11793587917861612
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 24.53846153846154,
        "std": 6.912812904203376
      },
      "incorrect": {
        "mean": 36.46153846153846,
        "std": 6.912812904203376
      },
      "accuracy_from_exact_match": {
        "mean": 0.03153846153846154,
        "std": 0.016351407300598295
      },
      "accuracy_boost_from_llm": {
        "mean": 0.37074615384615384,
        "std": 0.1174260265698211
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 21113.69230769231,
        "std": 35.34964827457403
      },
      "total_tokens_output": {
        "mean": 1342.923076923077,
        "std": 170.5427812505894
      },
      "total_tokens": {
        "mean": 22456.615384615383,
        "std": 170.5017655949812
      },
      "latency_mean_ms": {
        "mean": 817.5615384615385,
        "std": 114.84881238099696
      },
      "latency_p50_ms": {
        "mean": 630.863076923077,
        "std": 25.590273207612217
      },
      "latency_p95_ms": {
        "mean": 1365.6546153846155,
        "std": 214.15156708833706
      },
      "latency_p99_ms": {
        "mean": 5201.417692307692,
        "std": 3295.54110024008
      },
      "latency_total_ms": {
        "mean": 49871.42538461538,
        "std": 7005.734207537111
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 21125,
          "total_tokens_output": 1201,
          "total_tokens": 22326,
          "latency_mean_ms": 728.09,
          "latency_p50_ms": 651.66,
          "latency_p95_ms": 1218.89,
          "latency_p99_ms": 2559.38,
          "latency_total_ms": 44413.59,
          "accuracy": 0.3934,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.3833,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 24,
          "incorrect": 37,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.535,
            "mean_kappa": 0.535,
            "min_kappa": 0.2144,
            "max_kappa": 0.8946,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 21051,
          "total_tokens_output": 1357,
          "total_tokens": 22408,
          "latency_mean_ms": 809.46,
          "latency_p50_ms": 585.2,
          "latency_p95_ms": 1140.02,
          "latency_p99_ms": 6001.16,
          "latency_total_ms": 49377.35,
          "accuracy": 0.377,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.3448,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 23,
          "incorrect": 38,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8068,
            "mean_kappa": 0.8068,
            "min_kappa": 0.7109,
            "max_kappa": 0.858,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 21128,
          "total_tokens_output": 1635,
          "total_tokens": 22763,
          "latency_mean_ms": 1019.65,
          "latency_p50_ms": 637.08,
          "latency_p95_ms": 1453.14,
          "latency_p99_ms": 10649.99,
          "latency_total_ms": 62198.71,
          "accuracy": 0.3934,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.3833,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 24,
          "incorrect": 37,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.758,
            "mean_kappa": 0.758,
            "min_kappa": 0.7126,
            "max_kappa": 0.8244,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 21147,
          "total_tokens_output": 1226,
          "total_tokens": 22373,
          "latency_mean_ms": 742.87,
          "latency_p50_ms": 642.58,
          "latency_p95_ms": 1699.49,
          "latency_p99_ms": 2475.82,
          "latency_total_ms": 45315.33,
          "accuracy": 0.4098,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.3793,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 25,
          "incorrect": 36,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9549,
            "mean_kappa": 0.9549,
            "min_kappa": 0.9322,
            "max_kappa": 0.9663,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 21125,
          "total_tokens_output": 1201,
          "total_tokens": 22326,
          "latency_mean_ms": 728.09,
          "latency_p50_ms": 651.66,
          "latency_p95_ms": 1218.89,
          "latency_p99_ms": 2559.38,
          "latency_total_ms": 44413.59,
          "accuracy": 0.4098,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.4,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 25,
          "incorrect": 36,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.535,
            "mean_kappa": 0.535,
            "min_kappa": 0.2144,
            "max_kappa": 0.8946,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 21051,
          "total_tokens_output": 1357,
          "total_tokens": 22408,
          "latency_mean_ms": 809.46,
          "latency_p50_ms": 585.2,
          "latency_p95_ms": 1140.02,
          "latency_p99_ms": 6001.16,
          "latency_total_ms": 49377.35,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.3103,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8068,
            "mean_kappa": 0.8068,
            "min_kappa": 0.7109,
            "max_kappa": 0.858,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 21128,
          "total_tokens_output": 1635,
          "total_tokens": 22763,
          "latency_mean_ms": 1019.65,
          "latency_p50_ms": 637.08,
          "latency_p95_ms": 1453.14,
          "latency_p99_ms": 10649.99,
          "latency_total_ms": 62198.71,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.3333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.758,
            "mean_kappa": 0.758,
            "min_kappa": 0.7126,
            "max_kappa": 0.8244,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 21147,
          "total_tokens_output": 1226,
          "total_tokens": 22373,
          "latency_mean_ms": 742.87,
          "latency_p50_ms": 642.58,
          "latency_p95_ms": 1699.49,
          "latency_p99_ms": 2475.82,
          "latency_total_ms": 45315.33,
          "accuracy": 0.4262,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.3966,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 26,
          "incorrect": 35,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9549,
            "mean_kappa": 0.9549,
            "min_kappa": 0.9322,
            "max_kappa": 0.9663,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 21125,
          "total_tokens_output": 1201,
          "total_tokens": 22326,
          "latency_mean_ms": 728.09,
          "latency_p50_ms": 651.66,
          "latency_p95_ms": 1218.89,
          "latency_p99_ms": 2559.38,
          "latency_total_ms": 44413.59,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.3333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.535,
            "mean_kappa": 0.535,
            "min_kappa": 0.2144,
            "max_kappa": 0.8946,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 21051,
          "total_tokens_output": 1357,
          "total_tokens": 22408,
          "latency_mean_ms": 809.46,
          "latency_p50_ms": 585.2,
          "latency_p95_ms": 1140.02,
          "latency_p99_ms": 6001.16,
          "latency_total_ms": 49377.35,
          "accuracy": 0.3115,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.2759,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 19,
          "incorrect": 42,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8068,
            "mean_kappa": 0.8068,
            "min_kappa": 0.7109,
            "max_kappa": 0.858,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 21128,
          "total_tokens_output": 1635,
          "total_tokens": 22763,
          "latency_mean_ms": 1019.65,
          "latency_p50_ms": 637.08,
          "latency_p95_ms": 1453.14,
          "latency_p99_ms": 10649.99,
          "latency_total_ms": 62198.71,
          "accuracy": 0.2951,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.2833,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 18,
          "incorrect": 43,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.758,
            "mean_kappa": 0.758,
            "min_kappa": 0.7126,
            "max_kappa": 0.8244,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 21147,
          "total_tokens_output": 1226,
          "total_tokens": 22373,
          "latency_mean_ms": 742.87,
          "latency_p50_ms": 642.58,
          "latency_p95_ms": 1699.49,
          "latency_p99_ms": 2475.82,
          "latency_total_ms": 45315.33,
          "accuracy": 0.4098,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.3793,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 25,
          "incorrect": 36,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9549,
            "mean_kappa": 0.9549,
            "min_kappa": 0.9322,
            "max_kappa": 0.9663,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 21125,
          "total_tokens_output": 1201,
          "total_tokens": 22326,
          "latency_mean_ms": 728.09,
          "latency_p50_ms": 651.66,
          "latency_p95_ms": 1218.89,
          "latency_p99_ms": 2559.38,
          "latency_total_ms": 44413.59,
          "accuracy": 0.7705,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.7667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.7541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.535,
            "mean_kappa": 0.535,
            "min_kappa": 0.2144,
            "max_kappa": 0.8946,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_few_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.7460846153846153,
        "std": 0.1570211786114993
      },
      "mean_kappa": {
        "mean": 0.7460846153846153,
        "std": 0.1570211786114993
      },
      "min_kappa": {
        "mean": 0.6095923076923077,
        "std": 0.27728859018813
      },
      "max_kappa": {
        "mean": 0.8865,
        "std": 0.05066673920372677
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "phi3",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 13,
    "metrics": {
      "accuracy": {
        "mean": 0.07946923076923078,
        "std": 0.04717798353233757
      },
      "exact_match": {
        "mean": 0.0,
        "std": 0.0
      },
      "exact_match_rate": {
        "mean": 0.0,
        "std": 0.0
      },
      "llm_approval_rate": {
        "mean": 0.07946923076923078,
        "std": 0.04717798353233757
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 4.846153846153846,
        "std": 2.8781979898261087
      },
      "incorrect": {
        "mean": 56.15384615384615,
        "std": 2.8781979898261087
      },
      "accuracy_from_exact_match": {
        "mean": 0.0,
        "std": 0.0
      },
      "accuracy_boost_from_llm": {
        "mean": 0.07946923076923078,
        "std": 0.04717798353233757
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 10202.076923076924,
        "std": 43.85546459847312
      },
      "total_tokens_output": {
        "mean": 4552,
        "std": 590.1542171331151
      },
      "total_tokens": {
        "mean": 14754.076923076924,
        "std": 602.649976423164
      },
      "latency_mean_ms": {
        "mean": 2667.3230769230768,
        "std": 425.31565294106724
      },
      "latency_p50_ms": {
        "mean": 826.5638461538462,
        "std": 54.120789200349265
      },
      "latency_p95_ms": {
        "mean": 9184.020769230769,
        "std": 387.9361418199877
      },
      "latency_p99_ms": {
        "mean": 9395.104615384615,
        "std": 327.4656874242506
      },
      "latency_total_ms": {
        "mean": 162706.68384615384,
        "std": 25944.29577143353
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10206,
          "total_tokens_output": 4432,
          "total_tokens": 14638,
          "latency_mean_ms": 2601.69,
          "latency_p50_ms": 844.01,
          "latency_p95_ms": 9180.25,
          "latency_p99_ms": 9318.24,
          "latency_total_ms": 158702.9,
          "accuracy": 0.0656,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0656,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 4,
          "incorrect": 57,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0656,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5289,
            "mean_kappa": 0.5289,
            "min_kappa": 0.2043,
            "max_kappa": 0.8486,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10132,
          "total_tokens_output": 4746,
          "total_tokens": 14878,
          "latency_mean_ms": 2748.58,
          "latency_p50_ms": 835.76,
          "latency_p95_ms": 9050.71,
          "latency_p99_ms": 9361.9,
          "latency_total_ms": 167663.65,
          "accuracy": 0.0656,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0656,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 4,
          "incorrect": 57,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0656,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8991,
            "mean_kappa": 0.8991,
            "min_kappa": 0.8486,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10209,
          "total_tokens_output": 3683,
          "total_tokens": 13892,
          "latency_mean_ms": 2049.36,
          "latency_p50_ms": 733.93,
          "latency_p95_ms": 8694.27,
          "latency_p99_ms": 8990.46,
          "latency_total_ms": 125010.87,
          "accuracy": 0.082,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.082,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 5,
          "incorrect": 56,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9201,
            "mean_kappa": 0.9201,
            "min_kappa": 0.8802,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10260,
          "total_tokens_output": 5387,
          "total_tokens": 15647,
          "latency_mean_ms": 3291.54,
          "latency_p50_ms": 886.74,
          "latency_p95_ms": 9812.11,
          "latency_p99_ms": 9935.44,
          "latency_total_ms": 200783.91,
          "accuracy": 0.1148,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.1148,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 7,
          "incorrect": 54,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.1148,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7994,
            "mean_kappa": 0.7994,
            "min_kappa": 0.7024,
            "max_kappa": 0.8802,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10206,
          "total_tokens_output": 4432,
          "total_tokens": 14638,
          "latency_mean_ms": 2601.69,
          "latency_p50_ms": 844.01,
          "latency_p95_ms": 9180.25,
          "latency_p99_ms": 9318.24,
          "latency_total_ms": 158702.9,
          "accuracy": 0.0492,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0492,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 3,
          "incorrect": 58,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0492,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5289,
            "mean_kappa": 0.5289,
            "min_kappa": 0.2043,
            "max_kappa": 0.8486,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10132,
          "total_tokens_output": 4746,
          "total_tokens": 14878,
          "latency_mean_ms": 2748.58,
          "latency_p50_ms": 835.76,
          "latency_p95_ms": 9050.71,
          "latency_p99_ms": 9361.9,
          "latency_total_ms": 167663.65,
          "accuracy": 0.0656,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0656,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 4,
          "incorrect": 57,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0656,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8991,
            "mean_kappa": 0.8991,
            "min_kappa": 0.8486,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10209,
          "total_tokens_output": 3683,
          "total_tokens": 13892,
          "latency_mean_ms": 2049.36,
          "latency_p50_ms": 733.93,
          "latency_p95_ms": 8694.27,
          "latency_p99_ms": 8990.46,
          "latency_total_ms": 125010.87,
          "accuracy": 0.0656,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0656,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 4,
          "incorrect": 57,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0656,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9201,
            "mean_kappa": 0.9201,
            "min_kappa": 0.8802,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10260,
          "total_tokens_output": 5387,
          "total_tokens": 15647,
          "latency_mean_ms": 3291.54,
          "latency_p50_ms": 886.74,
          "latency_p95_ms": 9812.11,
          "latency_p99_ms": 9935.44,
          "latency_total_ms": 200783.91,
          "accuracy": 0.082,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.082,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 5,
          "incorrect": 56,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7994,
            "mean_kappa": 0.7994,
            "min_kappa": 0.7024,
            "max_kappa": 0.8802,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10206,
          "total_tokens_output": 4432,
          "total_tokens": 14638,
          "latency_mean_ms": 2601.69,
          "latency_p50_ms": 844.01,
          "latency_p95_ms": 9180.25,
          "latency_p99_ms": 9318.24,
          "latency_total_ms": 158702.9,
          "accuracy": 0.0328,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0328,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 2,
          "incorrect": 59,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0328,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5289,
            "mean_kappa": 0.5289,
            "min_kappa": 0.2043,
            "max_kappa": 0.8486,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10132,
          "total_tokens_output": 4746,
          "total_tokens": 14878,
          "latency_mean_ms": 2748.58,
          "latency_p50_ms": 835.76,
          "latency_p95_ms": 9050.71,
          "latency_p99_ms": 9361.9,
          "latency_total_ms": 167663.65,
          "accuracy": 0.0492,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0492,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 3,
          "incorrect": 58,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0492,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8991,
            "mean_kappa": 0.8991,
            "min_kappa": 0.8486,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10209,
          "total_tokens_output": 3683,
          "total_tokens": 13892,
          "latency_mean_ms": 2049.36,
          "latency_p50_ms": 733.93,
          "latency_p95_ms": 8694.27,
          "latency_p99_ms": 8990.46,
          "latency_total_ms": 125010.87,
          "accuracy": 0.0656,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0656,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 4,
          "incorrect": 57,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0656,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9201,
            "mean_kappa": 0.9201,
            "min_kappa": 0.8802,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10260,
          "total_tokens_output": 5387,
          "total_tokens": 15647,
          "latency_mean_ms": 3291.54,
          "latency_p50_ms": 886.74,
          "latency_p95_ms": 9812.11,
          "latency_p99_ms": 9935.44,
          "latency_total_ms": 200783.91,
          "accuracy": 0.0656,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0656,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 4,
          "incorrect": 57,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0656,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7994,
            "mean_kappa": 0.7994,
            "min_kappa": 0.7024,
            "max_kappa": 0.8802,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 10206,
          "total_tokens_output": 4432,
          "total_tokens": 14638,
          "latency_mean_ms": 2601.69,
          "latency_p50_ms": 844.01,
          "latency_p95_ms": 9180.25,
          "latency_p99_ms": 9318.24,
          "latency_total_ms": 158702.9,
          "accuracy": 0.2295,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2295,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 14,
          "incorrect": 47,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5289,
            "mean_kappa": 0.5289,
            "min_kappa": 0.2043,
            "max_kappa": 0.8486,
            "n_items": 61
          }
        },
        "source": "phi3_baseline_zero_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.7670307692307693,
        "std": 0.16468752876334478
      },
      "mean_kappa": {
        "mean": 0.7670307692307693,
        "std": 0.16468752876334478
      },
      "min_kappa": {
        "mean": 0.6239076923076923,
        "std": 0.28706508632535277
      },
      "max_kappa": {
        "mean": 0.9257692307692308,
        "std": 0.06967576981568473
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "phi3",
    "condition": "finetuned_few_shot",
    "finetuned": true,
    "few_shot": true,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.65573125,
        "std": 0.0700213335237019
      },
      "exact_match": {
        "mean": 0.3514344262295082,
        "std": 0.06556576539252522
      },
      "exact_match_rate": {
        "mean": 0.35141875,
        "std": 0.06554657903687652
      },
      "llm_approval_rate": {
        "mean": 0.4670125,
        "std": 0.1040567686109366
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 40,
        "std": 4.272001872658765
      },
      "incorrect": {
        "mean": 21,
        "std": 4.272001872658765
      },
      "accuracy_from_exact_match": {
        "mean": 0.35141875,
        "std": 0.06554657903687652
      },
      "accuracy_boost_from_llm": {
        "mean": 0.3043,
        "std": 0.07903791811529452
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 21125.9375,
        "std": 40.805129502919115
      },
      "total_tokens_output": {
        "mean": 1019.0625,
        "std": 47.13341271062387
      },
      "total_tokens": {
        "mean": 22145,
        "std": 86.69558812304119
      },
      "latency_mean_ms": {
        "mean": 602.4768750000001,
        "std": 34.83273347706688
      },
      "latency_p50_ms": {
        "mean": 565.74125,
        "std": 16.243095023347593
      },
      "latency_p95_ms": {
        "mean": 813.081875,
        "std": 31.85125669003308
      },
      "latency_p99_ms": {
        "mean": 1513.77375,
        "std": 628.6414331504387
      },
      "latency_total_ms": {
        "mean": 36751.1,
        "std": 2124.744137478674
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3114754098360656,
          "total_tokens_input": 21125,
          "total_tokens_output": 1005,
          "total_tokens": 22130,
          "latency_mean_ms": 579.39,
          "latency_p50_ms": 559.25,
          "latency_p95_ms": 805.07,
          "latency_p99_ms": 839.13,
          "latency_total_ms": 35342.87,
          "accuracy": 0.7049,
          "exact_match_rate": 0.3115,
          "llm_approval_rate": 0.5714,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.3115,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7518,
            "mean_kappa": 0.7518,
            "min_kappa": 0.5456,
            "max_kappa": 0.9212,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 21051,
          "total_tokens_output": 932,
          "total_tokens": 21983,
          "latency_mean_ms": 546.0,
          "latency_p50_ms": 537.86,
          "latency_p95_ms": 780.93,
          "latency_p99_ms": 822.54,
          "latency_total_ms": 33306.07,
          "accuracy": 0.6885,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.4722,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7895,
            "mean_kappa": 0.7895,
            "min_kappa": 0.757,
            "max_kappa": 0.8168,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 21128,
          "total_tokens_output": 1052,
          "total_tokens": 22180,
          "latency_mean_ms": 628.87,
          "latency_p50_ms": 582.17,
          "latency_p95_ms": 787.41,
          "latency_p99_ms": 1896.78,
          "latency_total_ms": 38360.85,
          "accuracy": 0.7377,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.5789,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8479,
            "mean_kappa": 0.8479,
            "min_kappa": 0.7732,
            "max_kappa": 0.9186,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.2459016393442623,
          "total_tokens_input": 21179,
          "total_tokens_output": 1067,
          "total_tokens": 22246,
          "latency_mean_ms": 636.21,
          "latency_p50_ms": 568.67,
          "latency_p95_ms": 821.98,
          "latency_p99_ms": 2388.75,
          "latency_total_ms": 38808.77,
          "accuracy": 0.6393,
          "exact_match_rate": 0.2459,
          "llm_approval_rate": 0.5217,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.2459,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7542,
            "mean_kappa": 0.7542,
            "min_kappa": 0.7265,
            "max_kappa": 0.7688,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 21147,
          "total_tokens_output": 1044,
          "total_tokens": 22191,
          "latency_mean_ms": 629.61,
          "latency_p50_ms": 582.92,
          "latency_p95_ms": 872.69,
          "latency_p99_ms": 1846.55,
          "latency_total_ms": 38406.35,
          "accuracy": 0.7213,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.5143,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7797,
            "mean_kappa": 0.7797,
            "min_kappa": 0.7126,
            "max_kappa": 0.8798,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3114754098360656,
          "total_tokens_input": 21125,
          "total_tokens_output": 1005,
          "total_tokens": 22130,
          "latency_mean_ms": 579.39,
          "latency_p50_ms": 559.25,
          "latency_p95_ms": 805.07,
          "latency_p99_ms": 839.13,
          "latency_total_ms": 35342.87,
          "accuracy": 0.7049,
          "exact_match_rate": 0.3115,
          "llm_approval_rate": 0.5714,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.3115,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7518,
            "mean_kappa": 0.7518,
            "min_kappa": 0.5456,
            "max_kappa": 0.9212,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 21051,
          "total_tokens_output": 932,
          "total_tokens": 21983,
          "latency_mean_ms": 546.0,
          "latency_p50_ms": 537.86,
          "latency_p95_ms": 780.93,
          "latency_p99_ms": 822.54,
          "latency_total_ms": 33306.07,
          "accuracy": 0.6393,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.3889,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7895,
            "mean_kappa": 0.7895,
            "min_kappa": 0.757,
            "max_kappa": 0.8168,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 21128,
          "total_tokens_output": 1052,
          "total_tokens": 22180,
          "latency_mean_ms": 628.87,
          "latency_p50_ms": 582.17,
          "latency_p95_ms": 787.41,
          "latency_p99_ms": 1896.78,
          "latency_total_ms": 38360.85,
          "accuracy": 0.7049,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.5263,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8479,
            "mean_kappa": 0.8479,
            "min_kappa": 0.7732,
            "max_kappa": 0.9186,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.2459016393442623,
          "total_tokens_input": 21179,
          "total_tokens_output": 1067,
          "total_tokens": 22246,
          "latency_mean_ms": 636.21,
          "latency_p50_ms": 568.67,
          "latency_p95_ms": 821.98,
          "latency_p99_ms": 2388.75,
          "latency_total_ms": 38808.77,
          "accuracy": 0.5738,
          "exact_match_rate": 0.2459,
          "llm_approval_rate": 0.4348,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.2459,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7542,
            "mean_kappa": 0.7542,
            "min_kappa": 0.7265,
            "max_kappa": 0.7688,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 21147,
          "total_tokens_output": 1044,
          "total_tokens": 22191,
          "latency_mean_ms": 629.61,
          "latency_p50_ms": 582.92,
          "latency_p95_ms": 872.69,
          "latency_p99_ms": 1846.55,
          "latency_total_ms": 38406.35,
          "accuracy": 0.7049,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.4857,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7797,
            "mean_kappa": 0.7797,
            "min_kappa": 0.7126,
            "max_kappa": 0.8798,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3114754098360656,
          "total_tokens_input": 21125,
          "total_tokens_output": 1005,
          "total_tokens": 22130,
          "latency_mean_ms": 579.39,
          "latency_p50_ms": 559.25,
          "latency_p95_ms": 805.07,
          "latency_p99_ms": 839.13,
          "latency_total_ms": 35342.87,
          "accuracy": 0.5574,
          "exact_match_rate": 0.3115,
          "llm_approval_rate": 0.3571,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.3115,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7518,
            "mean_kappa": 0.7518,
            "min_kappa": 0.5456,
            "max_kappa": 0.9212,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 21051,
          "total_tokens_output": 932,
          "total_tokens": 21983,
          "latency_mean_ms": 546.0,
          "latency_p50_ms": 537.86,
          "latency_p95_ms": 780.93,
          "latency_p99_ms": 822.54,
          "latency_total_ms": 33306.07,
          "accuracy": 0.5738,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.2778,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.1639,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7895,
            "mean_kappa": 0.7895,
            "min_kappa": 0.757,
            "max_kappa": 0.8168,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 21128,
          "total_tokens_output": 1052,
          "total_tokens": 22180,
          "latency_mean_ms": 628.87,
          "latency_p50_ms": 582.17,
          "latency_p95_ms": 787.41,
          "latency_p99_ms": 1896.78,
          "latency_total_ms": 38360.85,
          "accuracy": 0.6393,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.4211,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8479,
            "mean_kappa": 0.8479,
            "min_kappa": 0.7732,
            "max_kappa": 0.9186,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.2459016393442623,
          "total_tokens_input": 21179,
          "total_tokens_output": 1067,
          "total_tokens": 22246,
          "latency_mean_ms": 636.21,
          "latency_p50_ms": 568.67,
          "latency_p95_ms": 821.98,
          "latency_p99_ms": 2388.75,
          "latency_total_ms": 38808.77,
          "accuracy": 0.5246,
          "exact_match_rate": 0.2459,
          "llm_approval_rate": 0.3696,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 32,
          "incorrect": 29,
          "accuracy_from_exact_match": 0.2459,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7542,
            "mean_kappa": 0.7542,
            "min_kappa": 0.7265,
            "max_kappa": 0.7688,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 21147,
          "total_tokens_output": 1044,
          "total_tokens": 22191,
          "latency_mean_ms": 629.61,
          "latency_p50_ms": 582.92,
          "latency_p95_ms": 872.69,
          "latency_p99_ms": 1846.55,
          "latency_total_ms": 38406.35,
          "accuracy": 0.6066,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.3143,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.1803,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7797,
            "mean_kappa": 0.7797,
            "min_kappa": 0.7126,
            "max_kappa": 0.8798,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3114754098360656,
          "total_tokens_input": 21125,
          "total_tokens_output": 1005,
          "total_tokens": 22130,
          "latency_mean_ms": 579.39,
          "latency_p50_ms": 559.25,
          "latency_p95_ms": 805.07,
          "latency_p99_ms": 839.13,
          "latency_total_ms": 35342.87,
          "accuracy": 0.7705,
          "exact_match_rate": 0.3115,
          "llm_approval_rate": 0.6667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.3115,
          "accuracy_boost_from_llm": 0.459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7518,
            "mean_kappa": 0.7518,
            "min_kappa": 0.5456,
            "max_kappa": 0.9212,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_few_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.78256875,
        "std": 0.03461805379332437
      },
      "mean_kappa": {
        "mean": 0.78256875,
        "std": 0.03461805379332437
      },
      "min_kappa": {
        "mean": 0.69314375,
        "std": 0.08768197483483993
      },
      "max_kappa": {
        "mean": 0.8648,
        "std": 0.05949903360559732
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "phi3",
    "condition": "finetuned_zero_shot",
    "finetuned": true,
    "few_shot": false,
    "num_seeds": 17,
    "metrics": {
      "accuracy": {
        "mean": 0.6509176470588235,
        "std": 0.09767624333537162
      },
      "exact_match": {
        "mean": 0.3471552555448409,
        "std": 0.060360587674170976
      },
      "exact_match_rate": {
        "mean": 0.34714117647058823,
        "std": 0.060344141085293436
      },
      "llm_approval_rate": {
        "mean": 0.4621176470588235,
        "std": 0.15022316432676427
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 39.705882352941174,
        "std": 5.958332829223812
      },
      "incorrect": {
        "mean": 21.294117647058822,
        "std": 5.958332829223812
      },
      "accuracy_from_exact_match": {
        "mean": 0.34714117647058823,
        "std": 0.060344141085293436
      },
      "accuracy_boost_from_llm": {
        "mean": 0.3037705882352941,
        "std": 0.10919984790285617
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 10210.058823529413,
        "std": 41.508993480839635
      },
      "total_tokens_output": {
        "mean": 996.8235294117648,
        "std": 36.466318535646735
      },
      "total_tokens": {
        "mean": 11206.882352941177,
        "std": 76.58819011474226
      },
      "latency_mean_ms": {
        "mean": 565.8464705882353,
        "std": 25.121763693512158
      },
      "latency_p50_ms": {
        "mean": 548.9505882352942,
        "std": 17.072670789576918
      },
      "latency_p95_ms": {
        "mean": 767.9994117647059,
        "std": 26.336621220290162
      },
      "latency_p99_ms": {
        "mean": 1118.5429411764705,
        "std": 284.1644975292574
      },
      "latency_total_ms": {
        "mean": 34516.7,
        "std": 1532.5143646961374
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 10206,
          "total_tokens_output": 1001,
          "total_tokens": 11207,
          "latency_mean_ms": 559.42,
          "latency_p50_ms": 543.85,
          "latency_p95_ms": 747.06,
          "latency_p99_ms": 781.2,
          "latency_total_ms": 34124.77,
          "accuracy": 0.6885,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.525,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.678,
            "mean_kappa": 0.678,
            "min_kappa": 0.4812,
            "max_kappa": 0.7889,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 10132,
          "total_tokens_output": 934,
          "total_tokens": 11066,
          "latency_mean_ms": 535.18,
          "latency_p50_ms": 526.34,
          "latency_p95_ms": 771.03,
          "latency_p99_ms": 958.4,
          "latency_total_ms": 32645.96,
          "accuracy": 0.7213,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.5526,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7435,
            "mean_kappa": 0.7435,
            "min_kappa": 0.6546,
            "max_kappa": 0.813,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.39344262295081966,
          "total_tokens_input": 10209,
          "total_tokens_output": 1001,
          "total_tokens": 11210,
          "latency_mean_ms": 548.65,
          "latency_p50_ms": 534.85,
          "latency_p95_ms": 728.7,
          "latency_p99_ms": 1142.14,
          "latency_total_ms": 33467.74,
          "accuracy": 0.7541,
          "exact_match_rate": 0.3934,
          "llm_approval_rate": 0.5946,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.3934,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.687,
            "mean_kappa": 0.687,
            "min_kappa": 0.5392,
            "max_kappa": 0.9116,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.2459016393442623,
          "total_tokens_input": 10260,
          "total_tokens_output": 1047,
          "total_tokens": 11307,
          "latency_mean_ms": 607.23,
          "latency_p50_ms": 573.14,
          "latency_p95_ms": 792.59,
          "latency_p99_ms": 1576.05,
          "latency_total_ms": 37041.3,
          "accuracy": 0.6393,
          "exact_match_rate": 0.2459,
          "llm_approval_rate": 0.5217,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.2459,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.606,
            "mean_kappa": 0.606,
            "min_kappa": 0.3441,
            "max_kappa": 0.8051,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 10228,
          "total_tokens_output": 983,
          "total_tokens": 11211,
          "latency_mean_ms": 567.1,
          "latency_p50_ms": 560.21,
          "latency_p95_ms": 799.4,
          "latency_p99_ms": 1094.87,
          "latency_total_ms": 34592.84,
          "accuracy": 0.6721,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.4444,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7756,
            "mean_kappa": 0.7756,
            "min_kappa": 0.6998,
            "max_kappa": 0.8925,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 10206,
          "total_tokens_output": 1001,
          "total_tokens": 11207,
          "latency_mean_ms": 559.42,
          "latency_p50_ms": 543.85,
          "latency_p95_ms": 747.06,
          "latency_p99_ms": 781.2,
          "latency_total_ms": 34124.77,
          "accuracy": 0.6885,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.525,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.678,
            "mean_kappa": 0.678,
            "min_kappa": 0.4812,
            "max_kappa": 0.7889,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 10132,
          "total_tokens_output": 934,
          "total_tokens": 11066,
          "latency_mean_ms": 535.18,
          "latency_p50_ms": 526.34,
          "latency_p95_ms": 771.03,
          "latency_p99_ms": 958.4,
          "latency_total_ms": 32645.96,
          "accuracy": 0.6393,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.4211,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7435,
            "mean_kappa": 0.7435,
            "min_kappa": 0.6546,
            "max_kappa": 0.813,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.39344262295081966,
          "total_tokens_input": 10209,
          "total_tokens_output": 1001,
          "total_tokens": 11210,
          "latency_mean_ms": 548.65,
          "latency_p50_ms": 534.85,
          "latency_p95_ms": 728.7,
          "latency_p99_ms": 1142.14,
          "latency_total_ms": 33467.74,
          "accuracy": 0.7541,
          "exact_match_rate": 0.3934,
          "llm_approval_rate": 0.5946,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.3934,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.687,
            "mean_kappa": 0.687,
            "min_kappa": 0.5392,
            "max_kappa": 0.9116,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.2459016393442623,
          "total_tokens_input": 10260,
          "total_tokens_output": 1047,
          "total_tokens": 11307,
          "latency_mean_ms": 607.23,
          "latency_p50_ms": 573.14,
          "latency_p95_ms": 792.59,
          "latency_p99_ms": 1576.05,
          "latency_total_ms": 37041.3,
          "accuracy": 0.5574,
          "exact_match_rate": 0.2459,
          "llm_approval_rate": 0.413,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.2459,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.606,
            "mean_kappa": 0.606,
            "min_kappa": 0.3441,
            "max_kappa": 0.8051,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 10228,
          "total_tokens_output": 983,
          "total_tokens": 11211,
          "latency_mean_ms": 567.1,
          "latency_p50_ms": 560.21,
          "latency_p95_ms": 799.4,
          "latency_p99_ms": 1094.87,
          "latency_total_ms": 34592.84,
          "accuracy": 0.623,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.3611,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7756,
            "mean_kappa": 0.7756,
            "min_kappa": 0.6998,
            "max_kappa": 0.8925,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 10206,
          "total_tokens_output": 1001,
          "total_tokens": 11207,
          "latency_mean_ms": 559.42,
          "latency_p50_ms": 543.85,
          "latency_p95_ms": 747.06,
          "latency_p99_ms": 781.2,
          "latency_total_ms": 34124.77,
          "accuracy": 0.5902,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.375,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.678,
            "mean_kappa": 0.678,
            "min_kappa": 0.4812,
            "max_kappa": 0.7889,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 10132,
          "total_tokens_output": 934,
          "total_tokens": 11066,
          "latency_mean_ms": 535.18,
          "latency_p50_ms": 526.34,
          "latency_p95_ms": 771.03,
          "latency_p99_ms": 958.4,
          "latency_total_ms": 32645.96,
          "accuracy": 0.5574,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.2895,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.1803,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7435,
            "mean_kappa": 0.7435,
            "min_kappa": 0.6546,
            "max_kappa": 0.813,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.39344262295081966,
          "total_tokens_input": 10209,
          "total_tokens_output": 1001,
          "total_tokens": 11210,
          "latency_mean_ms": 548.65,
          "latency_p50_ms": 534.85,
          "latency_p95_ms": 728.7,
          "latency_p99_ms": 1142.14,
          "latency_total_ms": 33467.74,
          "accuracy": 0.5738,
          "exact_match_rate": 0.3934,
          "llm_approval_rate": 0.2973,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.3934,
          "accuracy_boost_from_llm": 0.1803,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.687,
            "mean_kappa": 0.687,
            "min_kappa": 0.5392,
            "max_kappa": 0.9116,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.2459016393442623,
          "total_tokens_input": 10260,
          "total_tokens_output": 1047,
          "total_tokens": 11307,
          "latency_mean_ms": 607.23,
          "latency_p50_ms": 573.14,
          "latency_p95_ms": 792.59,
          "latency_p99_ms": 1576.05,
          "latency_total_ms": 37041.3,
          "accuracy": 0.459,
          "exact_match_rate": 0.2459,
          "llm_approval_rate": 0.2826,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 28,
          "incorrect": 33,
          "accuracy_from_exact_match": 0.2459,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.606,
            "mean_kappa": 0.606,
            "min_kappa": 0.3441,
            "max_kappa": 0.8051,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 10228,
          "total_tokens_output": 983,
          "total_tokens": 11211,
          "latency_mean_ms": 567.1,
          "latency_p50_ms": 560.21,
          "latency_p95_ms": 799.4,
          "latency_p99_ms": 1094.87,
          "latency_total_ms": 34592.84,
          "accuracy": 0.5246,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.1944,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 32,
          "incorrect": 29,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.1148,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7756,
            "mean_kappa": 0.7756,
            "min_kappa": 0.6998,
            "max_kappa": 0.8925,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 10206,
          "total_tokens_output": 1001,
          "total_tokens": 11207,
          "latency_mean_ms": 559.42,
          "latency_p50_ms": 543.85,
          "latency_p95_ms": 747.06,
          "latency_p99_ms": 781.2,
          "latency_total_ms": 34124.77,
          "accuracy": 0.8197,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.725,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 50,
          "incorrect": 11,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.4754,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.678,
            "mean_kappa": 0.678,
            "min_kappa": 0.4812,
            "max_kappa": 0.7889,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.2459016393442623,
          "total_tokens_input": 10260,
          "total_tokens_output": 1047,
          "total_tokens": 11307,
          "latency_mean_ms": 607.23,
          "latency_p50_ms": 573.14,
          "latency_p95_ms": 792.59,
          "latency_p99_ms": 1576.05,
          "latency_total_ms": 37041.3,
          "accuracy": 0.8033,
          "exact_match_rate": 0.2459,
          "llm_approval_rate": 0.7391,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.2459,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.606,
            "mean_kappa": 0.606,
            "min_kappa": 0.3441,
            "max_kappa": 0.8051,
            "n_items": 61
          }
        },
        "source": "phi3_finetuned_zero_shot_seed45__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.6914294117647058,
        "std": 0.05909170106663115
      },
      "mean_kappa": {
        "mean": 0.6914294117647058,
        "std": 0.05909170106663115
      },
      "min_kappa": {
        "mean": 0.5283529411764706,
        "std": 0.12857600232431562
      },
      "max_kappa": {
        "mean": 0.8369,
        "std": 0.0491030968233884
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "qwen-32b",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 13,
    "metrics": {
      "accuracy": {
        "mean": 0.6809615384615385,
        "std": 0.08249661567381499
      },
      "exact_match": {
        "mean": 0.06557377049180328,
        "std": 0.029466132271243183
      },
      "exact_match_rate": {
        "mean": 0.0656,
        "std": 0.029477918724151682
      },
      "llm_approval_rate": {
        "mean": 0.6589923076923077,
        "std": 0.08627843532637144
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 41.53846153846154,
        "std": 5.032439148860346
      },
      "incorrect": {
        "mean": 19.46153846153846,
        "std": 5.032439148860346
      },
      "accuracy_from_exact_match": {
        "mean": 0.0656,
        "std": 0.029477918724151682
      },
      "accuracy_boost_from_llm": {
        "mean": 0.6153846153846154,
        "std": 0.07968764836394122
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 18540.76923076923,
        "std": 38.32483397756974
      },
      "total_tokens_output": {
        "mean": 865,
        "std": 34.8336707136158
      },
      "total_tokens": {
        "mean": 19405.76923076923,
        "std": 71.1046399504646
      },
      "latency_mean_ms": {
        "mean": 1606.4876923076922,
        "std": 79.98076933804354
      },
      "latency_p50_ms": {
        "mean": 1523.3576923076923,
        "std": 80.57414160060634
      },
      "latency_p95_ms": {
        "mean": 2279.08,
        "std": 181.31716818029966
      },
      "latency_p99_ms": {
        "mean": 4048.0315384615383,
        "std": 950.9121948209371
      },
      "latency_total_ms": {
        "mean": 97995.67615384616,
        "std": 4878.857792470156
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18538,
          "total_tokens_output": 856,
          "total_tokens": 19394,
          "latency_mean_ms": 1641.56,
          "latency_p50_ms": 1613.78,
          "latency_p95_ms": 2186.47,
          "latency_p99_ms": 3659.85,
          "latency_total_ms": 100135.11,
          "accuracy": 0.6885,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.6667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6768,
            "mean_kappa": 0.6768,
            "min_kappa": 0.4894,
            "max_kappa": 0.8555,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18477,
          "total_tokens_output": 818,
          "total_tokens": 19295,
          "latency_mean_ms": 1473.54,
          "latency_p50_ms": 1418.85,
          "latency_p95_ms": 2033.64,
          "latency_p99_ms": 3104.46,
          "latency_total_ms": 89885.78,
          "accuracy": 0.6393,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.6071,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7268,
            "mean_kappa": 0.7268,
            "min_kappa": 0.6645,
            "max_kappa": 0.8327,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 18577,
          "total_tokens_output": 919,
          "total_tokens": 19496,
          "latency_mean_ms": 1698.01,
          "latency_p50_ms": 1570.92,
          "latency_p95_ms": 2426.56,
          "latency_p99_ms": 5716.59,
          "latency_total_ms": 103578.52,
          "accuracy": 0.7213,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.7167,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.7049,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7155,
            "mean_kappa": 0.7155,
            "min_kappa": 0.6546,
            "max_kappa": 0.796,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.09836065573770492,
          "total_tokens_input": 18572,
          "total_tokens_output": 870,
          "total_tokens": 19442,
          "latency_mean_ms": 1601.15,
          "latency_p50_ms": 1459.74,
          "latency_p95_ms": 2500.52,
          "latency_p99_ms": 3840.62,
          "latency_total_ms": 97670.15,
          "accuracy": 0.7869,
          "exact_match_rate": 0.0984,
          "llm_approval_rate": 0.7636,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 48,
          "incorrect": 13,
          "accuracy_from_exact_match": 0.0984,
          "accuracy_boost_from_llm": 0.6885,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8541,
            "mean_kappa": 0.8541,
            "min_kappa": 0.8242,
            "max_kappa": 0.9074,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18538,
          "total_tokens_output": 856,
          "total_tokens": 19394,
          "latency_mean_ms": 1641.56,
          "latency_p50_ms": 1613.78,
          "latency_p95_ms": 2186.47,
          "latency_p99_ms": 3659.85,
          "latency_total_ms": 100135.11,
          "accuracy": 0.7049,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.6842,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6768,
            "mean_kappa": 0.6768,
            "min_kappa": 0.4894,
            "max_kappa": 0.8555,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18477,
          "total_tokens_output": 818,
          "total_tokens": 19295,
          "latency_mean_ms": 1473.54,
          "latency_p50_ms": 1418.85,
          "latency_p95_ms": 2033.64,
          "latency_p99_ms": 3104.46,
          "latency_total_ms": 89885.78,
          "accuracy": 0.623,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.5893,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7268,
            "mean_kappa": 0.7268,
            "min_kappa": 0.6645,
            "max_kappa": 0.8327,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 18577,
          "total_tokens_output": 919,
          "total_tokens": 19496,
          "latency_mean_ms": 1698.01,
          "latency_p50_ms": 1570.92,
          "latency_p95_ms": 2426.56,
          "latency_p99_ms": 5716.59,
          "latency_total_ms": 103578.52,
          "accuracy": 0.6557,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.65,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7155,
            "mean_kappa": 0.7155,
            "min_kappa": 0.6546,
            "max_kappa": 0.796,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.09836065573770492,
          "total_tokens_input": 18572,
          "total_tokens_output": 870,
          "total_tokens": 19442,
          "latency_mean_ms": 1601.15,
          "latency_p50_ms": 1459.74,
          "latency_p95_ms": 2500.52,
          "latency_p99_ms": 3840.62,
          "latency_total_ms": 97670.15,
          "accuracy": 0.7541,
          "exact_match_rate": 0.0984,
          "llm_approval_rate": 0.7273,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.0984,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8541,
            "mean_kappa": 0.8541,
            "min_kappa": 0.8242,
            "max_kappa": 0.9074,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18538,
          "total_tokens_output": 856,
          "total_tokens": 19394,
          "latency_mean_ms": 1641.56,
          "latency_p50_ms": 1613.78,
          "latency_p95_ms": 2186.47,
          "latency_p99_ms": 3659.85,
          "latency_total_ms": 100135.11,
          "accuracy": 0.623,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.5965,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6768,
            "mean_kappa": 0.6768,
            "min_kappa": 0.4894,
            "max_kappa": 0.8555,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18477,
          "total_tokens_output": 818,
          "total_tokens": 19295,
          "latency_mean_ms": 1473.54,
          "latency_p50_ms": 1418.85,
          "latency_p95_ms": 2033.64,
          "latency_p99_ms": 3104.46,
          "latency_total_ms": 89885.78,
          "accuracy": 0.541,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.5,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 33,
          "incorrect": 28,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7268,
            "mean_kappa": 0.7268,
            "min_kappa": 0.6645,
            "max_kappa": 0.8327,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 18577,
          "total_tokens_output": 919,
          "total_tokens": 19496,
          "latency_mean_ms": 1698.01,
          "latency_p50_ms": 1570.92,
          "latency_p95_ms": 2426.56,
          "latency_p99_ms": 5716.59,
          "latency_total_ms": 103578.52,
          "accuracy": 0.5574,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.55,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7155,
            "mean_kappa": 0.7155,
            "min_kappa": 0.6546,
            "max_kappa": 0.796,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.09836065573770492,
          "total_tokens_input": 18572,
          "total_tokens_output": 870,
          "total_tokens": 19442,
          "latency_mean_ms": 1601.15,
          "latency_p50_ms": 1459.74,
          "latency_p95_ms": 2500.52,
          "latency_p99_ms": 3840.62,
          "latency_total_ms": 97670.15,
          "accuracy": 0.7213,
          "exact_match_rate": 0.0984,
          "llm_approval_rate": 0.6909,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.0984,
          "accuracy_boost_from_llm": 0.623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8541,
            "mean_kappa": 0.8541,
            "min_kappa": 0.8242,
            "max_kappa": 0.9074,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18538,
          "total_tokens_output": 856,
          "total_tokens": 19394,
          "latency_mean_ms": 1641.56,
          "latency_p50_ms": 1613.78,
          "latency_p95_ms": 2186.47,
          "latency_p99_ms": 3659.85,
          "latency_total_ms": 100135.11,
          "accuracy": 0.8361,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.8246,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 51,
          "incorrect": 10,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.7705,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6768,
            "mean_kappa": 0.6768,
            "min_kappa": 0.4894,
            "max_kappa": 0.8555,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_few_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.7381846153846153,
        "std": 0.06639857327190381
      },
      "mean_kappa": {
        "mean": 0.7381846153846153,
        "std": 0.06639857327190381
      },
      "min_kappa": {
        "mean": 0.6451923076923077,
        "std": 0.12234884213427455
      },
      "max_kappa": {
        "mean": 0.8484846153846154,
        "std": 0.03885010337881197
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "qwen-32b",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 13,
    "metrics": {
      "accuracy": {
        "mean": 0.5018923076923077,
        "std": 0.12692686847483634
      },
      "exact_match": {
        "mean": 0.021437578814627996,
        "std": 0.013464159208110104
      },
      "exact_match_rate": {
        "mean": 0.021446153846153847,
        "std": 0.013469544871793348
      },
      "llm_approval_rate": {
        "mean": 0.4908,
        "std": 0.1309998355841599
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 30.615384615384617,
        "std": 7.741381923328692
      },
      "incorrect": {
        "mean": 30.384615384615383,
        "std": 7.741381923328692
      },
      "accuracy_from_exact_match": {
        "mean": 0.021446153846153847,
        "std": 0.013469544871793348
      },
      "accuracy_boost_from_llm": {
        "mean": 0.4804538461538462,
        "std": 0.1281912490436104
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 9442.076923076924,
        "std": 32.85741114962683
      },
      "total_tokens_output": {
        "mean": 872.4615384615385,
        "std": 29.91170438426399
      },
      "total_tokens": {
        "mean": 10314.538461538461,
        "std": 61.49123187604177
      },
      "latency_mean_ms": {
        "mean": 1572.6976923076923,
        "std": 82.51177157545894
      },
      "latency_p50_ms": {
        "mean": 1504.0838461538463,
        "std": 75.6329387480656
      },
      "latency_p95_ms": {
        "mean": 2536.35,
        "std": 415.73120748498434
      },
      "latency_p99_ms": {
        "mean": 4069.0607692307694,
        "std": 858.7506418984191
      },
      "latency_total_ms": {
        "mean": 95934.48384615385,
        "std": 5033.110475268195
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9449,
          "total_tokens_output": 890,
          "total_tokens": 10339,
          "latency_mean_ms": 1563.04,
          "latency_p50_ms": 1492.13,
          "latency_p95_ms": 2467.32,
          "latency_p99_ms": 4226.81,
          "latency_total_ms": 95345.39,
          "accuracy": 0.4426,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.4237,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 27,
          "incorrect": 34,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4528,
            "mean_kappa": 0.4528,
            "min_kappa": 0.1729,
            "max_kappa": 0.7793,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9388,
          "total_tokens_output": 818,
          "total_tokens": 10206,
          "latency_mean_ms": 1438.18,
          "latency_p50_ms": 1382.04,
          "latency_p95_ms": 2193.1,
          "latency_p99_ms": 2562.85,
          "latency_total_ms": 87729.08,
          "accuracy": 0.5574,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.5424,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.5246,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7607,
            "mean_kappa": 0.7607,
            "min_kappa": 0.6727,
            "max_kappa": 0.8358,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9446,
          "total_tokens_output": 885,
          "total_tokens": 10331,
          "latency_mean_ms": 1631.9,
          "latency_p50_ms": 1563.5,
          "latency_p95_ms": 2239.2,
          "latency_p99_ms": 4881.51,
          "latency_total_ms": 99545.69,
          "accuracy": 0.6066,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.6066,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.6066,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5931,
            "mean_kappa": 0.5931,
            "min_kappa": 0.5166,
            "max_kappa": 0.6988,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9483,
          "total_tokens_output": 891,
          "total_tokens": 10374,
          "latency_mean_ms": 1660.89,
          "latency_p50_ms": 1582.65,
          "latency_p95_ms": 3268.79,
          "latency_p99_ms": 4552.49,
          "latency_total_ms": 101314.14,
          "accuracy": 0.6066,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.6,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.5902,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8227,
            "mean_kappa": 0.8227,
            "min_kappa": 0.7681,
            "max_kappa": 0.8681,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9449,
          "total_tokens_output": 890,
          "total_tokens": 10339,
          "latency_mean_ms": 1563.04,
          "latency_p50_ms": 1492.13,
          "latency_p95_ms": 2467.32,
          "latency_p99_ms": 4226.81,
          "latency_total_ms": 95345.39,
          "accuracy": 0.377,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.3559,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 23,
          "incorrect": 38,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4528,
            "mean_kappa": 0.4528,
            "min_kappa": 0.1729,
            "max_kappa": 0.7793,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9388,
          "total_tokens_output": 818,
          "total_tokens": 10206,
          "latency_mean_ms": 1438.18,
          "latency_p50_ms": 1382.04,
          "latency_p95_ms": 2193.1,
          "latency_p99_ms": 2562.85,
          "latency_total_ms": 87729.08,
          "accuracy": 0.4918,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.4746,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 30,
          "incorrect": 31,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7607,
            "mean_kappa": 0.7607,
            "min_kappa": 0.6727,
            "max_kappa": 0.8358,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9446,
          "total_tokens_output": 885,
          "total_tokens": 10331,
          "latency_mean_ms": 1631.9,
          "latency_p50_ms": 1563.5,
          "latency_p95_ms": 2239.2,
          "latency_p99_ms": 4881.51,
          "latency_total_ms": 99545.69,
          "accuracy": 0.459,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.459,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 28,
          "incorrect": 33,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5931,
            "mean_kappa": 0.5931,
            "min_kappa": 0.5166,
            "max_kappa": 0.6988,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9483,
          "total_tokens_output": 891,
          "total_tokens": 10374,
          "latency_mean_ms": 1660.89,
          "latency_p50_ms": 1582.65,
          "latency_p95_ms": 3268.79,
          "latency_p99_ms": 4552.49,
          "latency_total_ms": 101314.14,
          "accuracy": 0.5574,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.55,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8227,
            "mean_kappa": 0.8227,
            "min_kappa": 0.7681,
            "max_kappa": 0.8681,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9449,
          "total_tokens_output": 890,
          "total_tokens": 10339,
          "latency_mean_ms": 1563.04,
          "latency_p50_ms": 1492.13,
          "latency_p95_ms": 2467.32,
          "latency_p99_ms": 4226.81,
          "latency_total_ms": 95345.39,
          "accuracy": 0.2787,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.2542,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 17,
          "incorrect": 44,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4528,
            "mean_kappa": 0.4528,
            "min_kappa": 0.1729,
            "max_kappa": 0.7793,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9388,
          "total_tokens_output": 818,
          "total_tokens": 10206,
          "latency_mean_ms": 1438.18,
          "latency_p50_ms": 1382.04,
          "latency_p95_ms": 2193.1,
          "latency_p99_ms": 2562.85,
          "latency_total_ms": 87729.08,
          "accuracy": 0.4426,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.4237,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 27,
          "incorrect": 34,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7607,
            "mean_kappa": 0.7607,
            "min_kappa": 0.6727,
            "max_kappa": 0.8358,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9446,
          "total_tokens_output": 885,
          "total_tokens": 10331,
          "latency_mean_ms": 1631.9,
          "latency_p50_ms": 1563.5,
          "latency_p95_ms": 2239.2,
          "latency_p99_ms": 4881.51,
          "latency_total_ms": 99545.69,
          "accuracy": 0.377,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.377,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 23,
          "incorrect": 38,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5931,
            "mean_kappa": 0.5931,
            "min_kappa": 0.5166,
            "max_kappa": 0.6988,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9483,
          "total_tokens_output": 891,
          "total_tokens": 10374,
          "latency_mean_ms": 1660.89,
          "latency_p50_ms": 1582.65,
          "latency_p95_ms": 3268.79,
          "latency_p99_ms": 4552.49,
          "latency_total_ms": 101314.14,
          "accuracy": 0.5246,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.5167,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 32,
          "incorrect": 29,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.5082,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8227,
            "mean_kappa": 0.8227,
            "min_kappa": 0.7681,
            "max_kappa": 0.8681,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9449,
          "total_tokens_output": 890,
          "total_tokens": 10339,
          "latency_mean_ms": 1563.04,
          "latency_p50_ms": 1492.13,
          "latency_p95_ms": 2467.32,
          "latency_p99_ms": 4226.81,
          "latency_total_ms": 95345.39,
          "accuracy": 0.8033,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.7966,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.7705,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4528,
            "mean_kappa": 0.4528,
            "min_kappa": 0.1729,
            "max_kappa": 0.7793,
            "n_items": 61
          }
        },
        "source": "qwen-32b_baseline_zero_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.6415923076923077,
        "std": 0.1495080572129731
      },
      "mean_kappa": {
        "mean": 0.6415923076923077,
        "std": 0.1495080572129731
      },
      "min_kappa": {
        "mean": 0.5049076923076923,
        "std": 0.23755159912852766
      },
      "max_kappa": {
        "mean": 0.7942538461538461,
        "std": 0.06187256898577437
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "qwen-3b",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 10,
    "metrics": {
      "accuracy": {
        "mean": 0.36067,
        "std": 0.0775872805297363
      },
      "exact_match": {
        "mean": 0.009836065573770493,
        "std": 0.008031113910764519
      },
      "exact_match_rate": {
        "mean": 0.009840000000000002,
        "std": 0.008034326356328825
      },
      "llm_approval_rate": {
        "mean": 0.35391,
        "std": 0.08095306603211518
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 22,
        "std": 4.732863826479693
      },
      "incorrect": {
        "mean": 39,
        "std": 4.732863826479693
      },
      "accuracy_from_exact_match": {
        "mean": 0.009840000000000002,
        "std": 0.008034326356328825
      },
      "accuracy_boost_from_llm": {
        "mean": 0.35084,
        "std": 0.08236240890114858
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 18518.8,
        "std": 27.39269975741712
      },
      "total_tokens_output": {
        "mean": 885.8,
        "std": 31.999374993896364
      },
      "total_tokens": {
        "mean": 19404.6,
        "std": 58.67742325630873
      },
      "latency_mean_ms": {
        "mean": 468.395,
        "std": 26.82772232225465
      },
      "latency_p50_ms": {
        "mean": 452.043,
        "std": 23.610830163295816
      },
      "latency_p95_ms": {
        "mean": 729.095,
        "std": 9.81739705828381
      },
      "latency_p99_ms": {
        "mean": 1321.14,
        "std": 240.037018895003
      },
      "latency_total_ms": {
        "mean": 28572.158,
        "std": 1636.475929146531
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 18538,
          "total_tokens_output": 917,
          "total_tokens": 19455,
          "latency_mean_ms": 497.24,
          "latency_p50_ms": 480.15,
          "latency_p95_ms": 717.44,
          "latency_p99_ms": 1613.43,
          "latency_total_ms": 30331.7,
          "accuracy": 0.3607,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.3607,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 22,
          "incorrect": 39,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7048,
            "mean_kappa": 0.7048,
            "min_kappa": 0.4985,
            "max_kappa": 0.929,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 18477,
          "total_tokens_output": 840,
          "total_tokens": 19317,
          "latency_mean_ms": 432.58,
          "latency_p50_ms": 426.14,
          "latency_p95_ms": 733.75,
          "latency_p99_ms": 1093.06,
          "latency_total_ms": 26387.48,
          "accuracy": 0.3115,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.3,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 19,
          "incorrect": 42,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8425,
            "mean_kappa": 0.8425,
            "min_kappa": 0.7639,
            "max_kappa": 0.8837,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 18535,
          "total_tokens_output": 890,
          "total_tokens": 19425,
          "latency_mean_ms": 465.75,
          "latency_p50_ms": 440.47,
          "latency_p95_ms": 739.98,
          "latency_p99_ms": 1159.5,
          "latency_total_ms": 28410.78,
          "accuracy": 0.377,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.3667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 23,
          "incorrect": 38,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9285,
            "mean_kappa": 0.9285,
            "min_kappa": 0.9274,
            "max_kappa": 0.929,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 18538,
          "total_tokens_output": 917,
          "total_tokens": 19455,
          "latency_mean_ms": 497.24,
          "latency_p50_ms": 480.15,
          "latency_p95_ms": 717.44,
          "latency_p99_ms": 1613.43,
          "latency_total_ms": 30331.7,
          "accuracy": 0.377,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.377,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 23,
          "incorrect": 38,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7048,
            "mean_kappa": 0.7048,
            "min_kappa": 0.4985,
            "max_kappa": 0.929,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 18477,
          "total_tokens_output": 840,
          "total_tokens": 19317,
          "latency_mean_ms": 432.58,
          "latency_p50_ms": 426.14,
          "latency_p95_ms": 733.75,
          "latency_p99_ms": 1093.06,
          "latency_total_ms": 26387.48,
          "accuracy": 0.2951,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.2833,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 18,
          "incorrect": 43,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8425,
            "mean_kappa": 0.8425,
            "min_kappa": 0.7639,
            "max_kappa": 0.8837,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 18535,
          "total_tokens_output": 890,
          "total_tokens": 19425,
          "latency_mean_ms": 465.75,
          "latency_p50_ms": 440.47,
          "latency_p95_ms": 739.98,
          "latency_p99_ms": 1159.5,
          "latency_total_ms": 28410.78,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.3333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9285,
            "mean_kappa": 0.9285,
            "min_kappa": 0.9274,
            "max_kappa": 0.929,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 18538,
          "total_tokens_output": 917,
          "total_tokens": 19455,
          "latency_mean_ms": 497.24,
          "latency_p50_ms": 480.15,
          "latency_p95_ms": 717.44,
          "latency_p99_ms": 1613.43,
          "latency_total_ms": 30331.7,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.3443,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7048,
            "mean_kappa": 0.7048,
            "min_kappa": 0.4985,
            "max_kappa": 0.929,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 18477,
          "total_tokens_output": 840,
          "total_tokens": 19317,
          "latency_mean_ms": 432.58,
          "latency_p50_ms": 426.14,
          "latency_p95_ms": 733.75,
          "latency_p99_ms": 1093.06,
          "latency_total_ms": 26387.48,
          "accuracy": 0.2787,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.2667,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 17,
          "incorrect": 44,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8425,
            "mean_kappa": 0.8425,
            "min_kappa": 0.7639,
            "max_kappa": 0.8837,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 18535,
          "total_tokens_output": 890,
          "total_tokens": 19425,
          "latency_mean_ms": 465.75,
          "latency_p50_ms": 440.47,
          "latency_p95_ms": 739.98,
          "latency_p99_ms": 1159.5,
          "latency_total_ms": 28410.78,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.3333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9285,
            "mean_kappa": 0.9285,
            "min_kappa": 0.9274,
            "max_kappa": 0.929,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 18538,
          "total_tokens_output": 917,
          "total_tokens": 19455,
          "latency_mean_ms": 497.24,
          "latency_p50_ms": 480.15,
          "latency_p95_ms": 717.44,
          "latency_p99_ms": 1613.43,
          "latency_total_ms": 30331.7,
          "accuracy": 0.5738,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.5738,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.5738,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7048,
            "mean_kappa": 0.7048,
            "min_kappa": 0.4985,
            "max_kappa": 0.929,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_few_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.81322,
        "std": 0.09458328393537624
      },
      "mean_kappa": {
        "mean": 0.81322,
        "std": 0.09458328393537624
      },
      "min_kappa": {
        "mean": 0.70679,
        "std": 0.18147448002405187
      },
      "max_kappa": {
        "mean": 0.9154100000000001,
        "std": 0.02075906789814996
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "qwen-3b",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.05431875,
        "std": 0.06752517325736751
      },
      "exact_match": {
        "mean": 0.0,
        "std": 0.0
      },
      "exact_match_rate": {
        "mean": 0.0,
        "std": 0.0
      },
      "llm_approval_rate": {
        "mean": 0.05431875,
        "std": 0.06752517325736751
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 3.3125,
        "std": 4.118840097648851
      },
      "incorrect": {
        "mean": 57.6875,
        "std": 4.118840097648851
      },
      "accuracy_from_exact_match": {
        "mean": 0.0,
        "std": 0.0
      },
      "accuracy_boost_from_llm": {
        "mean": 0.05431875,
        "std": 0.06752517325736751
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 9450.6875,
        "std": 34.61885098829827
      },
      "total_tokens_output": {
        "mean": 1174.5625,
        "std": 138.68397922525153
      },
      "total_tokens": {
        "mean": 10625.25,
        "std": 152.46413512692092
      },
      "latency_mean_ms": {
        "mean": 652.3043749999999,
        "std": 85.90129196996617
      },
      "latency_p50_ms": {
        "mean": 512.35,
        "std": 31.868954720856475
      },
      "latency_p95_ms": {
        "mean": 1290.0149999999999,
        "std": 360.35994240134403
      },
      "latency_p99_ms": {
        "mean": 3785.445625,
        "std": 1309.0461121842154
      },
      "latency_total_ms": {
        "mean": 39790.5675,
        "std": 5240.038316106931
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9449,
          "total_tokens_output": 1096,
          "total_tokens": 10545,
          "latency_mean_ms": 604.76,
          "latency_p50_ms": 530.53,
          "latency_p95_ms": 1255.59,
          "latency_p99_ms": 3141.37,
          "latency_total_ms": 36890.1,
          "accuracy": 0.0328,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0328,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 2,
          "incorrect": 59,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0328,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5697,
            "mean_kappa": 0.5697,
            "min_kappa": 0.1394,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9388,
          "total_tokens_output": 1229,
          "total_tokens": 10617,
          "latency_mean_ms": 680.68,
          "latency_p50_ms": 496.4,
          "latency_p95_ms": 1084.26,
          "latency_p99_ms": 5148.73,
          "latency_total_ms": 41521.65,
          "accuracy": 0.0328,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0328,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 2,
          "incorrect": 59,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0328,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7728,
            "mean_kappa": 0.7728,
            "min_kappa": 0.6592,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9446,
          "total_tokens_output": 954,
          "total_tokens": 10400,
          "latency_mean_ms": 519.75,
          "latency_p50_ms": 454.5,
          "latency_p95_ms": 937.62,
          "latency_p99_ms": 1655.9,
          "latency_total_ms": 31704.87,
          "accuracy": 0.0328,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0328,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 2,
          "incorrect": 59,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0328,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8612,
            "mean_kappa": 0.8612,
            "min_kappa": 0.7918,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9488,
          "total_tokens_output": 1365,
          "total_tokens": 10853,
          "latency_mean_ms": 780.39,
          "latency_p50_ms": 545.7,
          "latency_p95_ms": 2005.59,
          "latency_p99_ms": 5258.35,
          "latency_total_ms": 47604.01,
          "accuracy": 0.0492,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0492,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 3,
          "incorrect": 58,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0492,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7822,
            "mean_kappa": 0.7822,
            "min_kappa": 0.6494,
            "max_kappa": 0.8486,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9483,
          "total_tokens_output": 1255,
          "total_tokens": 10738,
          "latency_mean_ms": 691.79,
          "latency_p50_ms": 528.56,
          "latency_p95_ms": 1178.49,
          "latency_p99_ms": 3937.57,
          "latency_total_ms": 42199.03,
          "accuracy": 0.0164,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0164,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 1,
          "incorrect": 60,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0164,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7728,
            "mean_kappa": 0.7728,
            "min_kappa": 0.6592,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9449,
          "total_tokens_output": 1096,
          "total_tokens": 10545,
          "latency_mean_ms": 604.76,
          "latency_p50_ms": 530.53,
          "latency_p95_ms": 1255.59,
          "latency_p99_ms": 3141.37,
          "latency_total_ms": 36890.1,
          "accuracy": 0.0328,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0328,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 2,
          "incorrect": 59,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0328,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5697,
            "mean_kappa": 0.5697,
            "min_kappa": 0.1394,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9388,
          "total_tokens_output": 1229,
          "total_tokens": 10617,
          "latency_mean_ms": 680.68,
          "latency_p50_ms": 496.4,
          "latency_p95_ms": 1084.26,
          "latency_p99_ms": 5148.73,
          "latency_total_ms": 41521.65,
          "accuracy": 0.0328,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0328,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 2,
          "incorrect": 59,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0328,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7728,
            "mean_kappa": 0.7728,
            "min_kappa": 0.6592,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9446,
          "total_tokens_output": 954,
          "total_tokens": 10400,
          "latency_mean_ms": 519.75,
          "latency_p50_ms": 454.5,
          "latency_p95_ms": 937.62,
          "latency_p99_ms": 1655.9,
          "latency_total_ms": 31704.87,
          "accuracy": 0.0492,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0492,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 3,
          "incorrect": 58,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0492,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8612,
            "mean_kappa": 0.8612,
            "min_kappa": 0.7918,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9488,
          "total_tokens_output": 1365,
          "total_tokens": 10853,
          "latency_mean_ms": 780.39,
          "latency_p50_ms": 545.7,
          "latency_p95_ms": 2005.59,
          "latency_p99_ms": 5258.35,
          "latency_total_ms": 47604.01,
          "accuracy": 0.0656,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0656,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 4,
          "incorrect": 57,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0656,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7822,
            "mean_kappa": 0.7822,
            "min_kappa": 0.6494,
            "max_kappa": 0.8486,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9483,
          "total_tokens_output": 1255,
          "total_tokens": 10738,
          "latency_mean_ms": 691.79,
          "latency_p50_ms": 528.56,
          "latency_p95_ms": 1178.49,
          "latency_p99_ms": 3937.57,
          "latency_total_ms": 42199.03,
          "accuracy": 0.0328,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0328,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 2,
          "incorrect": 59,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0328,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7728,
            "mean_kappa": 0.7728,
            "min_kappa": 0.6592,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9449,
          "total_tokens_output": 1096,
          "total_tokens": 10545,
          "latency_mean_ms": 604.76,
          "latency_p50_ms": 530.53,
          "latency_p95_ms": 1255.59,
          "latency_p99_ms": 3141.37,
          "latency_total_ms": 36890.1,
          "accuracy": 0.0328,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0328,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 2,
          "incorrect": 59,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0328,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5697,
            "mean_kappa": 0.5697,
            "min_kappa": 0.1394,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9388,
          "total_tokens_output": 1229,
          "total_tokens": 10617,
          "latency_mean_ms": 680.68,
          "latency_p50_ms": 496.4,
          "latency_p95_ms": 1084.26,
          "latency_p99_ms": 5148.73,
          "latency_total_ms": 41521.65,
          "accuracy": 0.0164,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0164,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 1,
          "incorrect": 60,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0164,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7728,
            "mean_kappa": 0.7728,
            "min_kappa": 0.6592,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9446,
          "total_tokens_output": 954,
          "total_tokens": 10400,
          "latency_mean_ms": 519.75,
          "latency_p50_ms": 454.5,
          "latency_p95_ms": 937.62,
          "latency_p99_ms": 1655.9,
          "latency_total_ms": 31704.87,
          "accuracy": 0.0492,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0492,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 3,
          "incorrect": 58,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0492,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8612,
            "mean_kappa": 0.8612,
            "min_kappa": 0.7918,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9488,
          "total_tokens_output": 1365,
          "total_tokens": 10853,
          "latency_mean_ms": 780.39,
          "latency_p50_ms": 545.7,
          "latency_p95_ms": 2005.59,
          "latency_p99_ms": 5258.35,
          "latency_total_ms": 47604.01,
          "accuracy": 0.0492,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0492,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 3,
          "incorrect": 58,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0492,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7822,
            "mean_kappa": 0.7822,
            "min_kappa": 0.6494,
            "max_kappa": 0.8486,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9483,
          "total_tokens_output": 1255,
          "total_tokens": 10738,
          "latency_mean_ms": 691.79,
          "latency_p50_ms": 528.56,
          "latency_p95_ms": 1178.49,
          "latency_p99_ms": 3937.57,
          "latency_total_ms": 42199.03,
          "accuracy": 0.0328,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.0328,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 2,
          "incorrect": 59,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.0328,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7728,
            "mean_kappa": 0.7728,
            "min_kappa": 0.6592,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9449,
          "total_tokens_output": 1096,
          "total_tokens": 10545,
          "latency_mean_ms": 604.76,
          "latency_p50_ms": 530.53,
          "latency_p95_ms": 1255.59,
          "latency_p99_ms": 3141.37,
          "latency_total_ms": 36890.1,
          "accuracy": 0.3115,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.3115,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 19,
          "incorrect": 42,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5697,
            "mean_kappa": 0.5697,
            "min_kappa": 0.1394,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_baseline_zero_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.7403625,
        "std": 0.10364366161878882
      },
      "mean_kappa": {
        "mean": 0.7403625,
        "std": 0.10364366161878882
      },
      "min_kappa": {
        "mean": 0.552275,
        "std": 0.24378234016228492
      },
      "max_kappa": {
        "mean": 0.9716125,
        "std": 0.059093293559844835
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "qwen-3b",
    "condition": "finetuned_few_shot",
    "finetuned": true,
    "few_shot": true,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.68441875,
        "std": 0.06721413745215735
      },
      "exact_match": {
        "mean": 0.40881147540983603,
        "std": 0.05603487259784965
      },
      "exact_match_rate": {
        "mean": 0.40879375,
        "std": 0.05602472075733622
      },
      "llm_approval_rate": {
        "mean": 0.465325,
        "std": 0.10427504795012084
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 41.75,
        "std": 4.100304866714182
      },
      "incorrect": {
        "mean": 19.25,
        "std": 4.100304866714182
      },
      "accuracy_from_exact_match": {
        "mean": 0.40879375,
        "std": 0.05602472075733622
      },
      "accuracy_boost_from_llm": {
        "mean": 0.2756125,
        "std": 0.06790105738315126
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 18539.6875,
        "std": 34.61885098829827
      },
      "total_tokens_output": {
        "mean": 779.1875,
        "std": 38.64456421995207
      },
      "total_tokens": {
        "mean": 19318.875,
        "std": 51.013325465019435
      },
      "latency_mean_ms": {
        "mean": 410.66125,
        "std": 15.568954233907304
      },
      "latency_p50_ms": {
        "mean": 403.943125,
        "std": 5.37259681014452
      },
      "latency_p95_ms": {
        "mean": 574.190625,
        "std": 13.38260926947262
      },
      "latency_p99_ms": {
        "mean": 878.11,
        "std": 423.1716054835201
      },
      "latency_total_ms": {
        "mean": 25050.3125,
        "std": 949.756733073659
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4426229508196721,
          "total_tokens_input": 18538,
          "total_tokens_output": 773,
          "total_tokens": 19311,
          "latency_mean_ms": 394.27,
          "latency_p50_ms": 401.68,
          "latency_p95_ms": 556.47,
          "latency_p99_ms": 706.66,
          "latency_total_ms": 24050.48,
          "accuracy": 0.7213,
          "exact_match_rate": 0.4426,
          "llm_approval_rate": 0.5,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.4426,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8039,
            "mean_kappa": 0.8039,
            "min_kappa": 0.6806,
            "max_kappa": 0.8754,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 18477,
          "total_tokens_output": 753,
          "total_tokens": 19230,
          "latency_mean_ms": 414.23,
          "latency_p50_ms": 403.35,
          "latency_p95_ms": 567.48,
          "latency_p99_ms": 803.04,
          "latency_total_ms": 25268.07,
          "accuracy": 0.7213,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.5143,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9227,
            "mean_kappa": 0.9227,
            "min_kappa": 0.884,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 18535,
          "total_tokens_output": 858,
          "total_tokens": 19393,
          "latency_mean_ms": 439.68,
          "latency_p50_ms": 403.82,
          "latency_p95_ms": 589.0,
          "latency_p99_ms": 1745.05,
          "latency_total_ms": 26820.55,
          "accuracy": 0.7705,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.6316,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7928,
            "mean_kappa": 0.7928,
            "min_kappa": 0.6911,
            "max_kappa": 0.9548,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3114754098360656,
          "total_tokens_input": 18577,
          "total_tokens_output": 761,
          "total_tokens": 19338,
          "latency_mean_ms": 401.97,
          "latency_p50_ms": 414.17,
          "latency_p95_ms": 573.25,
          "latency_p99_ms": 598.92,
          "latency_total_ms": 24519.91,
          "accuracy": 0.6721,
          "exact_match_rate": 0.3115,
          "llm_approval_rate": 0.5238,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.3115,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7967,
            "mean_kappa": 0.7967,
            "min_kappa": 0.7301,
            "max_kappa": 0.8672,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.47540983606557374,
          "total_tokens_input": 18572,
          "total_tokens_output": 753,
          "total_tokens": 19325,
          "latency_mean_ms": 408.62,
          "latency_p50_ms": 397.45,
          "latency_p95_ms": 590.66,
          "latency_p99_ms": 594.03,
          "latency_total_ms": 24925.83,
          "accuracy": 0.7049,
          "exact_match_rate": 0.4754,
          "llm_approval_rate": 0.4375,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.4754,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8061,
            "mean_kappa": 0.8061,
            "min_kappa": 0.7126,
            "max_kappa": 0.8585,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4426229508196721,
          "total_tokens_input": 18538,
          "total_tokens_output": 773,
          "total_tokens": 19311,
          "latency_mean_ms": 394.27,
          "latency_p50_ms": 401.68,
          "latency_p95_ms": 556.47,
          "latency_p99_ms": 706.66,
          "latency_total_ms": 24050.48,
          "accuracy": 0.7377,
          "exact_match_rate": 0.4426,
          "llm_approval_rate": 0.5294,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.4426,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8039,
            "mean_kappa": 0.8039,
            "min_kappa": 0.6806,
            "max_kappa": 0.8754,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 18477,
          "total_tokens_output": 753,
          "total_tokens": 19230,
          "latency_mean_ms": 414.23,
          "latency_p50_ms": 403.35,
          "latency_p95_ms": 567.48,
          "latency_p99_ms": 803.04,
          "latency_total_ms": 25268.07,
          "accuracy": 0.7213,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.5143,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9227,
            "mean_kappa": 0.9227,
            "min_kappa": 0.884,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 18535,
          "total_tokens_output": 858,
          "total_tokens": 19393,
          "latency_mean_ms": 439.68,
          "latency_p50_ms": 403.82,
          "latency_p95_ms": 589.0,
          "latency_p99_ms": 1745.05,
          "latency_total_ms": 26820.55,
          "accuracy": 0.7541,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.6053,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.377,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7928,
            "mean_kappa": 0.7928,
            "min_kappa": 0.6911,
            "max_kappa": 0.9548,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3114754098360656,
          "total_tokens_input": 18577,
          "total_tokens_output": 761,
          "total_tokens": 19338,
          "latency_mean_ms": 401.97,
          "latency_p50_ms": 414.17,
          "latency_p95_ms": 573.25,
          "latency_p99_ms": 598.92,
          "latency_total_ms": 24519.91,
          "accuracy": 0.5738,
          "exact_match_rate": 0.3115,
          "llm_approval_rate": 0.381,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.3115,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7967,
            "mean_kappa": 0.7967,
            "min_kappa": 0.7301,
            "max_kappa": 0.8672,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.47540983606557374,
          "total_tokens_input": 18572,
          "total_tokens_output": 753,
          "total_tokens": 19325,
          "latency_mean_ms": 408.62,
          "latency_p50_ms": 397.45,
          "latency_p95_ms": 590.66,
          "latency_p99_ms": 594.03,
          "latency_total_ms": 24925.83,
          "accuracy": 0.6721,
          "exact_match_rate": 0.4754,
          "llm_approval_rate": 0.375,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.4754,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8061,
            "mean_kappa": 0.8061,
            "min_kappa": 0.7126,
            "max_kappa": 0.8585,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4426229508196721,
          "total_tokens_input": 18538,
          "total_tokens_output": 773,
          "total_tokens": 19311,
          "latency_mean_ms": 394.27,
          "latency_p50_ms": 401.68,
          "latency_p95_ms": 556.47,
          "latency_p99_ms": 706.66,
          "latency_total_ms": 24050.48,
          "accuracy": 0.6557,
          "exact_match_rate": 0.4426,
          "llm_approval_rate": 0.3824,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.4426,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8039,
            "mean_kappa": 0.8039,
            "min_kappa": 0.6806,
            "max_kappa": 0.8754,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 18477,
          "total_tokens_output": 753,
          "total_tokens": 19230,
          "latency_mean_ms": 414.23,
          "latency_p50_ms": 403.35,
          "latency_p95_ms": 567.48,
          "latency_p99_ms": 803.04,
          "latency_total_ms": 25268.07,
          "accuracy": 0.6721,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.4286,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9227,
            "mean_kappa": 0.9227,
            "min_kappa": 0.884,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 18535,
          "total_tokens_output": 858,
          "total_tokens": 19393,
          "latency_mean_ms": 439.68,
          "latency_p50_ms": 403.82,
          "latency_p95_ms": 589.0,
          "latency_p99_ms": 1745.05,
          "latency_total_ms": 26820.55,
          "accuracy": 0.6393,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.4211,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7928,
            "mean_kappa": 0.7928,
            "min_kappa": 0.6911,
            "max_kappa": 0.9548,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3114754098360656,
          "total_tokens_input": 18577,
          "total_tokens_output": 761,
          "total_tokens": 19338,
          "latency_mean_ms": 401.97,
          "latency_p50_ms": 414.17,
          "latency_p95_ms": 573.25,
          "latency_p99_ms": 598.92,
          "latency_total_ms": 24519.91,
          "accuracy": 0.541,
          "exact_match_rate": 0.3115,
          "llm_approval_rate": 0.3333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 33,
          "incorrect": 28,
          "accuracy_from_exact_match": 0.3115,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7967,
            "mean_kappa": 0.7967,
            "min_kappa": 0.7301,
            "max_kappa": 0.8672,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.47540983606557374,
          "total_tokens_input": 18572,
          "total_tokens_output": 753,
          "total_tokens": 19325,
          "latency_mean_ms": 408.62,
          "latency_p50_ms": 397.45,
          "latency_p95_ms": 590.66,
          "latency_p99_ms": 594.03,
          "latency_total_ms": 24925.83,
          "accuracy": 0.6066,
          "exact_match_rate": 0.4754,
          "llm_approval_rate": 0.25,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.4754,
          "accuracy_boost_from_llm": 0.1311,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8061,
            "mean_kappa": 0.8061,
            "min_kappa": 0.7126,
            "max_kappa": 0.8585,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4426229508196721,
          "total_tokens_input": 18538,
          "total_tokens_output": 773,
          "total_tokens": 19311,
          "latency_mean_ms": 394.27,
          "latency_p50_ms": 401.68,
          "latency_p95_ms": 556.47,
          "latency_p99_ms": 706.66,
          "latency_total_ms": 24050.48,
          "accuracy": 0.7869,
          "exact_match_rate": 0.4426,
          "llm_approval_rate": 0.6176,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 48,
          "incorrect": 13,
          "accuracy_from_exact_match": 0.4426,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8039,
            "mean_kappa": 0.8039,
            "min_kappa": 0.6806,
            "max_kappa": 0.8754,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_few_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.8231562499999999,
        "std": 0.048054096713365656
      },
      "mean_kappa": {
        "mean": 0.8231562499999999,
        "std": 0.048054096713365656
      },
      "min_kappa": {
        "mean": 0.7359875,
        "std": 0.07322216941439252
      },
      "max_kappa": {
        "mean": 0.9089437499999999,
        "std": 0.05508185918192577
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "qwen-3b",
    "condition": "finetuned_zero_shot",
    "finetuned": true,
    "few_shot": false,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.6495875,
        "std": 0.0798592580340564
      },
      "exact_match": {
        "mean": 0.36372950819672134,
        "std": 0.06911997940788087
      },
      "exact_match_rate": {
        "mean": 0.3637375,
        "std": 0.06910927827542407
      },
      "llm_approval_rate": {
        "mean": 0.4449625,
        "std": 0.12754063016838987
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 39.625,
        "std": 4.871793817476269
      },
      "incorrect": {
        "mean": 21.375,
        "std": 4.871793817476269
      },
      "accuracy_from_exact_match": {
        "mean": 0.3637375,
        "std": 0.06910927827542407
      },
      "accuracy_boost_from_llm": {
        "mean": 0.28585,
        "std": 0.09399476049227426
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 9450.6875,
        "std": 34.61885098829827
      },
      "total_tokens_output": {
        "mean": 774.875,
        "std": 25.8912992142148
      },
      "total_tokens": {
        "mean": 10225.5625,
        "std": 46.93608519838441
      },
      "latency_mean_ms": {
        "mean": 421.255625,
        "std": 26.467380388118794
      },
      "latency_p50_ms": {
        "mean": 415.361875,
        "std": 26.414543157782898
      },
      "latency_p95_ms": {
        "mean": 591.986875,
        "std": 25.0812409279201
      },
      "latency_p99_ms": {
        "mean": 866.095,
        "std": 312.92319886435394
      },
      "latency_total_ms": {
        "mean": 25696.659375,
        "std": 1614.4222501001273
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.36065573770491804,
          "total_tokens_input": 9449,
          "total_tokens_output": 779,
          "total_tokens": 10228,
          "latency_mean_ms": 435.11,
          "latency_p50_ms": 436.72,
          "latency_p95_ms": 607.99,
          "latency_p99_ms": 867.67,
          "latency_total_ms": 26541.75,
          "accuracy": 0.7213,
          "exact_match_rate": 0.3607,
          "llm_approval_rate": 0.5641,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.3607,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7108,
            "mean_kappa": 0.7108,
            "min_kappa": 0.4959,
            "max_kappa": 0.9184,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 9388,
          "total_tokens_output": 744,
          "total_tokens": 10132,
          "latency_mean_ms": 370.58,
          "latency_p50_ms": 362.31,
          "latency_p95_ms": 542.96,
          "latency_p99_ms": 722.08,
          "latency_total_ms": 22605.65,
          "accuracy": 0.6721,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.4444,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8832,
            "mean_kappa": 0.8832,
            "min_kappa": 0.8252,
            "max_kappa": 0.9633,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 9446,
          "total_tokens_output": 823,
          "total_tokens": 10269,
          "latency_mean_ms": 450.14,
          "latency_p50_ms": 428.94,
          "latency_p95_ms": 614.62,
          "latency_p99_ms": 1487.73,
          "latency_total_ms": 27458.52,
          "accuracy": 0.7377,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.6,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7174,
            "mean_kappa": 0.7174,
            "min_kappa": 0.6185,
            "max_kappa": 0.9153,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.2459016393442623,
          "total_tokens_input": 9488,
          "total_tokens_output": 760,
          "total_tokens": 10248,
          "latency_mean_ms": 416.9,
          "latency_p50_ms": 426.04,
          "latency_p95_ms": 588.0,
          "latency_p99_ms": 627.91,
          "latency_total_ms": 25430.84,
          "accuracy": 0.6393,
          "exact_match_rate": 0.2459,
          "llm_approval_rate": 0.5217,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.2459,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.736,
            "mean_kappa": 0.736,
            "min_kappa": 0.6766,
            "max_kappa": 0.7909,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.45901639344262296,
          "total_tokens_input": 9483,
          "total_tokens_output": 767,
          "total_tokens": 10250,
          "latency_mean_ms": 428.93,
          "latency_p50_ms": 415.68,
          "latency_p95_ms": 601.03,
          "latency_p99_ms": 624.56,
          "latency_total_ms": 26164.84,
          "accuracy": 0.6557,
          "exact_match_rate": 0.459,
          "llm_approval_rate": 0.3636,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.459,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9297,
            "mean_kappa": 0.9297,
            "min_kappa": 0.8946,
            "max_kappa": 0.9641,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.36065573770491804,
          "total_tokens_input": 9449,
          "total_tokens_output": 779,
          "total_tokens": 10228,
          "latency_mean_ms": 435.11,
          "latency_p50_ms": 436.72,
          "latency_p95_ms": 607.99,
          "latency_p99_ms": 867.67,
          "latency_total_ms": 26541.75,
          "accuracy": 0.7213,
          "exact_match_rate": 0.3607,
          "llm_approval_rate": 0.5641,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.3607,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7108,
            "mean_kappa": 0.7108,
            "min_kappa": 0.4959,
            "max_kappa": 0.9184,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 9388,
          "total_tokens_output": 744,
          "total_tokens": 10132,
          "latency_mean_ms": 370.58,
          "latency_p50_ms": 362.31,
          "latency_p95_ms": 542.96,
          "latency_p99_ms": 722.08,
          "latency_total_ms": 22605.65,
          "accuracy": 0.6557,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.4167,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8832,
            "mean_kappa": 0.8832,
            "min_kappa": 0.8252,
            "max_kappa": 0.9633,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 9446,
          "total_tokens_output": 823,
          "total_tokens": 10269,
          "latency_mean_ms": 450.14,
          "latency_p50_ms": 428.94,
          "latency_p95_ms": 614.62,
          "latency_p99_ms": 1487.73,
          "latency_total_ms": 27458.52,
          "accuracy": 0.7377,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.6,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7174,
            "mean_kappa": 0.7174,
            "min_kappa": 0.6185,
            "max_kappa": 0.9153,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.2459016393442623,
          "total_tokens_input": 9488,
          "total_tokens_output": 760,
          "total_tokens": 10248,
          "latency_mean_ms": 416.9,
          "latency_p50_ms": 426.04,
          "latency_p95_ms": 588.0,
          "latency_p99_ms": 627.91,
          "latency_total_ms": 25430.84,
          "accuracy": 0.6066,
          "exact_match_rate": 0.2459,
          "llm_approval_rate": 0.4783,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.2459,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.736,
            "mean_kappa": 0.736,
            "min_kappa": 0.6766,
            "max_kappa": 0.7909,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.45901639344262296,
          "total_tokens_input": 9483,
          "total_tokens_output": 767,
          "total_tokens": 10250,
          "latency_mean_ms": 428.93,
          "latency_p50_ms": 415.68,
          "latency_p95_ms": 601.03,
          "latency_p99_ms": 624.56,
          "latency_total_ms": 26164.84,
          "accuracy": 0.6393,
          "exact_match_rate": 0.459,
          "llm_approval_rate": 0.3333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.459,
          "accuracy_boost_from_llm": 0.1803,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9297,
            "mean_kappa": 0.9297,
            "min_kappa": 0.8946,
            "max_kappa": 0.9641,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.36065573770491804,
          "total_tokens_input": 9449,
          "total_tokens_output": 779,
          "total_tokens": 10228,
          "latency_mean_ms": 435.11,
          "latency_p50_ms": 436.72,
          "latency_p95_ms": 607.99,
          "latency_p99_ms": 867.67,
          "latency_total_ms": 26541.75,
          "accuracy": 0.5738,
          "exact_match_rate": 0.3607,
          "llm_approval_rate": 0.3333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.3607,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7108,
            "mean_kappa": 0.7108,
            "min_kappa": 0.4959,
            "max_kappa": 0.9184,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4098360655737705,
          "total_tokens_input": 9388,
          "total_tokens_output": 744,
          "total_tokens": 10132,
          "latency_mean_ms": 370.58,
          "latency_p50_ms": 362.31,
          "latency_p95_ms": 542.96,
          "latency_p99_ms": 722.08,
          "latency_total_ms": 22605.65,
          "accuracy": 0.5902,
          "exact_match_rate": 0.4098,
          "llm_approval_rate": 0.3056,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.4098,
          "accuracy_boost_from_llm": 0.1803,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8832,
            "mean_kappa": 0.8832,
            "min_kappa": 0.8252,
            "max_kappa": 0.9633,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 9446,
          "total_tokens_output": 823,
          "total_tokens": 10269,
          "latency_mean_ms": 450.14,
          "latency_p50_ms": 428.94,
          "latency_p95_ms": 614.62,
          "latency_p99_ms": 1487.73,
          "latency_total_ms": 27458.52,
          "accuracy": 0.5574,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.325,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7174,
            "mean_kappa": 0.7174,
            "min_kappa": 0.6185,
            "max_kappa": 0.9153,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.2459016393442623,
          "total_tokens_input": 9488,
          "total_tokens_output": 760,
          "total_tokens": 10248,
          "latency_mean_ms": 416.9,
          "latency_p50_ms": 426.04,
          "latency_p95_ms": 588.0,
          "latency_p99_ms": 627.91,
          "latency_total_ms": 25430.84,
          "accuracy": 0.4754,
          "exact_match_rate": 0.2459,
          "llm_approval_rate": 0.3043,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.2459,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.736,
            "mean_kappa": 0.736,
            "min_kappa": 0.6766,
            "max_kappa": 0.7909,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.45901639344262296,
          "total_tokens_input": 9483,
          "total_tokens_output": 767,
          "total_tokens": 10250,
          "latency_mean_ms": 428.93,
          "latency_p50_ms": 415.68,
          "latency_p95_ms": 601.03,
          "latency_p99_ms": 624.56,
          "latency_total_ms": 26164.84,
          "accuracy": 0.6066,
          "exact_match_rate": 0.459,
          "llm_approval_rate": 0.2727,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.459,
          "accuracy_boost_from_llm": 0.1475,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.9297,
            "mean_kappa": 0.9297,
            "min_kappa": 0.8946,
            "max_kappa": 0.9641,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.36065573770491804,
          "total_tokens_input": 9449,
          "total_tokens_output": 779,
          "total_tokens": 10228,
          "latency_mean_ms": 435.11,
          "latency_p50_ms": 436.72,
          "latency_p95_ms": 607.99,
          "latency_p99_ms": 867.67,
          "latency_total_ms": 26541.75,
          "accuracy": 0.8033,
          "exact_match_rate": 0.3607,
          "llm_approval_rate": 0.6923,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.3607,
          "accuracy_boost_from_llm": 0.4426,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7108,
            "mean_kappa": 0.7108,
            "min_kappa": 0.4959,
            "max_kappa": 0.9184,
            "n_items": 61
          }
        },
        "source": "qwen-3b_finetuned_zero_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.79013125,
        "std": 0.09160293198603142
      },
      "mean_kappa": {
        "mean": 0.79013125,
        "std": 0.09160293198603142
      },
      "min_kappa": {
        "mean": 0.68926875,
        "std": 0.14726394551429584
      },
      "max_kappa": {
        "mean": 0.9109,
        "std": 0.061344865310798406
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "qwen-7b",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 13,
    "metrics": {
      "accuracy": {
        "mean": 0.42117692307692306,
        "std": 0.11651901233998849
      },
      "exact_match": {
        "mean": 0.05926860025220681,
        "std": 0.01878898414344431
      },
      "exact_match_rate": {
        "mean": 0.05929230769230769,
        "std": 0.01879649973710169
      },
      "llm_approval_rate": {
        "mean": 0.38532307692307693,
        "std": 0.12243225538951455
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 25.692307692307693,
        "std": 7.107792207090159
      },
      "incorrect": {
        "mean": 35.30769230769231,
        "std": 7.107792207090159
      },
      "accuracy_from_exact_match": {
        "mean": 0.05929230769230769,
        "std": 0.01879649973710169
      },
      "accuracy_boost_from_llm": {
        "mean": 0.36191538461538464,
        "std": 0.11163004727949058
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 18531.076923076922,
        "std": 32.85741114962683
      },
      "total_tokens_output": {
        "mean": 880.1538461538462,
        "std": 30.096884975144864
      },
      "total_tokens": {
        "mean": 19411.23076923077,
        "std": 59.73937478253588
      },
      "latency_mean_ms": {
        "mean": 702.1069230769231,
        "std": 45.05092987764224
      },
      "latency_p50_ms": {
        "mean": 661.3538461538461,
        "std": 41.8216073226897
      },
      "latency_p95_ms": {
        "mean": 1051.126923076923,
        "std": 130.95129948452745
      },
      "latency_p99_ms": {
        "mean": 1623.27,
        "std": 215.3970364055822
      },
      "latency_total_ms": {
        "mean": 42828.551538461536,
        "std": 2748.02002184187
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18538,
          "total_tokens_output": 909,
          "total_tokens": 19447,
          "latency_mean_ms": 735.19,
          "latency_p50_ms": 684.14,
          "latency_p95_ms": 1236.91,
          "latency_p99_ms": 1672.32,
          "latency_total_ms": 44846.55,
          "accuracy": 0.4918,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.4464,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 30,
          "incorrect": 31,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5943,
            "mean_kappa": 0.5943,
            "min_kappa": 0.2877,
            "max_kappa": 0.9016,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18477,
          "total_tokens_output": 828,
          "total_tokens": 19305,
          "latency_mean_ms": 624.53,
          "latency_p50_ms": 588.95,
          "latency_p95_ms": 898.39,
          "latency_p99_ms": 1239.61,
          "latency_total_ms": 38096.5,
          "accuracy": 0.377,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.3333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 23,
          "incorrect": 38,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7322,
            "mean_kappa": 0.7322,
            "min_kappa": 0.7109,
            "max_kappa": 0.7493,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 18535,
          "total_tokens_output": 886,
          "total_tokens": 19421,
          "latency_mean_ms": 699.38,
          "latency_p50_ms": 662.85,
          "latency_p95_ms": 988.64,
          "latency_p99_ms": 1781.61,
          "latency_total_ms": 42662.24,
          "accuracy": 0.459,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.4407,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 28,
          "incorrect": 33,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.4262,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7985,
            "mean_kappa": 0.7985,
            "min_kappa": 0.7619,
            "max_kappa": 0.8327,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 18572,
          "total_tokens_output": 888,
          "total_tokens": 19460,
          "latency_mean_ms": 738.3,
          "latency_p50_ms": 701.88,
          "latency_p95_ms": 1018.64,
          "latency_p99_ms": 1783.19,
          "latency_total_ms": 45036.25,
          "accuracy": 0.4098,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.3793,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 25,
          "incorrect": 36,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8115,
            "mean_kappa": 0.8115,
            "min_kappa": 0.7522,
            "max_kappa": 0.8977,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18538,
          "total_tokens_output": 909,
          "total_tokens": 19447,
          "latency_mean_ms": 735.19,
          "latency_p50_ms": 684.14,
          "latency_p95_ms": 1236.91,
          "latency_p99_ms": 1672.32,
          "latency_total_ms": 44846.55,
          "accuracy": 0.4754,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.4286,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5943,
            "mean_kappa": 0.5943,
            "min_kappa": 0.2877,
            "max_kappa": 0.9016,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18477,
          "total_tokens_output": 828,
          "total_tokens": 19305,
          "latency_mean_ms": 624.53,
          "latency_p50_ms": 588.95,
          "latency_p95_ms": 898.39,
          "latency_p99_ms": 1239.61,
          "latency_total_ms": 38096.5,
          "accuracy": 0.3279,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.2807,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 20,
          "incorrect": 41,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7322,
            "mean_kappa": 0.7322,
            "min_kappa": 0.7109,
            "max_kappa": 0.7493,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 18535,
          "total_tokens_output": 886,
          "total_tokens": 19421,
          "latency_mean_ms": 699.38,
          "latency_p50_ms": 662.85,
          "latency_p95_ms": 988.64,
          "latency_p99_ms": 1781.61,
          "latency_total_ms": 42662.24,
          "accuracy": 0.377,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.3559,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 23,
          "incorrect": 38,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7985,
            "mean_kappa": 0.7985,
            "min_kappa": 0.7619,
            "max_kappa": 0.8327,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 18572,
          "total_tokens_output": 888,
          "total_tokens": 19460,
          "latency_mean_ms": 738.3,
          "latency_p50_ms": 701.88,
          "latency_p95_ms": 1018.64,
          "latency_p99_ms": 1783.19,
          "latency_total_ms": 45036.25,
          "accuracy": 0.3934,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.3621,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 24,
          "incorrect": 37,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8115,
            "mean_kappa": 0.8115,
            "min_kappa": 0.7522,
            "max_kappa": 0.8977,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18538,
          "total_tokens_output": 909,
          "total_tokens": 19447,
          "latency_mean_ms": 735.19,
          "latency_p50_ms": 684.14,
          "latency_p95_ms": 1236.91,
          "latency_p99_ms": 1672.32,
          "latency_total_ms": 44846.55,
          "accuracy": 0.3607,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.3036,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 22,
          "incorrect": 39,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5943,
            "mean_kappa": 0.5943,
            "min_kappa": 0.2877,
            "max_kappa": 0.9016,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18477,
          "total_tokens_output": 828,
          "total_tokens": 19305,
          "latency_mean_ms": 624.53,
          "latency_p50_ms": 588.95,
          "latency_p95_ms": 898.39,
          "latency_p99_ms": 1239.61,
          "latency_total_ms": 38096.5,
          "accuracy": 0.3115,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.2632,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 19,
          "incorrect": 42,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7322,
            "mean_kappa": 0.7322,
            "min_kappa": 0.7109,
            "max_kappa": 0.7493,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 18535,
          "total_tokens_output": 886,
          "total_tokens": 19421,
          "latency_mean_ms": 699.38,
          "latency_p50_ms": 662.85,
          "latency_p95_ms": 988.64,
          "latency_p99_ms": 1781.61,
          "latency_total_ms": 42662.24,
          "accuracy": 0.4262,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.4068,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 26,
          "incorrect": 35,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7985,
            "mean_kappa": 0.7985,
            "min_kappa": 0.7619,
            "max_kappa": 0.8327,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 18572,
          "total_tokens_output": 888,
          "total_tokens": 19460,
          "latency_mean_ms": 738.3,
          "latency_p50_ms": 701.88,
          "latency_p95_ms": 1018.64,
          "latency_p99_ms": 1783.19,
          "latency_total_ms": 45036.25,
          "accuracy": 0.2951,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.2586,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 18,
          "incorrect": 43,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8115,
            "mean_kappa": 0.8115,
            "min_kappa": 0.7522,
            "max_kappa": 0.8977,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.08196721311475409,
          "total_tokens_input": 18538,
          "total_tokens_output": 909,
          "total_tokens": 19447,
          "latency_mean_ms": 735.19,
          "latency_p50_ms": 684.14,
          "latency_p95_ms": 1236.91,
          "latency_p99_ms": 1672.32,
          "latency_total_ms": 44846.55,
          "accuracy": 0.7705,
          "exact_match_rate": 0.082,
          "llm_approval_rate": 0.75,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.082,
          "accuracy_boost_from_llm": 0.6885,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.5943,
            "mean_kappa": 0.5943,
            "min_kappa": 0.2877,
            "max_kappa": 0.9016,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_few_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.7233692307692308,
        "std": 0.09076783897238036
      },
      "mean_kappa": {
        "mean": 0.7233692307692308,
        "std": 0.09076783897238036
      },
      "min_kappa": {
        "mean": 0.6019846153846153,
        "std": 0.21032936386005438
      },
      "max_kappa": {
        "mean": 0.8496538461538461,
        "std": 0.06126480499733063
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "qwen-7b",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 16,
    "metrics": {
      "accuracy": {
        "mean": 0.26536875,
        "std": 0.12514551889075973
      },
      "exact_match": {
        "mean": 0.0030737704918032786,
        "std": 0.006398563522949179
      },
      "exact_match_rate": {
        "mean": 0.0030750000000000005,
        "std": 0.006401122948358358
      },
      "llm_approval_rate": {
        "mean": 0.26288125,
        "std": 0.12652089362408683
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 16.1875,
        "std": 7.633959899685091
      },
      "incorrect": {
        "mean": 44.8125,
        "std": 7.633959899685091
      },
      "accuracy_from_exact_match": {
        "mean": 0.0030750000000000005,
        "std": 0.006401122948358358
      },
      "accuracy_boost_from_llm": {
        "mean": 0.26229375,
        "std": 0.12685057384946077
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 9450.6875,
        "std": 34.61885098829827
      },
      "total_tokens_output": {
        "mean": 953.4375,
        "std": 14.039981971142272
      },
      "total_tokens": {
        "mean": 10404.125,
        "std": 47.139255138366366
      },
      "latency_mean_ms": {
        "mean": 744.899375,
        "std": 24.79755896977312
      },
      "latency_p50_ms": {
        "mean": 697.62,
        "std": 35.2165958746725
      },
      "latency_p95_ms": {
        "mean": 1185.5531250000001,
        "std": 107.89842391798122
      },
      "latency_p99_ms": {
        "mean": 1824.254375,
        "std": 227.93332295236993
      },
      "latency_total_ms": {
        "mean": 45438.729999999996,
        "std": 1512.7055839166135
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9449,
          "total_tokens_output": 954,
          "total_tokens": 10403,
          "latency_mean_ms": 767.99,
          "latency_p50_ms": 737.04,
          "latency_p95_ms": 1299.63,
          "latency_p99_ms": 1614.14,
          "latency_total_ms": 46847.11,
          "accuracy": 0.2459,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2459,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 15,
          "incorrect": 46,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4078,
            "mean_kappa": 0.4078,
            "min_kappa": 0.186,
            "max_kappa": 0.6863,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9388,
          "total_tokens_output": 928,
          "total_tokens": 10316,
          "latency_mean_ms": 699.77,
          "latency_p50_ms": 636.79,
          "latency_p95_ms": 990.35,
          "latency_p99_ms": 1730.56,
          "latency_total_ms": 42685.78,
          "accuracy": 0.2623,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2623,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 16,
          "incorrect": 45,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6651,
            "mean_kappa": 0.6651,
            "min_kappa": 0.6109,
            "max_kappa": 0.7101,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9446,
          "total_tokens_output": 961,
          "total_tokens": 10407,
          "latency_mean_ms": 736.85,
          "latency_p50_ms": 686.15,
          "latency_p95_ms": 1137.57,
          "latency_p99_ms": 1747.97,
          "latency_total_ms": 44947.7,
          "accuracy": 0.2951,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2951,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 18,
          "incorrect": 43,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6116,
            "mean_kappa": 0.6116,
            "min_kappa": 0.4729,
            "max_kappa": 0.7929,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9488,
          "total_tokens_output": 972,
          "total_tokens": 10460,
          "latency_mean_ms": 745.69,
          "latency_p50_ms": 691.43,
          "latency_p95_ms": 1221.48,
          "latency_p99_ms": 2275.5,
          "latency_total_ms": 45486.81,
          "accuracy": 0.2295,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.2167,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 14,
          "incorrect": 47,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7631,
            "mean_kappa": 0.7631,
            "min_kappa": 0.7332,
            "max_kappa": 0.7939,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9483,
          "total_tokens_output": 952,
          "total_tokens": 10435,
          "latency_mean_ms": 766.5,
          "latency_p50_ms": 723.55,
          "latency_p95_ms": 1240.71,
          "latency_p99_ms": 1823.14,
          "latency_total_ms": 46756.79,
          "accuracy": 0.3115,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.3115,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 19,
          "incorrect": 42,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6807,
            "mean_kappa": 0.6807,
            "min_kappa": 0.6048,
            "max_kappa": 0.7639,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9449,
          "total_tokens_output": 954,
          "total_tokens": 10403,
          "latency_mean_ms": 767.99,
          "latency_p50_ms": 737.04,
          "latency_p95_ms": 1299.63,
          "latency_p99_ms": 1614.14,
          "latency_total_ms": 46847.11,
          "accuracy": 0.2787,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2787,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 17,
          "incorrect": 44,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4078,
            "mean_kappa": 0.4078,
            "min_kappa": 0.186,
            "max_kappa": 0.6863,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9388,
          "total_tokens_output": 928,
          "total_tokens": 10316,
          "latency_mean_ms": 699.77,
          "latency_p50_ms": 636.79,
          "latency_p95_ms": 990.35,
          "latency_p99_ms": 1730.56,
          "latency_total_ms": 42685.78,
          "accuracy": 0.2951,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2951,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 18,
          "incorrect": 43,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6651,
            "mean_kappa": 0.6651,
            "min_kappa": 0.6109,
            "max_kappa": 0.7101,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9446,
          "total_tokens_output": 961,
          "total_tokens": 10407,
          "latency_mean_ms": 736.85,
          "latency_p50_ms": 686.15,
          "latency_p95_ms": 1137.57,
          "latency_p99_ms": 1747.97,
          "latency_total_ms": 44947.7,
          "accuracy": 0.2459,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2459,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 15,
          "incorrect": 46,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6116,
            "mean_kappa": 0.6116,
            "min_kappa": 0.4729,
            "max_kappa": 0.7929,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9488,
          "total_tokens_output": 972,
          "total_tokens": 10460,
          "latency_mean_ms": 745.69,
          "latency_p50_ms": 691.43,
          "latency_p95_ms": 1221.48,
          "latency_p99_ms": 2275.5,
          "latency_total_ms": 45486.81,
          "accuracy": 0.2131,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.2,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 13,
          "incorrect": 48,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7631,
            "mean_kappa": 0.7631,
            "min_kappa": 0.7332,
            "max_kappa": 0.7939,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9483,
          "total_tokens_output": 952,
          "total_tokens": 10435,
          "latency_mean_ms": 766.5,
          "latency_p50_ms": 723.55,
          "latency_p95_ms": 1240.71,
          "latency_p99_ms": 1823.14,
          "latency_total_ms": 46756.79,
          "accuracy": 0.2787,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2787,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 17,
          "incorrect": 44,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6807,
            "mean_kappa": 0.6807,
            "min_kappa": 0.6048,
            "max_kappa": 0.7639,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9449,
          "total_tokens_output": 954,
          "total_tokens": 10403,
          "latency_mean_ms": 767.99,
          "latency_p50_ms": 737.04,
          "latency_p95_ms": 1299.63,
          "latency_p99_ms": 1614.14,
          "latency_total_ms": 46847.11,
          "accuracy": 0.1967,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.1967,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 12,
          "incorrect": 49,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4078,
            "mean_kappa": 0.4078,
            "min_kappa": 0.186,
            "max_kappa": 0.6863,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9388,
          "total_tokens_output": 928,
          "total_tokens": 10316,
          "latency_mean_ms": 699.77,
          "latency_p50_ms": 636.79,
          "latency_p95_ms": 990.35,
          "latency_p99_ms": 1730.56,
          "latency_total_ms": 42685.78,
          "accuracy": 0.2459,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.2459,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 15,
          "incorrect": 46,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6651,
            "mean_kappa": 0.6651,
            "min_kappa": 0.6109,
            "max_kappa": 0.7101,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9446,
          "total_tokens_output": 961,
          "total_tokens": 10407,
          "latency_mean_ms": 736.85,
          "latency_p50_ms": 686.15,
          "latency_p95_ms": 1137.57,
          "latency_p99_ms": 1747.97,
          "latency_total_ms": 44947.7,
          "accuracy": 0.1148,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.1148,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 7,
          "incorrect": 54,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.1148,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6116,
            "mean_kappa": 0.6116,
            "min_kappa": 0.4729,
            "max_kappa": 0.7929,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9488,
          "total_tokens_output": 972,
          "total_tokens": 10460,
          "latency_mean_ms": 745.69,
          "latency_p50_ms": 691.43,
          "latency_p95_ms": 1221.48,
          "latency_p99_ms": 2275.5,
          "latency_total_ms": 45486.81,
          "accuracy": 0.1639,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.15,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 10,
          "incorrect": 51,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.1475,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7631,
            "mean_kappa": 0.7631,
            "min_kappa": 0.7332,
            "max_kappa": 0.7939,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9483,
          "total_tokens_output": 952,
          "total_tokens": 10435,
          "latency_mean_ms": 766.5,
          "latency_p50_ms": 723.55,
          "latency_p95_ms": 1240.71,
          "latency_p99_ms": 1823.14,
          "latency_total_ms": 46756.79,
          "accuracy": 0.1639,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.1639,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 10,
          "incorrect": 51,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.1639,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6807,
            "mean_kappa": 0.6807,
            "min_kappa": 0.6048,
            "max_kappa": 0.7639,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9449,
          "total_tokens_output": 954,
          "total_tokens": 10403,
          "latency_mean_ms": 767.99,
          "latency_p50_ms": 737.04,
          "latency_p95_ms": 1299.63,
          "latency_p99_ms": 1614.14,
          "latency_total_ms": 46847.11,
          "accuracy": 0.7049,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.7049,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.7049,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.4078,
            "mean_kappa": 0.4078,
            "min_kappa": 0.186,
            "max_kappa": 0.6863,
            "n_items": 61
          }
        },
        "source": "qwen-7b_baseline_zero_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.61204375,
        "std": 0.12696026429925822
      },
      "mean_kappa": {
        "mean": 0.61204375,
        "std": 0.12696026429925822
      },
      "min_kappa": {
        "mean": 0.5005875,
        "std": 0.19836424474624956
      },
      "max_kappa": {
        "mean": 0.745475,
        "std": 0.04511213112899901
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "qwen-7b",
    "condition": "finetuned_few_shot",
    "finetuned": true,
    "few_shot": true,
    "num_seeds": 17,
    "metrics": {
      "accuracy": {
        "mean": 0.7232470588235295,
        "std": 0.06744373792626805
      },
      "exact_match": {
        "mean": 0.46962391513982643,
        "std": 0.08300998733522601
      },
      "exact_match_rate": {
        "mean": 0.46962941176470585,
        "std": 0.08301654523049558
      },
      "llm_approval_rate": {
        "mean": 0.4732529411764706,
        "std": 0.1201060811393145
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 44.11764705882353,
        "std": 4.1142843411872265
      },
      "incorrect": {
        "mean": 16.88235294117647,
        "std": 4.1142843411872265
      },
      "accuracy_from_exact_match": {
        "mean": 0.46962941176470585,
        "std": 0.08301654523049558
      },
      "accuracy_boost_from_llm": {
        "mean": 0.25361176470588237,
        "std": 0.08208792189119679
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 18525.882352941175,
        "std": 66.07382889656012
      },
      "total_tokens_output": {
        "mean": 786.8823529411765,
        "std": 24.647830958002288
      },
      "total_tokens": {
        "mean": 19312.764705882353,
        "std": 86.62599080955452
      },
      "latency_mean_ms": {
        "mean": 1075.5535294117647,
        "std": 51.446217484141684
      },
      "latency_p50_ms": {
        "mean": 1045.635882352941,
        "std": 48.65641872399756
      },
      "latency_p95_ms": {
        "mean": 1497.154705882353,
        "std": 88.56482232989158
      },
      "latency_p99_ms": {
        "mean": 2247.784117647059,
        "std": 441.6960013677071
      },
      "latency_total_ms": {
        "mean": 65608.63764705883,
        "std": 3138.2037475591756
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.47540983606557374,
          "total_tokens_input": 18538,
          "total_tokens_output": 804,
          "total_tokens": 19342,
          "latency_mean_ms": 1063.33,
          "latency_p50_ms": 1047.6,
          "latency_p95_ms": 1442.45,
          "latency_p99_ms": 2218.73,
          "latency_total_ms": 64863.12,
          "accuracy": 0.7869,
          "exact_match_rate": 0.4754,
          "llm_approval_rate": 0.5938,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 48,
          "incorrect": 13,
          "accuracy_from_exact_match": 0.4754,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8992,
            "mean_kappa": 0.8992,
            "min_kappa": 0.8157,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 18388,
          "total_tokens_output": 745,
          "total_tokens": 19133,
          "latency_mean_ms": 977.39,
          "latency_p50_ms": 953.76,
          "latency_p95_ms": 1422.31,
          "latency_p99_ms": 1575.03,
          "latency_total_ms": 59620.66,
          "accuracy": 0.7705,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.5172,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.808,
            "mean_kappa": 0.808,
            "min_kappa": 0.7583,
            "max_kappa": 0.8643,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 18535,
          "total_tokens_output": 785,
          "total_tokens": 19320,
          "latency_mean_ms": 1090.98,
          "latency_p50_ms": 1090.57,
          "latency_p95_ms": 1509.9,
          "latency_p99_ms": 1898.66,
          "latency_total_ms": 66549.68,
          "accuracy": 0.7377,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.6,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7985,
            "mean_kappa": 0.7985,
            "min_kappa": 0.7401,
            "max_kappa": 0.9153,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.39344262295081966,
          "total_tokens_input": 18577,
          "total_tokens_output": 821,
          "total_tokens": 19398,
          "latency_mean_ms": 1138.3,
          "latency_p50_ms": 1099.34,
          "latency_p95_ms": 1678.96,
          "latency_p99_ms": 2537.02,
          "latency_total_ms": 69436.22,
          "accuracy": 0.7049,
          "exact_match_rate": 0.3934,
          "llm_approval_rate": 0.5135,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.3934,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8121,
            "mean_kappa": 0.8121,
            "min_kappa": 0.7208,
            "max_kappa": 0.8979,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5737704918032787,
          "total_tokens_input": 18572,
          "total_tokens_output": 777,
          "total_tokens": 19349,
          "latency_mean_ms": 1102.77,
          "latency_p50_ms": 1038.6,
          "latency_p95_ms": 1462.08,
          "latency_p99_ms": 2826.32,
          "latency_total_ms": 67268.67,
          "accuracy": 0.7705,
          "exact_match_rate": 0.5738,
          "llm_approval_rate": 0.4615,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.5738,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.81,
            "mean_kappa": 0.81,
            "min_kappa": 0.6685,
            "max_kappa": 0.9024,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.47540983606557374,
          "total_tokens_input": 18538,
          "total_tokens_output": 804,
          "total_tokens": 19342,
          "latency_mean_ms": 1063.33,
          "latency_p50_ms": 1047.6,
          "latency_p95_ms": 1442.45,
          "latency_p99_ms": 2218.73,
          "latency_total_ms": 64863.12,
          "accuracy": 0.8033,
          "exact_match_rate": 0.4754,
          "llm_approval_rate": 0.625,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.4754,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8992,
            "mean_kappa": 0.8992,
            "min_kappa": 0.8157,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 18388,
          "total_tokens_output": 745,
          "total_tokens": 19133,
          "latency_mean_ms": 977.39,
          "latency_p50_ms": 953.76,
          "latency_p95_ms": 1422.31,
          "latency_p99_ms": 1575.03,
          "latency_total_ms": 59620.66,
          "accuracy": 0.7541,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.4828,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.808,
            "mean_kappa": 0.808,
            "min_kappa": 0.7583,
            "max_kappa": 0.8643,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 18535,
          "total_tokens_output": 785,
          "total_tokens": 19320,
          "latency_mean_ms": 1090.98,
          "latency_p50_ms": 1090.57,
          "latency_p95_ms": 1509.9,
          "latency_p99_ms": 1898.66,
          "latency_total_ms": 66549.68,
          "accuracy": 0.7377,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.6,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7985,
            "mean_kappa": 0.7985,
            "min_kappa": 0.7401,
            "max_kappa": 0.9153,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.39344262295081966,
          "total_tokens_input": 18577,
          "total_tokens_output": 821,
          "total_tokens": 19398,
          "latency_mean_ms": 1138.3,
          "latency_p50_ms": 1099.34,
          "latency_p95_ms": 1678.96,
          "latency_p99_ms": 2537.02,
          "latency_total_ms": 69436.22,
          "accuracy": 0.623,
          "exact_match_rate": 0.3934,
          "llm_approval_rate": 0.3784,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.3934,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8121,
            "mean_kappa": 0.8121,
            "min_kappa": 0.7208,
            "max_kappa": 0.8979,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5737704918032787,
          "total_tokens_input": 18572,
          "total_tokens_output": 777,
          "total_tokens": 19349,
          "latency_mean_ms": 1102.77,
          "latency_p50_ms": 1038.6,
          "latency_p95_ms": 1462.08,
          "latency_p99_ms": 2826.32,
          "latency_total_ms": 67268.67,
          "accuracy": 0.7213,
          "exact_match_rate": 0.5738,
          "llm_approval_rate": 0.3462,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.5738,
          "accuracy_boost_from_llm": 0.1475,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.81,
            "mean_kappa": 0.81,
            "min_kappa": 0.6685,
            "max_kappa": 0.9024,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.47540983606557374,
          "total_tokens_input": 18538,
          "total_tokens_output": 804,
          "total_tokens": 19342,
          "latency_mean_ms": 1063.33,
          "latency_p50_ms": 1047.6,
          "latency_p95_ms": 1442.45,
          "latency_p99_ms": 2218.73,
          "latency_total_ms": 64863.12,
          "accuracy": 0.7377,
          "exact_match_rate": 0.4754,
          "llm_approval_rate": 0.5,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.4754,
          "accuracy_boost_from_llm": 0.2623,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8992,
            "mean_kappa": 0.8992,
            "min_kappa": 0.8157,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 18388,
          "total_tokens_output": 745,
          "total_tokens": 19133,
          "latency_mean_ms": 977.39,
          "latency_p50_ms": 953.76,
          "latency_p95_ms": 1422.31,
          "latency_p99_ms": 1575.03,
          "latency_total_ms": 59620.66,
          "accuracy": 0.6721,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.3103,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.1475,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.808,
            "mean_kappa": 0.808,
            "min_kappa": 0.7583,
            "max_kappa": 0.8643,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 18535,
          "total_tokens_output": 785,
          "total_tokens": 19320,
          "latency_mean_ms": 1090.98,
          "latency_p50_ms": 1090.57,
          "latency_p95_ms": 1509.9,
          "latency_p99_ms": 1898.66,
          "latency_total_ms": 66549.68,
          "accuracy": 0.623,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.425,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7985,
            "mean_kappa": 0.7985,
            "min_kappa": 0.7401,
            "max_kappa": 0.9153,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.39344262295081966,
          "total_tokens_input": 18577,
          "total_tokens_output": 821,
          "total_tokens": 19398,
          "latency_mean_ms": 1138.3,
          "latency_p50_ms": 1099.34,
          "latency_p95_ms": 1678.96,
          "latency_p99_ms": 2537.02,
          "latency_total_ms": 69436.22,
          "accuracy": 0.5738,
          "exact_match_rate": 0.3934,
          "llm_approval_rate": 0.2973,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.3934,
          "accuracy_boost_from_llm": 0.1803,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8121,
            "mean_kappa": 0.8121,
            "min_kappa": 0.7208,
            "max_kappa": 0.8979,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5737704918032787,
          "total_tokens_input": 18572,
          "total_tokens_output": 777,
          "total_tokens": 19349,
          "latency_mean_ms": 1102.77,
          "latency_p50_ms": 1038.6,
          "latency_p95_ms": 1462.08,
          "latency_p99_ms": 2826.32,
          "latency_total_ms": 67268.67,
          "accuracy": 0.6721,
          "exact_match_rate": 0.5738,
          "llm_approval_rate": 0.2308,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.5738,
          "accuracy_boost_from_llm": 0.0984,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.81,
            "mean_kappa": 0.81,
            "min_kappa": 0.6685,
            "max_kappa": 0.9024,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.47540983606557374,
          "total_tokens_input": 18538,
          "total_tokens_output": 804,
          "total_tokens": 19342,
          "latency_mean_ms": 1063.33,
          "latency_p50_ms": 1047.6,
          "latency_p95_ms": 1442.45,
          "latency_p99_ms": 2218.73,
          "latency_total_ms": 64863.12,
          "accuracy": 0.8033,
          "exact_match_rate": 0.4754,
          "llm_approval_rate": 0.625,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.4754,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8992,
            "mean_kappa": 0.8992,
            "min_kappa": 0.8157,
            "max_kappa": 1.0,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5737704918032787,
          "total_tokens_input": 18572,
          "total_tokens_output": 777,
          "total_tokens": 19349,
          "latency_mean_ms": 1102.77,
          "latency_p50_ms": 1038.6,
          "latency_p95_ms": 1462.08,
          "latency_p99_ms": 2826.32,
          "latency_total_ms": 67268.67,
          "accuracy": 0.8033,
          "exact_match_rate": 0.5738,
          "llm_approval_rate": 0.5385,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 49,
          "incorrect": 12,
          "accuracy_from_exact_match": 0.5738,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.81,
            "mean_kappa": 0.81,
            "min_kappa": 0.6685,
            "max_kappa": 0.9024,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_few_shot_seed46__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.8289764705882353,
        "std": 0.03920288899035772
      },
      "mean_kappa": {
        "mean": 0.8289764705882353,
        "std": 0.03920288899035772
      },
      "min_kappa": {
        "mean": 0.7408470588235294,
        "std": 0.05171720748622271
      },
      "max_kappa": {
        "mean": 0.9201235294117647,
        "std": 0.04707800197434248
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "qwen-7b",
    "condition": "finetuned_zero_shot",
    "finetuned": true,
    "few_shot": false,
    "num_seeds": 17,
    "metrics": {
      "accuracy": {
        "mean": 0.6779176470588235,
        "std": 0.08146720910384467
      },
      "exact_match": {
        "mean": 0.44358727097396333,
        "std": 0.07276624678848018
      },
      "exact_match_rate": {
        "mean": 0.4435823529411765,
        "std": 0.07277127128115483
      },
      "llm_approval_rate": {
        "mean": 0.42514117647058824,
        "std": 0.10442495790714994
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 41.35294117647059,
        "std": 4.969805020090453
      },
      "incorrect": {
        "mean": 19.647058823529413,
        "std": 4.969805020090453
      },
      "accuracy_from_exact_match": {
        "mean": 0.4435823529411765,
        "std": 0.07277127128115483
      },
      "accuracy_boost_from_llm": {
        "mean": 0.2343235294117647,
        "std": 0.058664906128559215
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 9447,
        "std": 36.681458691888274
      },
      "total_tokens_output": {
        "mean": 791.3529411764706,
        "std": 17.074029733764696
      },
      "total_tokens": {
        "mean": 10238.35294117647,
        "std": 50.68233382489125
      },
      "latency_mean_ms": {
        "mean": 1095.8582352941175,
        "std": 45.80075368443495
      },
      "latency_p50_ms": {
        "mean": 1063.2564705882353,
        "std": 62.904325011801134
      },
      "latency_p95_ms": {
        "mean": 1530.949411764706,
        "std": 46.02984677110737
      },
      "latency_p99_ms": {
        "mean": 2272.5364705882353,
        "std": 397.06958921788623
      },
      "latency_total_ms": {
        "mean": 66847.38058823529,
        "std": 2793.8544570148943
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 9449,
          "total_tokens_output": 796,
          "total_tokens": 10245,
          "latency_mean_ms": 1127.84,
          "latency_p50_ms": 1116.75,
          "latency_p95_ms": 1546.69,
          "latency_p99_ms": 1847.58,
          "latency_total_ms": 68798.36,
          "accuracy": 0.7541,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.4828,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8536,
            "mean_kappa": 0.8536,
            "min_kappa": 0.7256,
            "max_kappa": 0.9548,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 9388,
          "total_tokens_output": 768,
          "total_tokens": 10156,
          "latency_mean_ms": 1022.6,
          "latency_p50_ms": 978.72,
          "latency_p95_ms": 1469.99,
          "latency_p99_ms": 1937.45,
          "latency_total_ms": 62378.66,
          "accuracy": 0.7049,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.4857,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.2787,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7306,
            "mean_kappa": 0.7306,
            "min_kappa": 0.6101,
            "max_kappa": 0.8979,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 9446,
          "total_tokens_output": 798,
          "total_tokens": 10244,
          "latency_mean_ms": 1126.51,
          "latency_p50_ms": 1119.56,
          "latency_p95_ms": 1551.92,
          "latency_p99_ms": 2374.71,
          "latency_total_ms": 68717.34,
          "accuracy": 0.6557,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.475,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7479,
            "mean_kappa": 0.7479,
            "min_kappa": 0.6952,
            "max_kappa": 0.8205,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 9488,
          "total_tokens_output": 819,
          "total_tokens": 10307,
          "latency_mean_ms": 1140.69,
          "latency_p50_ms": 1109.64,
          "latency_p95_ms": 1603.09,
          "latency_p99_ms": 2531.5,
          "latency_total_ms": 69581.93,
          "accuracy": 0.6885,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.5,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.3115,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7538,
            "mean_kappa": 0.7538,
            "min_kappa": 0.6371,
            "max_kappa": 0.8217,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 9483,
          "total_tokens_output": 782,
          "total_tokens": 10265,
          "latency_mean_ms": 1075.41,
          "latency_p50_ms": 1001.96,
          "latency_p95_ms": 1498.13,
          "latency_p99_ms": 2924.79,
          "latency_total_ms": 65599.86,
          "accuracy": 0.7377,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.4483,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 45,
          "incorrect": 16,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8923,
            "mean_kappa": 0.8923,
            "min_kappa": 0.8754,
            "max_kappa": 0.9213,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 9449,
          "total_tokens_output": 796,
          "total_tokens": 10245,
          "latency_mean_ms": 1127.84,
          "latency_p50_ms": 1116.75,
          "latency_p95_ms": 1546.69,
          "latency_p99_ms": 1847.58,
          "latency_total_ms": 68798.36,
          "accuracy": 0.7705,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.5172,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8536,
            "mean_kappa": 0.8536,
            "min_kappa": 0.7256,
            "max_kappa": 0.9548,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 9388,
          "total_tokens_output": 768,
          "total_tokens": 10156,
          "latency_mean_ms": 1022.6,
          "latency_p50_ms": 978.72,
          "latency_p95_ms": 1469.99,
          "latency_p99_ms": 1937.45,
          "latency_total_ms": 62378.66,
          "accuracy": 0.623,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.3429,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 38,
          "incorrect": 23,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7306,
            "mean_kappa": 0.7306,
            "min_kappa": 0.6101,
            "max_kappa": 0.8979,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 9446,
          "total_tokens_output": 798,
          "total_tokens": 10244,
          "latency_mean_ms": 1126.51,
          "latency_p50_ms": 1119.56,
          "latency_p95_ms": 1551.92,
          "latency_p99_ms": 2374.71,
          "latency_total_ms": 68717.34,
          "accuracy": 0.6393,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.45,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 39,
          "incorrect": 22,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7479,
            "mean_kappa": 0.7479,
            "min_kappa": 0.6952,
            "max_kappa": 0.8205,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 9488,
          "total_tokens_output": 819,
          "total_tokens": 10307,
          "latency_mean_ms": 1140.69,
          "latency_p50_ms": 1109.64,
          "latency_p95_ms": 1603.09,
          "latency_p99_ms": 2531.5,
          "latency_total_ms": 69581.93,
          "accuracy": 0.6066,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.3684,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 37,
          "incorrect": 24,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.2295,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7538,
            "mean_kappa": 0.7538,
            "min_kappa": 0.6371,
            "max_kappa": 0.8217,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 9483,
          "total_tokens_output": 782,
          "total_tokens": 10265,
          "latency_mean_ms": 1075.41,
          "latency_p50_ms": 1001.96,
          "latency_p95_ms": 1498.13,
          "latency_p99_ms": 2924.79,
          "latency_total_ms": 65599.86,
          "accuracy": 0.7213,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.4138,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8923,
            "mean_kappa": 0.8923,
            "min_kappa": 0.8754,
            "max_kappa": 0.9213,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 9449,
          "total_tokens_output": 796,
          "total_tokens": 10245,
          "latency_mean_ms": 1127.84,
          "latency_p50_ms": 1116.75,
          "latency_p95_ms": 1546.69,
          "latency_p99_ms": 1847.58,
          "latency_total_ms": 68798.36,
          "accuracy": 0.7213,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.4138,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.1967,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8536,
            "mean_kappa": 0.8536,
            "min_kappa": 0.7256,
            "max_kappa": 0.9548,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 9388,
          "total_tokens_output": 768,
          "total_tokens": 10156,
          "latency_mean_ms": 1022.6,
          "latency_p50_ms": 978.72,
          "latency_p95_ms": 1469.99,
          "latency_p99_ms": 1937.45,
          "latency_total_ms": 62378.66,
          "accuracy": 0.5738,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.2571,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 35,
          "incorrect": 26,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.1475,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7306,
            "mean_kappa": 0.7306,
            "min_kappa": 0.6101,
            "max_kappa": 0.8979,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3442622950819672,
          "total_tokens_input": 9446,
          "total_tokens_output": 798,
          "total_tokens": 10244,
          "latency_mean_ms": 1126.51,
          "latency_p50_ms": 1119.56,
          "latency_p95_ms": 1551.92,
          "latency_p99_ms": 2374.71,
          "latency_total_ms": 68717.34,
          "accuracy": 0.5574,
          "exact_match_rate": 0.3443,
          "llm_approval_rate": 0.325,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.3443,
          "accuracy_boost_from_llm": 0.2131,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7479,
            "mean_kappa": 0.7479,
            "min_kappa": 0.6952,
            "max_kappa": 0.8205,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.3770491803278688,
          "total_tokens_input": 9488,
          "total_tokens_output": 819,
          "total_tokens": 10307,
          "latency_mean_ms": 1140.69,
          "latency_p50_ms": 1109.64,
          "latency_p95_ms": 1603.09,
          "latency_p99_ms": 2531.5,
          "latency_total_ms": 69581.93,
          "accuracy": 0.5082,
          "exact_match_rate": 0.377,
          "llm_approval_rate": 0.2105,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 31,
          "incorrect": 30,
          "accuracy_from_exact_match": 0.377,
          "accuracy_boost_from_llm": 0.1311,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7538,
            "mean_kappa": 0.7538,
            "min_kappa": 0.6371,
            "max_kappa": 0.8217,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 9483,
          "total_tokens_output": 782,
          "total_tokens": 10265,
          "latency_mean_ms": 1075.41,
          "latency_p50_ms": 1001.96,
          "latency_p95_ms": 1498.13,
          "latency_p99_ms": 2924.79,
          "latency_total_ms": 65599.86,
          "accuracy": 0.6885,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.3448,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.1639,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8923,
            "mean_kappa": 0.8923,
            "min_kappa": 0.8754,
            "max_kappa": 0.9213,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.5245901639344263,
          "total_tokens_input": 9449,
          "total_tokens_output": 796,
          "total_tokens": 10245,
          "latency_mean_ms": 1127.84,
          "latency_p50_ms": 1116.75,
          "latency_p95_ms": 1546.69,
          "latency_p99_ms": 1847.58,
          "latency_total_ms": 68798.36,
          "accuracy": 0.8197,
          "exact_match_rate": 0.5246,
          "llm_approval_rate": 0.6207,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 50,
          "incorrect": 11,
          "accuracy_from_exact_match": 0.5246,
          "accuracy_boost_from_llm": 0.2951,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8536,
            "mean_kappa": 0.8536,
            "min_kappa": 0.7256,
            "max_kappa": 0.9548,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed42__judge-llama-70b.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.4262295081967213,
          "total_tokens_input": 9388,
          "total_tokens_output": 768,
          "total_tokens": 10156,
          "latency_mean_ms": 1022.6,
          "latency_p50_ms": 978.72,
          "latency_p95_ms": 1469.99,
          "latency_p99_ms": 1937.45,
          "latency_total_ms": 62378.66,
          "accuracy": 0.7541,
          "exact_match_rate": 0.4262,
          "llm_approval_rate": 0.5714,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.4262,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7306,
            "mean_kappa": 0.7306,
            "min_kappa": 0.6101,
            "max_kappa": 0.8979,
            "n_items": 61
          }
        },
        "source": "qwen-7b_finetuned_zero_shot_seed43__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.7952235294117648,
        "std": 0.0643857175376447
      },
      "mean_kappa": {
        "mean": 0.7952235294117648,
        "std": 0.0643857175376447
      },
      "min_kappa": {
        "mean": 0.7038764705882353,
        "std": 0.09040036783769362
      },
      "max_kappa": {
        "mean": 0.8883117647058824,
        "std": 0.053369873440017264
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "qwen-coder-32b",
    "condition": "baseline_few_shot",
    "finetuned": false,
    "few_shot": true,
    "num_seeds": 13,
    "metrics": {
      "accuracy": {
        "mean": 0.7023846153846154,
        "std": 0.08229781608611725
      },
      "exact_match": {
        "mean": 0.10214375788146281,
        "std": 0.02332060782964304
      },
      "exact_match_rate": {
        "mean": 0.10216153846153846,
        "std": 0.023301255775388136
      },
      "llm_approval_rate": {
        "mean": 0.6690538461538461,
        "std": 0.08940538286483148
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 42.84615384615385,
        "std": 5.020667345255606
      },
      "incorrect": {
        "mean": 18.153846153846153,
        "std": 5.020667345255606
      },
      "accuracy_from_exact_match": {
        "mean": 0.10216153846153846,
        "std": 0.023301255775388136
      },
      "accuracy_boost_from_llm": {
        "mean": 0.6002615384615385,
        "std": 0.07810079816849642
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 18531.076923076922,
        "std": 32.85741114962683
      },
      "total_tokens_output": {
        "mean": 889.5384615384615,
        "std": 32.4431227383825
      },
      "total_tokens": {
        "mean": 19420.615384615383,
        "std": 63.928491856181914
      },
      "latency_mean_ms": {
        "mean": 1644.6299999999999,
        "std": 50.08677808026322
      },
      "latency_p50_ms": {
        "mean": 1549.9553846153847,
        "std": 49.194303862788615
      },
      "latency_p95_ms": {
        "mean": 2273.757692307692,
        "std": 100.57763990331405
      },
      "latency_p99_ms": {
        "mean": 4673.6884615384615,
        "std": 1270.750574502185
      },
      "latency_total_ms": {
        "mean": 100322.38,
        "std": 3055.279291367902
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.09836065573770492,
          "total_tokens_input": 18538,
          "total_tokens_output": 893,
          "total_tokens": 19431,
          "latency_mean_ms": 1676.07,
          "latency_p50_ms": 1605.97,
          "latency_p95_ms": 2324.34,
          "latency_p99_ms": 3931.29,
          "latency_total_ms": 102240.46,
          "accuracy": 0.7049,
          "exact_match_rate": 0.0984,
          "llm_approval_rate": 0.6727,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.0984,
          "accuracy_boost_from_llm": 0.6066,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6348,
            "mean_kappa": 0.6348,
            "min_kappa": 0.396,
            "max_kappa": 0.8121,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.11475409836065574,
          "total_tokens_input": 18477,
          "total_tokens_output": 833,
          "total_tokens": 19310,
          "latency_mean_ms": 1553.48,
          "latency_p50_ms": 1470.73,
          "latency_p95_ms": 2412.33,
          "latency_p99_ms": 3017.44,
          "latency_total_ms": 94762.28,
          "accuracy": 0.6557,
          "exact_match_rate": 0.1148,
          "llm_approval_rate": 0.6111,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.1148,
          "accuracy_boost_from_llm": 0.541,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6701,
            "mean_kappa": 0.6701,
            "min_kappa": 0.6546,
            "max_kappa": 0.6958,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18535,
          "total_tokens_output": 916,
          "total_tokens": 19451,
          "latency_mean_ms": 1665.19,
          "latency_p50_ms": 1555.1,
          "latency_p95_ms": 2170.24,
          "latency_p99_ms": 5900.55,
          "latency_total_ms": 101576.29,
          "accuracy": 0.6721,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.6491,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.6066,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7377,
            "mean_kappa": 0.7377,
            "min_kappa": 0.7024,
            "max_kappa": 0.7553,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed44__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 18572,
          "total_tokens_output": 915,
          "total_tokens": 19487,
          "latency_mean_ms": 1673.3,
          "latency_p50_ms": 1549.35,
          "latency_p95_ms": 2171.26,
          "latency_p99_ms": 6092.94,
          "latency_total_ms": 102071.13,
          "accuracy": 0.7869,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.7547,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 48,
          "incorrect": 13,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8249,
            "mean_kappa": 0.8249,
            "min_kappa": 0.7857,
            "max_kappa": 0.8574,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.09836065573770492,
          "total_tokens_input": 18538,
          "total_tokens_output": 893,
          "total_tokens": 19431,
          "latency_mean_ms": 1676.07,
          "latency_p50_ms": 1605.97,
          "latency_p95_ms": 2324.34,
          "latency_p99_ms": 3931.29,
          "latency_total_ms": 102240.46,
          "accuracy": 0.7541,
          "exact_match_rate": 0.0984,
          "llm_approval_rate": 0.7273,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 46,
          "incorrect": 15,
          "accuracy_from_exact_match": 0.0984,
          "accuracy_boost_from_llm": 0.6557,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6348,
            "mean_kappa": 0.6348,
            "min_kappa": 0.396,
            "max_kappa": 0.8121,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.11475409836065574,
          "total_tokens_input": 18477,
          "total_tokens_output": 833,
          "total_tokens": 19310,
          "latency_mean_ms": 1553.48,
          "latency_p50_ms": 1470.73,
          "latency_p95_ms": 2412.33,
          "latency_p99_ms": 3017.44,
          "latency_total_ms": 94762.28,
          "accuracy": 0.7213,
          "exact_match_rate": 0.1148,
          "llm_approval_rate": 0.6852,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 44,
          "incorrect": 17,
          "accuracy_from_exact_match": 0.1148,
          "accuracy_boost_from_llm": 0.6066,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6701,
            "mean_kappa": 0.6701,
            "min_kappa": 0.6546,
            "max_kappa": 0.6958,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18535,
          "total_tokens_output": 916,
          "total_tokens": 19451,
          "latency_mean_ms": 1665.19,
          "latency_p50_ms": 1555.1,
          "latency_p95_ms": 2170.24,
          "latency_p99_ms": 5900.55,
          "latency_total_ms": 101576.29,
          "accuracy": 0.6721,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.6491,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 41,
          "incorrect": 20,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.6066,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7377,
            "mean_kappa": 0.7377,
            "min_kappa": 0.7024,
            "max_kappa": 0.7553,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed44__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 18572,
          "total_tokens_output": 915,
          "total_tokens": 19487,
          "latency_mean_ms": 1673.3,
          "latency_p50_ms": 1549.35,
          "latency_p95_ms": 2171.26,
          "latency_p99_ms": 6092.94,
          "latency_total_ms": 102071.13,
          "accuracy": 0.7705,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.7358,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 47,
          "incorrect": 14,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8249,
            "mean_kappa": 0.8249,
            "min_kappa": 0.7857,
            "max_kappa": 0.8574,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.09836065573770492,
          "total_tokens_input": 18538,
          "total_tokens_output": 893,
          "total_tokens": 19431,
          "latency_mean_ms": 1676.07,
          "latency_p50_ms": 1605.97,
          "latency_p95_ms": 2324.34,
          "latency_p99_ms": 3931.29,
          "latency_total_ms": 102240.46,
          "accuracy": 0.6557,
          "exact_match_rate": 0.0984,
          "llm_approval_rate": 0.6182,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 40,
          "incorrect": 21,
          "accuracy_from_exact_match": 0.0984,
          "accuracy_boost_from_llm": 0.5574,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6348,
            "mean_kappa": 0.6348,
            "min_kappa": 0.396,
            "max_kappa": 0.8121,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.11475409836065574,
          "total_tokens_input": 18477,
          "total_tokens_output": 833,
          "total_tokens": 19310,
          "latency_mean_ms": 1553.48,
          "latency_p50_ms": 1470.73,
          "latency_p95_ms": 2412.33,
          "latency_p99_ms": 3017.44,
          "latency_total_ms": 94762.28,
          "accuracy": 0.5574,
          "exact_match_rate": 0.1148,
          "llm_approval_rate": 0.5,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 34,
          "incorrect": 27,
          "accuracy_from_exact_match": 0.1148,
          "accuracy_boost_from_llm": 0.4426,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6701,
            "mean_kappa": 0.6701,
            "min_kappa": 0.6546,
            "max_kappa": 0.6958,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 44,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.06557377049180328,
          "total_tokens_input": 18535,
          "total_tokens_output": 916,
          "total_tokens": 19451,
          "latency_mean_ms": 1665.19,
          "latency_p50_ms": 1555.1,
          "latency_p95_ms": 2170.24,
          "latency_p99_ms": 5900.55,
          "latency_total_ms": 101576.29,
          "accuracy": 0.5902,
          "exact_match_rate": 0.0656,
          "llm_approval_rate": 0.5614,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 36,
          "incorrect": 25,
          "accuracy_from_exact_match": 0.0656,
          "accuracy_boost_from_llm": 0.5246,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7377,
            "mean_kappa": 0.7377,
            "min_kappa": 0.7024,
            "max_kappa": 0.7553,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed44__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.13114754098360656,
          "total_tokens_input": 18572,
          "total_tokens_output": 915,
          "total_tokens": 19487,
          "latency_mean_ms": 1673.3,
          "latency_p50_ms": 1549.35,
          "latency_p95_ms": 2171.26,
          "latency_p99_ms": 6092.94,
          "latency_total_ms": 102071.13,
          "accuracy": 0.7049,
          "exact_match_rate": 0.1311,
          "llm_approval_rate": 0.6604,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 43,
          "incorrect": 18,
          "accuracy_from_exact_match": 0.1311,
          "accuracy_boost_from_llm": 0.5738,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.8249,
            "mean_kappa": 0.8249,
            "min_kappa": 0.7857,
            "max_kappa": 0.8574,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.09836065573770492,
          "total_tokens_input": 18538,
          "total_tokens_output": 893,
          "total_tokens": 19431,
          "latency_mean_ms": 1676.07,
          "latency_p50_ms": 1605.97,
          "latency_p95_ms": 2324.34,
          "latency_p99_ms": 3931.29,
          "latency_total_ms": 102240.46,
          "accuracy": 0.8852,
          "exact_match_rate": 0.0984,
          "llm_approval_rate": 0.8727,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 54,
          "incorrect": 7,
          "accuracy_from_exact_match": 0.0984,
          "accuracy_boost_from_llm": 0.7869,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6348,
            "mean_kappa": 0.6348,
            "min_kappa": 0.396,
            "max_kappa": 0.8121,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_few_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.7105615384615385,
        "std": 0.07301211215072508
      },
      "mean_kappa": {
        "mean": 0.7105615384615385,
        "std": 0.07301211215072508
      },
      "min_kappa": {
        "mean": 0.6163153846153846,
        "std": 0.1536373694833882
      },
      "max_kappa": {
        "mean": 0.7826076923076923,
        "std": 0.05890325133429804
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  },
  {
    "model_short": "qwen-coder-32b",
    "condition": "baseline_zero_shot",
    "finetuned": false,
    "few_shot": false,
    "num_seeds": 13,
    "metrics": {
      "accuracy": {
        "mean": 0.43756923076923077,
        "std": 0.09214025583620945
      },
      "exact_match": {
        "mean": 0.02648171500630517,
        "std": 0.018788984143444314
      },
      "exact_match_rate": {
        "mean": 0.026492307692307693,
        "std": 0.01879649973710169
      },
      "llm_approval_rate": {
        "mean": 0.4222692307692308,
        "std": 0.09554379088319324
      },
      "total_evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "evaluated": {
        "mean": 61,
        "std": 0.0
      },
      "correct": {
        "mean": 26.692307692307693,
        "std": 5.6211772019831105
      },
      "incorrect": {
        "mean": 34.30769230769231,
        "std": 5.6211772019831105
      },
      "accuracy_from_exact_match": {
        "mean": 0.026492307692307693,
        "std": 0.01879649973710169
      },
      "accuracy_boost_from_llm": {
        "mean": 0.4110923076923077,
        "std": 0.09192463017677087
      },
      "no_llm_fallback_count": {
        "mean": 0,
        "std": 0.0
      },
      "n_examples": {
        "mean": 61,
        "std": 0.0
      },
      "total_tokens_input": {
        "mean": 9451.76923076923,
        "std": 38.32483397756974
      },
      "total_tokens_output": {
        "mean": 897.4615384615385,
        "std": 54.66487465191939
      },
      "total_tokens": {
        "mean": 10349.23076923077,
        "std": 88.29248059816598
      },
      "latency_mean_ms": {
        "mean": 1631.6515384615384,
        "std": 93.76047033602775
      },
      "latency_p50_ms": {
        "mean": 1492.7423076923076,
        "std": 66.35098088125996
      },
      "latency_p95_ms": {
        "mean": 2413.776153846154,
        "std": 198.1114956295866
      },
      "latency_p99_ms": {
        "mean": 5026.289230769231,
        "std": 1550.3603066357562
      },
      "latency_total_ms": {
        "mean": 99530.80076923077,
        "std": 5719.286568606075
      }
    },
    "per_seed": [
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 9449,
          "total_tokens_output": 879,
          "total_tokens": 10328,
          "latency_mean_ms": 1634.7,
          "latency_p50_ms": 1567.59,
          "latency_p95_ms": 2339.57,
          "latency_p99_ms": 4401.98,
          "latency_total_ms": 99716.81,
          "accuracy": 0.4426,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.4138,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 27,
          "incorrect": 34,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.3934,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6013,
            "mean_kappa": 0.6013,
            "min_kappa": 0.3184,
            "max_kappa": 0.832,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed42__judge-ds-v3.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9388,
          "total_tokens_output": 835,
          "total_tokens": 10223,
          "latency_mean_ms": 1509.97,
          "latency_p50_ms": 1423.31,
          "latency_p95_ms": 2255.59,
          "latency_p99_ms": 3447.17,
          "latency_total_ms": 92108.46,
          "accuracy": 0.4754,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.4576,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.4426,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6904,
            "mean_kappa": 0.6904,
            "min_kappa": 0.6379,
            "max_kappa": 0.7345,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed43__judge-ds-v3.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9488,
          "total_tokens_output": 990,
          "total_tokens": 10478,
          "latency_mean_ms": 1780.9,
          "latency_p50_ms": 1533.8,
          "latency_p95_ms": 2313.59,
          "latency_p99_ms": 7731.16,
          "latency_total_ms": 108634.83,
          "accuracy": 0.4918,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.4833,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 30,
          "incorrect": 31,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.4754,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7781,
            "mean_kappa": 0.7781,
            "min_kappa": 0.7034,
            "max_kappa": 0.8282,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed45__judge-ds-v3.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9483,
          "total_tokens_output": 892,
          "total_tokens": 10375,
          "latency_mean_ms": 1600.02,
          "latency_p50_ms": 1421.32,
          "latency_p95_ms": 2771.09,
          "latency_p99_ms": 4732.95,
          "latency_total_ms": 97601.1,
          "accuracy": 0.4754,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.4754,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 29,
          "incorrect": 32,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.4754,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.822,
            "mean_kappa": 0.822,
            "min_kappa": 0.7316,
            "max_kappa": 0.9671,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed46__judge-ds-v3.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 9449,
          "total_tokens_output": 879,
          "total_tokens": 10328,
          "latency_mean_ms": 1634.7,
          "latency_p50_ms": 1567.59,
          "latency_p95_ms": 2339.57,
          "latency_p99_ms": 4401.98,
          "latency_total_ms": 99716.81,
          "accuracy": 0.3934,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.3621,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 24,
          "incorrect": 37,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6013,
            "mean_kappa": 0.6013,
            "min_kappa": 0.3184,
            "max_kappa": 0.832,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed42__judge-gpt-4.1.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9388,
          "total_tokens_output": 835,
          "total_tokens": 10223,
          "latency_mean_ms": 1509.97,
          "latency_p50_ms": 1423.31,
          "latency_p95_ms": 2255.59,
          "latency_p99_ms": 3447.17,
          "latency_total_ms": 92108.46,
          "accuracy": 0.459,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.4407,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 28,
          "incorrect": 33,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.4262,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6904,
            "mean_kappa": 0.6904,
            "min_kappa": 0.6379,
            "max_kappa": 0.7345,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed43__judge-gpt-4.1.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9488,
          "total_tokens_output": 990,
          "total_tokens": 10478,
          "latency_mean_ms": 1780.9,
          "latency_p50_ms": 1533.8,
          "latency_p95_ms": 2313.59,
          "latency_p99_ms": 7731.16,
          "latency_total_ms": 108634.83,
          "accuracy": 0.4262,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.4167,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 26,
          "incorrect": 35,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.4098,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7781,
            "mean_kappa": 0.7781,
            "min_kappa": 0.7034,
            "max_kappa": 0.8282,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed45__judge-gpt-4.1.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9483,
          "total_tokens_output": 892,
          "total_tokens": 10375,
          "latency_mean_ms": 1600.02,
          "latency_p50_ms": 1421.32,
          "latency_p95_ms": 2771.09,
          "latency_p99_ms": 4732.95,
          "latency_total_ms": 97601.1,
          "accuracy": 0.459,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.459,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 28,
          "incorrect": 33,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.822,
            "mean_kappa": 0.822,
            "min_kappa": 0.7316,
            "max_kappa": 0.9671,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed46__judge-gpt-4.1.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 9449,
          "total_tokens_output": 879,
          "total_tokens": 10328,
          "latency_mean_ms": 1634.7,
          "latency_p50_ms": 1567.59,
          "latency_p95_ms": 2339.57,
          "latency_p99_ms": 4401.98,
          "latency_total_ms": 99716.81,
          "accuracy": 0.2951,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.2586,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 18,
          "incorrect": 43,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.2459,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6013,
            "mean_kappa": 0.6013,
            "min_kappa": 0.3184,
            "max_kappa": 0.832,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed42__judge-gpt-5.2.json"
      },
      {
        "seed": 43,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.03278688524590164,
          "total_tokens_input": 9388,
          "total_tokens_output": 835,
          "total_tokens": 10223,
          "latency_mean_ms": 1509.97,
          "latency_p50_ms": 1423.31,
          "latency_p95_ms": 2255.59,
          "latency_p99_ms": 3447.17,
          "latency_total_ms": 92108.46,
          "accuracy": 0.377,
          "exact_match_rate": 0.0328,
          "llm_approval_rate": 0.3559,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 23,
          "incorrect": 38,
          "accuracy_from_exact_match": 0.0328,
          "accuracy_boost_from_llm": 0.3443,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6904,
            "mean_kappa": 0.6904,
            "min_kappa": 0.6379,
            "max_kappa": 0.7345,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed43__judge-gpt-5.2.json"
      },
      {
        "seed": 45,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.01639344262295082,
          "total_tokens_input": 9488,
          "total_tokens_output": 990,
          "total_tokens": 10478,
          "latency_mean_ms": 1780.9,
          "latency_p50_ms": 1533.8,
          "latency_p95_ms": 2313.59,
          "latency_p99_ms": 7731.16,
          "latency_total_ms": 108634.83,
          "accuracy": 0.3443,
          "exact_match_rate": 0.0164,
          "llm_approval_rate": 0.3333,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 21,
          "incorrect": 40,
          "accuracy_from_exact_match": 0.0164,
          "accuracy_boost_from_llm": 0.3279,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.7781,
            "mean_kappa": 0.7781,
            "min_kappa": 0.7034,
            "max_kappa": 0.8282,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed45__judge-gpt-5.2.json"
      },
      {
        "seed": 46,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.0,
          "total_tokens_input": 9483,
          "total_tokens_output": 892,
          "total_tokens": 10375,
          "latency_mean_ms": 1600.02,
          "latency_p50_ms": 1421.32,
          "latency_p95_ms": 2771.09,
          "latency_p99_ms": 4732.95,
          "latency_total_ms": 97601.1,
          "accuracy": 0.3607,
          "exact_match_rate": 0.0,
          "llm_approval_rate": 0.3607,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 22,
          "incorrect": 39,
          "accuracy_from_exact_match": 0.0,
          "accuracy_boost_from_llm": 0.3607,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.822,
            "mean_kappa": 0.822,
            "min_kappa": 0.7316,
            "max_kappa": 0.9671,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed46__judge-gpt-5.2.json"
      },
      {
        "seed": 42,
        "metrics": {
          "n_examples": 61,
          "exact_match": 0.04918032786885246,
          "total_tokens_input": 9449,
          "total_tokens_output": 879,
          "total_tokens": 10328,
          "latency_mean_ms": 1634.7,
          "latency_p50_ms": 1567.59,
          "latency_p95_ms": 2339.57,
          "latency_p99_ms": 4401.98,
          "latency_total_ms": 99716.81,
          "accuracy": 0.6885,
          "exact_match_rate": 0.0492,
          "llm_approval_rate": 0.6724,
          "total_evaluated": 61,
          "evaluated": 61,
          "correct": 42,
          "incorrect": 19,
          "accuracy_from_exact_match": 0.0492,
          "accuracy_boost_from_llm": 0.6393,
          "no_llm_fallback_count": 0,
          "judge_agreement": {
            "confidence_score": 0.6013,
            "mean_kappa": 0.6013,
            "min_kappa": 0.3184,
            "max_kappa": 0.832,
            "n_items": 61
          }
        },
        "source": "qwen-coder-32b_baseline_zero_shot_seed42__judge-llama-70b.json"
      }
    ],
    "judge_agreement": {
      "confidence_score": {
        "mean": 0.7135923076923076,
        "std": 0.08761467616381369
      },
      "mean_kappa": {
        "mean": 0.7135923076923076,
        "std": 0.08761467616381369
      },
      "min_kappa": {
        "mean": 0.5763307692307692,
        "std": 0.1750276478582538
      },
      "max_kappa": {
        "mean": 0.8398,
        "std": 0.07967587222857753
      },
      "n_items": {
        "mean": 61,
        "std": 0.0
      }
    }
  }
]