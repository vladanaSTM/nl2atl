{
  "judge_model": "gpt-5.2",
  "prompt_version": "v1.0",
  "created_at": "2026-01-16T17:38:01.159086Z",
  "overall": {
    "accuracy": 0.5352941176470588,
    "precision": 0.5352941176470588,
    "recall": 0.5352941176470588,
    "f1": 0.5352941176470588,
    "tp": 364,
    "fp": 316,
    "tn": 0,
    "fn": 316,
    "evaluated": 680,
    "correct_yes": 364,
    "correct_no": 316
  },
  "per_file": [
    {
      "source_file": "ds-r1-qwen-32b_baseline_few_shot.json",
      "stem": "ds-r1-qwen-32b_baseline_few_shot",
      "metrics": {
        "accuracy": 0.7,
        "precision": 0.7,
        "recall": 0.7,
        "f1": 0.7,
        "tp": 14,
        "fp": 6,
        "tn": 0,
        "fn": 6,
        "evaluated": 20,
        "correct_yes": 14,
        "correct_no": 6
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 2,
        "llm_calls": 18,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "ds-r1-qwen-32b_baseline_zero_shot.json",
      "stem": "ds-r1-qwen-32b_baseline_zero_shot",
      "metrics": {
        "accuracy": 0.1,
        "precision": 0.1,
        "recall": 0.1,
        "f1": 0.1,
        "tp": 2,
        "fp": 18,
        "tn": 0,
        "fn": 18,
        "evaluated": 20,
        "correct_yes": 2,
        "correct_no": 18
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "ds-v3.2_baseline_few_shot.json",
      "stem": "ds-v3.2_baseline_few_shot",
      "metrics": {
        "accuracy": 0.7,
        "precision": 0.7,
        "recall": 0.7,
        "f1": 0.7,
        "tp": 14,
        "fp": 6,
        "tn": 0,
        "fn": 6,
        "evaluated": 20,
        "correct_yes": 14,
        "correct_no": 6
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 2,
        "llm_calls": 18,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "ds-v3.2_baseline_zero_shot.json",
      "stem": "ds-v3.2_baseline_zero_shot",
      "metrics": {
        "accuracy": 0.6,
        "precision": 0.6,
        "recall": 0.6,
        "f1": 0.6,
        "tp": 12,
        "fp": 8,
        "tn": 0,
        "fn": 8,
        "evaluated": 20,
        "correct_yes": 12,
        "correct_no": 8
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "gemma3-27b_baseline_few_shot.json",
      "stem": "gemma3-27b_baseline_few_shot",
      "metrics": {
        "accuracy": 0.65,
        "precision": 0.65,
        "recall": 0.65,
        "f1": 0.65,
        "tp": 13,
        "fp": 7,
        "tn": 0,
        "fn": 7,
        "evaluated": 20,
        "correct_yes": 13,
        "correct_no": 7
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 2,
        "llm_calls": 18,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "gemma3-27b_baseline_zero_shot.json",
      "stem": "gemma3-27b_baseline_zero_shot",
      "metrics": {
        "accuracy": 0.1,
        "precision": 0.1,
        "recall": 0.1,
        "f1": 0.1,
        "tp": 2,
        "fp": 18,
        "tn": 0,
        "fn": 18,
        "evaluated": 20,
        "correct_yes": 2,
        "correct_no": 18
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "gpt-4.1_baseline_few_shot.json",
      "stem": "gpt-4.1_baseline_few_shot",
      "metrics": {
        "accuracy": 0.85,
        "precision": 0.85,
        "recall": 0.85,
        "f1": 0.85,
        "tp": 17,
        "fp": 3,
        "tn": 0,
        "fn": 3,
        "evaluated": 20,
        "correct_yes": 17,
        "correct_no": 3
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 3,
        "llm_calls": 17,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "gpt-4.1_baseline_zero_shot.json",
      "stem": "gpt-4.1_baseline_zero_shot",
      "metrics": {
        "accuracy": 0.8,
        "precision": 0.8,
        "recall": 0.8,
        "f1": 0.8,
        "tp": 16,
        "fp": 4,
        "tn": 0,
        "fn": 4,
        "evaluated": 20,
        "correct_yes": 16,
        "correct_no": 4
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "gpt-5.2_baseline_few_shot.json",
      "stem": "gpt-5.2_baseline_few_shot",
      "metrics": {
        "accuracy": 0.8,
        "precision": 0.8,
        "recall": 0.8,
        "f1": 0.8,
        "tp": 16,
        "fp": 4,
        "tn": 0,
        "fn": 4,
        "evaluated": 20,
        "correct_yes": 16,
        "correct_no": 4
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 2,
        "llm_calls": 18,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "gpt-5.2_baseline_zero_shot.json",
      "stem": "gpt-5.2_baseline_zero_shot",
      "metrics": {
        "accuracy": 0.8,
        "precision": 0.8,
        "recall": 0.8,
        "f1": 0.8,
        "tp": 16,
        "fp": 4,
        "tn": 0,
        "fn": 4,
        "evaluated": 20,
        "correct_yes": 16,
        "correct_no": 4
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "gpt-5_baseline_few_shot.json",
      "stem": "gpt-5_baseline_few_shot",
      "metrics": {
        "accuracy": 0.95,
        "precision": 0.95,
        "recall": 0.95,
        "f1": 0.95,
        "tp": 19,
        "fp": 1,
        "tn": 0,
        "fn": 1,
        "evaluated": 20,
        "correct_yes": 19,
        "correct_no": 1
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 2,
        "llm_calls": 18,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "gpt-5_baseline_zero_shot.json",
      "stem": "gpt-5_baseline_zero_shot",
      "metrics": {
        "accuracy": 0.55,
        "precision": 0.55,
        "recall": 0.55,
        "f1": 0.55,
        "tp": 11,
        "fp": 9,
        "tn": 0,
        "fn": 9,
        "evaluated": 20,
        "correct_yes": 11,
        "correct_no": 9
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "llama_baseline_few_shot.json",
      "stem": "llama_baseline_few_shot",
      "metrics": {
        "accuracy": 0.25,
        "precision": 0.25,
        "recall": 0.25,
        "f1": 0.25,
        "tp": 5,
        "fp": 15,
        "tn": 0,
        "fn": 15,
        "evaluated": 20,
        "correct_yes": 5,
        "correct_no": 15
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "llama_baseline_zero_shot.json",
      "stem": "llama_baseline_zero_shot",
      "metrics": {
        "accuracy": 0.1,
        "precision": 0.1,
        "recall": 0.1,
        "f1": 0.1,
        "tp": 2,
        "fp": 18,
        "tn": 0,
        "fn": 18,
        "evaluated": 20,
        "correct_yes": 2,
        "correct_no": 18
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "llama_finetuned_few_shot.json",
      "stem": "llama_finetuned_few_shot",
      "metrics": {
        "accuracy": 0.9,
        "precision": 0.9,
        "recall": 0.9,
        "f1": 0.9,
        "tp": 18,
        "fp": 2,
        "tn": 0,
        "fn": 2,
        "evaluated": 20,
        "correct_yes": 18,
        "correct_no": 2
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 8,
        "llm_calls": 12,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "llama_finetuned_zero_shot.json",
      "stem": "llama_finetuned_zero_shot",
      "metrics": {
        "accuracy": 0.85,
        "precision": 0.85,
        "recall": 0.85,
        "f1": 0.85,
        "tp": 17,
        "fp": 3,
        "tn": 0,
        "fn": 3,
        "evaluated": 20,
        "correct_yes": 17,
        "correct_no": 3
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 8,
        "llm_calls": 12,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "mistral_baseline_few_shot.json",
      "stem": "mistral_baseline_few_shot",
      "metrics": {
        "accuracy": 0.65,
        "precision": 0.65,
        "recall": 0.65,
        "f1": 0.65,
        "tp": 13,
        "fp": 7,
        "tn": 0,
        "fn": 7,
        "evaluated": 20,
        "correct_yes": 13,
        "correct_no": 7
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "mistral_baseline_zero_shot.json",
      "stem": "mistral_baseline_zero_shot",
      "metrics": {
        "accuracy": 0.1,
        "precision": 0.1,
        "recall": 0.1,
        "f1": 0.1,
        "tp": 2,
        "fp": 18,
        "tn": 0,
        "fn": 18,
        "evaluated": 20,
        "correct_yes": 2,
        "correct_no": 18
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "mistral_finetuned_few_shot.json",
      "stem": "mistral_finetuned_few_shot",
      "metrics": {
        "accuracy": 0.85,
        "precision": 0.85,
        "recall": 0.85,
        "f1": 0.85,
        "tp": 17,
        "fp": 3,
        "tn": 0,
        "fn": 3,
        "evaluated": 20,
        "correct_yes": 17,
        "correct_no": 3
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "mistral_finetuned_zero_shot.json",
      "stem": "mistral_finetuned_zero_shot",
      "metrics": {
        "accuracy": 0.9,
        "precision": 0.9,
        "recall": 0.9,
        "f1": 0.9,
        "tp": 18,
        "fp": 2,
        "tn": 0,
        "fn": 2,
        "evaluated": 20,
        "correct_yes": 18,
        "correct_no": 2
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "phi3_baseline_few_shot.json",
      "stem": "phi3_baseline_few_shot",
      "metrics": {
        "accuracy": 0.2,
        "precision": 0.2,
        "recall": 0.2,
        "f1": 0.2,
        "tp": 4,
        "fp": 16,
        "tn": 0,
        "fn": 16,
        "evaluated": 20,
        "correct_yes": 4,
        "correct_no": 16
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "phi3_baseline_zero_shot.json",
      "stem": "phi3_baseline_zero_shot",
      "metrics": {
        "accuracy": 0.1,
        "precision": 0.1,
        "recall": 0.1,
        "f1": 0.1,
        "tp": 2,
        "fp": 18,
        "tn": 0,
        "fn": 18,
        "evaluated": 20,
        "correct_yes": 2,
        "correct_no": 18
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "phi3_finetuned_few_shot.json",
      "stem": "phi3_finetuned_few_shot",
      "metrics": {
        "accuracy": 0.75,
        "precision": 0.75,
        "recall": 0.75,
        "f1": 0.75,
        "tp": 15,
        "fp": 5,
        "tn": 0,
        "fn": 5,
        "evaluated": 20,
        "correct_yes": 15,
        "correct_no": 5
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 7,
        "llm_calls": 13,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "phi3_finetuned_zero_shot.json",
      "stem": "phi3_finetuned_zero_shot",
      "metrics": {
        "accuracy": 0.7,
        "precision": 0.7,
        "recall": 0.7,
        "f1": 0.7,
        "tp": 14,
        "fp": 6,
        "tn": 0,
        "fn": 6,
        "evaluated": 20,
        "correct_yes": 14,
        "correct_no": 6
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 7,
        "llm_calls": 13,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "qwen-3b_baseline_few_shot.json",
      "stem": "qwen-3b_baseline_few_shot",
      "metrics": {
        "accuracy": 0.35,
        "precision": 0.35,
        "recall": 0.35,
        "f1": 0.35,
        "tp": 7,
        "fp": 13,
        "tn": 0,
        "fn": 13,
        "evaluated": 20,
        "correct_yes": 7,
        "correct_no": 13
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "qwen-3b_baseline_zero_shot.json",
      "stem": "qwen-3b_baseline_zero_shot",
      "metrics": {
        "accuracy": 0.0,
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "tp": 0,
        "fp": 20,
        "tn": 0,
        "fn": 20,
        "evaluated": 20,
        "correct_yes": 0,
        "correct_no": 20
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "qwen-3b_finetuned_few_shot.json",
      "stem": "qwen-3b_finetuned_few_shot",
      "metrics": {
        "accuracy": 0.75,
        "precision": 0.75,
        "recall": 0.75,
        "f1": 0.75,
        "tp": 15,
        "fp": 5,
        "tn": 0,
        "fn": 5,
        "evaluated": 20,
        "correct_yes": 15,
        "correct_no": 5
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 7,
        "llm_calls": 13,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "qwen-3b_finetuned_zero_shot.json",
      "stem": "qwen-3b_finetuned_zero_shot",
      "metrics": {
        "accuracy": 0.15,
        "precision": 0.15,
        "recall": 0.15,
        "f1": 0.15,
        "tp": 3,
        "fp": 17,
        "tn": 0,
        "fn": 17,
        "evaluated": 20,
        "correct_yes": 3,
        "correct_no": 17
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "qwen-7b_baseline_few_shot.json",
      "stem": "qwen-7b_baseline_few_shot",
      "metrics": {
        "accuracy": 0.4,
        "precision": 0.4,
        "recall": 0.4,
        "f1": 0.4,
        "tp": 8,
        "fp": 12,
        "tn": 0,
        "fn": 12,
        "evaluated": 20,
        "correct_yes": 8,
        "correct_no": 12
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 2,
        "llm_calls": 18,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "qwen-7b_baseline_zero_shot.json",
      "stem": "qwen-7b_baseline_zero_shot",
      "metrics": {
        "accuracy": 0.05,
        "precision": 0.05,
        "recall": 0.05,
        "f1": 0.05,
        "tp": 1,
        "fp": 19,
        "tn": 0,
        "fn": 19,
        "evaluated": 20,
        "correct_yes": 1,
        "correct_no": 19
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "qwen-7b_finetuned_few_shot.json",
      "stem": "qwen-7b_finetuned_few_shot",
      "metrics": {
        "accuracy": 0.95,
        "precision": 0.95,
        "recall": 0.95,
        "f1": 0.95,
        "tp": 19,
        "fp": 1,
        "tn": 0,
        "fn": 1,
        "evaluated": 20,
        "correct_yes": 19,
        "correct_no": 1
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 9,
        "llm_calls": 11,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "qwen-7b_finetuned_zero_shot.json",
      "stem": "qwen-7b_finetuned_zero_shot",
      "metrics": {
        "accuracy": 0.75,
        "precision": 0.75,
        "recall": 0.75,
        "f1": 0.75,
        "tp": 15,
        "fp": 5,
        "tn": 0,
        "fn": 5,
        "evaluated": 20,
        "correct_yes": 15,
        "correct_no": 5
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 6,
        "llm_calls": 14,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "qwen-coder-32b_baseline_few_shot.json",
      "stem": "qwen-coder-32b_baseline_few_shot",
      "metrics": {
        "accuracy": 0.75,
        "precision": 0.75,
        "recall": 0.75,
        "f1": 0.75,
        "tp": 15,
        "fp": 5,
        "tn": 0,
        "fn": 5,
        "evaluated": 20,
        "correct_yes": 15,
        "correct_no": 5
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 2,
        "llm_calls": 18,
        "cache_hits": 0,
        "no_llm": 0
      }
    },
    {
      "source_file": "qwen-coder-32b_baseline_zero_shot.json",
      "stem": "qwen-coder-32b_baseline_zero_shot",
      "metrics": {
        "accuracy": 0.1,
        "precision": 0.1,
        "recall": 0.1,
        "f1": 0.1,
        "tp": 2,
        "fp": 18,
        "tn": 0,
        "fn": 18,
        "evaluated": 20,
        "correct_yes": 2,
        "correct_no": 18
      },
      "stats": {
        "unmatched": 0,
        "auto_exact": 0,
        "llm_calls": 20,
        "cache_hits": 0,
        "no_llm": 0
      }
    }
  ],
  "ranking": [
    {
      "rank": 1,
      "source_file": "gpt-5_baseline_few_shot.json",
      "accuracy": 0.95,
      "f1": 0.95,
      "tp": 19,
      "fp": 1,
      "tn": 0,
      "fn": 1
    },
    {
      "rank": 2,
      "source_file": "qwen-7b_finetuned_few_shot.json",
      "accuracy": 0.95,
      "f1": 0.95,
      "tp": 19,
      "fp": 1,
      "tn": 0,
      "fn": 1
    },
    {
      "rank": 3,
      "source_file": "llama_finetuned_few_shot.json",
      "accuracy": 0.9,
      "f1": 0.9,
      "tp": 18,
      "fp": 2,
      "tn": 0,
      "fn": 2
    },
    {
      "rank": 4,
      "source_file": "mistral_finetuned_zero_shot.json",
      "accuracy": 0.9,
      "f1": 0.9,
      "tp": 18,
      "fp": 2,
      "tn": 0,
      "fn": 2
    },
    {
      "rank": 5,
      "source_file": "gpt-4.1_baseline_few_shot.json",
      "accuracy": 0.85,
      "f1": 0.85,
      "tp": 17,
      "fp": 3,
      "tn": 0,
      "fn": 3
    },
    {
      "rank": 6,
      "source_file": "llama_finetuned_zero_shot.json",
      "accuracy": 0.85,
      "f1": 0.85,
      "tp": 17,
      "fp": 3,
      "tn": 0,
      "fn": 3
    },
    {
      "rank": 7,
      "source_file": "mistral_finetuned_few_shot.json",
      "accuracy": 0.85,
      "f1": 0.85,
      "tp": 17,
      "fp": 3,
      "tn": 0,
      "fn": 3
    },
    {
      "rank": 8,
      "source_file": "gpt-4.1_baseline_zero_shot.json",
      "accuracy": 0.8,
      "f1": 0.8,
      "tp": 16,
      "fp": 4,
      "tn": 0,
      "fn": 4
    },
    {
      "rank": 9,
      "source_file": "gpt-5.2_baseline_few_shot.json",
      "accuracy": 0.8,
      "f1": 0.8,
      "tp": 16,
      "fp": 4,
      "tn": 0,
      "fn": 4
    },
    {
      "rank": 10,
      "source_file": "gpt-5.2_baseline_zero_shot.json",
      "accuracy": 0.8,
      "f1": 0.8,
      "tp": 16,
      "fp": 4,
      "tn": 0,
      "fn": 4
    },
    {
      "rank": 11,
      "source_file": "phi3_finetuned_few_shot.json",
      "accuracy": 0.75,
      "f1": 0.75,
      "tp": 15,
      "fp": 5,
      "tn": 0,
      "fn": 5
    },
    {
      "rank": 12,
      "source_file": "qwen-3b_finetuned_few_shot.json",
      "accuracy": 0.75,
      "f1": 0.75,
      "tp": 15,
      "fp": 5,
      "tn": 0,
      "fn": 5
    },
    {
      "rank": 13,
      "source_file": "qwen-7b_finetuned_zero_shot.json",
      "accuracy": 0.75,
      "f1": 0.75,
      "tp": 15,
      "fp": 5,
      "tn": 0,
      "fn": 5
    },
    {
      "rank": 14,
      "source_file": "qwen-coder-32b_baseline_few_shot.json",
      "accuracy": 0.75,
      "f1": 0.75,
      "tp": 15,
      "fp": 5,
      "tn": 0,
      "fn": 5
    },
    {
      "rank": 15,
      "source_file": "ds-r1-qwen-32b_baseline_few_shot.json",
      "accuracy": 0.7,
      "f1": 0.7,
      "tp": 14,
      "fp": 6,
      "tn": 0,
      "fn": 6
    },
    {
      "rank": 16,
      "source_file": "ds-v3.2_baseline_few_shot.json",
      "accuracy": 0.7,
      "f1": 0.7,
      "tp": 14,
      "fp": 6,
      "tn": 0,
      "fn": 6
    },
    {
      "rank": 17,
      "source_file": "phi3_finetuned_zero_shot.json",
      "accuracy": 0.7,
      "f1": 0.7,
      "tp": 14,
      "fp": 6,
      "tn": 0,
      "fn": 6
    },
    {
      "rank": 18,
      "source_file": "gemma3-27b_baseline_few_shot.json",
      "accuracy": 0.65,
      "f1": 0.65,
      "tp": 13,
      "fp": 7,
      "tn": 0,
      "fn": 7
    },
    {
      "rank": 19,
      "source_file": "mistral_baseline_few_shot.json",
      "accuracy": 0.65,
      "f1": 0.65,
      "tp": 13,
      "fp": 7,
      "tn": 0,
      "fn": 7
    },
    {
      "rank": 20,
      "source_file": "ds-v3.2_baseline_zero_shot.json",
      "accuracy": 0.6,
      "f1": 0.6,
      "tp": 12,
      "fp": 8,
      "tn": 0,
      "fn": 8
    },
    {
      "rank": 21,
      "source_file": "gpt-5_baseline_zero_shot.json",
      "accuracy": 0.55,
      "f1": 0.55,
      "tp": 11,
      "fp": 9,
      "tn": 0,
      "fn": 9
    },
    {
      "rank": 22,
      "source_file": "qwen-7b_baseline_few_shot.json",
      "accuracy": 0.4,
      "f1": 0.4,
      "tp": 8,
      "fp": 12,
      "tn": 0,
      "fn": 12
    },
    {
      "rank": 23,
      "source_file": "qwen-3b_baseline_few_shot.json",
      "accuracy": 0.35,
      "f1": 0.35,
      "tp": 7,
      "fp": 13,
      "tn": 0,
      "fn": 13
    },
    {
      "rank": 24,
      "source_file": "llama_baseline_few_shot.json",
      "accuracy": 0.25,
      "f1": 0.25,
      "tp": 5,
      "fp": 15,
      "tn": 0,
      "fn": 15
    },
    {
      "rank": 25,
      "source_file": "phi3_baseline_few_shot.json",
      "accuracy": 0.2,
      "f1": 0.2,
      "tp": 4,
      "fp": 16,
      "tn": 0,
      "fn": 16
    },
    {
      "rank": 26,
      "source_file": "qwen-3b_finetuned_zero_shot.json",
      "accuracy": 0.15,
      "f1": 0.15,
      "tp": 3,
      "fp": 17,
      "tn": 0,
      "fn": 17
    },
    {
      "rank": 27,
      "source_file": "ds-r1-qwen-32b_baseline_zero_shot.json",
      "accuracy": 0.1,
      "f1": 0.1,
      "tp": 2,
      "fp": 18,
      "tn": 0,
      "fn": 18
    },
    {
      "rank": 28,
      "source_file": "gemma3-27b_baseline_zero_shot.json",
      "accuracy": 0.1,
      "f1": 0.1,
      "tp": 2,
      "fp": 18,
      "tn": 0,
      "fn": 18
    },
    {
      "rank": 29,
      "source_file": "llama_baseline_zero_shot.json",
      "accuracy": 0.1,
      "f1": 0.1,
      "tp": 2,
      "fp": 18,
      "tn": 0,
      "fn": 18
    },
    {
      "rank": 30,
      "source_file": "mistral_baseline_zero_shot.json",
      "accuracy": 0.1,
      "f1": 0.1,
      "tp": 2,
      "fp": 18,
      "tn": 0,
      "fn": 18
    },
    {
      "rank": 31,
      "source_file": "phi3_baseline_zero_shot.json",
      "accuracy": 0.1,
      "f1": 0.1,
      "tp": 2,
      "fp": 18,
      "tn": 0,
      "fn": 18
    },
    {
      "rank": 32,
      "source_file": "qwen-coder-32b_baseline_zero_shot.json",
      "accuracy": 0.1,
      "f1": 0.1,
      "tp": 2,
      "fp": 18,
      "tn": 0,
      "fn": 18
    },
    {
      "rank": 33,
      "source_file": "qwen-7b_baseline_zero_shot.json",
      "accuracy": 0.05,
      "f1": 0.05,
      "tp": 1,
      "fp": 19,
      "tn": 0,
      "fn": 19
    },
    {
      "rank": 34,
      "source_file": "qwen-3b_baseline_zero_shot.json",
      "accuracy": 0.0,
      "f1": 0.0,
      "tp": 0,
      "fp": 20,
      "tn": 0,
      "fn": 20
    }
  ],
  "totals": {
    "evaluated": 680,
    "auto_exact": 69,
    "llm_calls": 611,
    "cache_hits": 0,
    "no_llm": 0
  },
  "metric_notes": {
    "accuracy": "correct_yes / evaluated",
    "precision_recall_f1": "computed as correct_yes / evaluated (positive class correct==yes)",
    "confusion_matrix": "tp=correct_yes, fp=incorrect, fn=incorrect, tn=0"
  }
}